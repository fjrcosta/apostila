<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 12 Introdução à Correlação Linear de Pearson e Regressão Linear Simples | apostila.knit</title>
  <meta name="description" content="Apostila com alguns tópicos de estatística e probabilidade." />
  <meta name="generator" content="bookdown 0.44 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 12 Introdução à Correlação Linear de Pearson e Regressão Linear Simples | apostila.knit" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://fjrcosta.github.io/apostila/images/logo-uel.png" />
  <meta property="og:description" content="Apostila com alguns tópicos de estatística e probabilidade." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 12 Introdução à Correlação Linear de Pearson e Regressão Linear Simples | apostila.knit" />
  
  <meta name="twitter:description" content="Apostila com alguns tópicos de estatística e probabilidade." />
  <meta name="twitter:image" content="https://fjrcosta.github.io/apostila/images/logo-uel.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introducao-a-testes-de-hipoteses.html"/>
<link rel="next" href="introducao-a-regressao-linear-multipla.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Índice</a></li>

<li class="divider"></li>
<li><a href="index.html#section" id="toc-section"></a></li>
<li class="chapter" data-level="1" data-path="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html"><a href="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html"><i class="fa fa-check"></i><b>1</b> Introdução histórica daquilo que veio a se chamar estatística</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html"><a href="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html#filosofia-da-ciencia-teoria-do-conhecimento-epistemologia"><i class="fa fa-check"></i><b>1.1</b> Filosofia da ciencia (teoria do conhecimento, epistemologia)</a></li>
<li class="chapter" data-level="1.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#diferentes-usos-relacionados-ao-termo-primeiros-levantamentos-estudos-e-publica%C3%A7%C3%B5es-o-passado-distante"><i class="fa fa-check"></i><b>1.2</b> Diferentes usos relacionados ao termo, primeiros levantamentos, estudos e publicações (o passado distante)</a></li>
<li class="chapter" data-level="1.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#visualiza%C3%A7%C3%A3o-de-dados-estudos-e-primeiras-publica%C3%A7%C3%B5es"><i class="fa fa-check"></i><b>1.3</b> Visualização de dados &amp; Estudos e primeiras publicações</a></li>
<li class="chapter" data-level="1.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#pesquisadores-cuja-contribui%C3%A7%C3%A3o-foi-fundamental-na-%C3%A1rea"><i class="fa fa-check"></i><b>1.4</b> Pesquisadores cuja contribuição foi fundamental na área</a></li>
<li class="chapter" data-level="1.5" data-path="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html"><a href="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html#revista-biometrika"><i class="fa fa-check"></i><b>1.5</b> Revista Biometrika</a></li>
<li class="chapter" data-level="1.6" data-path="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html"><a href="introducao-historica-daquilo-que-veio-a-se-chamar-estatistica.html#eugenia"><i class="fa fa-check"></i><b>1.6</b> Eugenia</a></li>
<li class="chapter" data-level="1.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#estat%C3%ADstica-e-machine-learning-uma-livre-tradu%C3%A7%C3%A3o-deste-link"><i class="fa fa-check"></i><b>1.7</b> Estatística e <em>machine learning</em> : uma livre tradução deste link</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introducao-conceitual-essencial.html"><a href="introducao-conceitual-essencial.html"><i class="fa fa-check"></i><b>2</b> Introdução conceitual essencial</a>
<ul>
<li class="chapter" data-level="2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#estat%C3%ADstica-descritiva"><i class="fa fa-check"></i><b>2.1</b> Estatística descritiva</a></li>
<li class="chapter" data-level="2.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#estat%C3%ADstica-inferencial"><i class="fa fa-check"></i><b>2.2</b> Estatística inferencial</a></li>
<li class="chapter" data-level="2.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#produ%C3%A7%C3%A3o-de-conhecimento"><i class="fa fa-check"></i><b>2.3</b> Produção de conhecimento</a></li>
<li class="chapter" data-level="2.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#popula%C3%A7%C3%A3o-universo-amostra"><i class="fa fa-check"></i><b>2.4</b> População (universo) &amp; amostra</a></li>
<li class="chapter" data-level="2.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#par%C3%A2metros-e-estat%C3%ADsticas"><i class="fa fa-check"></i><b>2.5</b> Parâmetros e estatísticas</a></li>
<li class="chapter" data-level="2.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#tipos-de-vari%C3%A1veis"><i class="fa fa-check"></i><b>2.6</b> Tipos de variáveis</a></li>
<li class="chapter" data-level="2.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#indexa%C3%A7%C3%A3o-de-dados-i"><i class="fa fa-check"></i><b>2.7</b> Indexação de dados (<span class="math inline">\(i\)</span>)</a></li>
<li class="chapter" data-level="2.8" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#no%C3%A7%C3%B5es-b%C3%A1sicas-sobre-somat%C3%B3rios-sigma"><i class="fa fa-check"></i><b>2.8</b> Noções básicas sobre somatórios (<span class="math inline">\(\Sigma\)</span>)</a></li>
<li class="chapter" data-level="2.9" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#an%C3%A1lise-combinat%C3%B3ria-m%C3%A9todos-de-enumera%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9</b> Análise combinatória (métodos de enumeração)</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#princ%C3%ADpio-b%C3%A1sico-da-contagem-regra-da-multiplica%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9.1</b> Princípio básico da contagem (regra da multiplicação)</a></li>
<li class="chapter" data-level="2.9.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#regra-da-adi%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9.2</b> Regra da adição</a></li>
<li class="chapter" data-level="2.9.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#permuta%C3%A7%C3%B5es-ordena%C3%A7%C3%A3o-de-elementos"><i class="fa fa-check"></i><b>2.9.3</b> Permutações (ordenação de elementos)</a></li>
<li class="chapter" data-level="2.9.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#arranjos-sem-repeti%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9.4</b> Arranjos sem repetição</a></li>
<li class="chapter" data-level="2.9.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#arranjos-com-repeti%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9.5</b> Arranjos com repetição</a></li>
<li class="chapter" data-level="2.9.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#combina%C3%A7%C3%B5es-sem-repeti%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9.6</b> Combinações sem repetição</a></li>
<li class="chapter" data-level="2.9.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#combina%C3%A7%C3%B5es-com-repeti%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>2.9.7</b> Combinações com Repetição</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="introducao-conceitual-essencial.html"><a href="introducao-conceitual-essencial.html#fatoriais"><i class="fa fa-check"></i><b>2.10</b> Fatoriais</a></li>
<li class="chapter" data-level="2.11" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#conectivos-l%C3%B3gicos"><i class="fa fa-check"></i><b>2.11</b> Conectivos lógicos</a></li>
<li class="chapter" data-level="2.12" data-path="introducao-conceitual-essencial.html"><a href="introducao-conceitual-essencial.html#leis-de-de-morgan"><i class="fa fa-check"></i><b>2.12</b> Leis de De Morgan</a></li>
<li class="chapter" data-level="2.13" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#no%C3%A7%C3%B5es-b%C3%A1sicas-para-o-uso-de-calculadora-cassio-fx-82ms"><i class="fa fa-check"></i><b>2.13</b> Noções básicas para o uso de calculadora (Cassio fx-82MS)</a></li>
<li class="chapter" data-level="2.14" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#instala%C3%A7%C3%A3o-do-software-r-em-conjunto-com-a-interface-gr%C3%A1fica-rstudio"><i class="fa fa-check"></i><b>2.14</b> Instalação do software R em conjunto com a interface gráfica RStudio</a>
<ul>
<li class="chapter" data-level="2.14.1" data-path="introducao-conceitual-essencial.html"><a href="introducao-conceitual-essencial.html#rstudio"><i class="fa fa-check"></i><b>2.14.1</b> RStudio</a></li>
<li class="chapter" data-level="2.14.2" data-path="introducao-conceitual-essencial.html"><a href="introducao-conceitual-essencial.html#pacotes"><i class="fa fa-check"></i><b>2.14.2</b> Pacotes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html"><i class="fa fa-check"></i><b>3</b> Introdução à estatística descritiva</a>
<ul>
<li class="chapter" data-level="3.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#an%C3%A1lise-explorat%C3%B3ria"><i class="fa fa-check"></i><b>3.1</b> Análise exploratória</a></li>
<li class="chapter" data-level="3.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#dados-brutos-em-rol-diagrama-de-ramos-folhas-e-de-dispers%C3%A3o-unidimensional"><i class="fa fa-check"></i><b>3.2</b> Dados brutos, em rol, diagrama de ramos &amp; folhas e de dispersão unidimensional</a></li>
<li class="chapter" data-level="3.3" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#apresentacao-descritiva-de-dados-na-forma-de-resumos-numericos"><i class="fa fa-check"></i><b>3.3</b> Apresentacao descritiva de dados na forma de resumos numericos</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#estimadores"><i class="fa fa-check"></i><b>3.3.1</b> Estimadores</a></li>
<li class="chapter" data-level="3.3.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#medidas-de-tend%C3%AAncia-central-posi%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>3.3.2</b> Medidas de tendência central (posição)</a></li>
<li class="chapter" data-level="3.3.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#medidas-de-dispers%C3%A3o-variabilidade"><i class="fa fa-check"></i><b>3.3.3</b> Medidas de dispersão (variabilidade)</a></li>
<li class="chapter" data-level="3.3.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#medidas-de-subdivis%C3%A3o-separatrizes"><i class="fa fa-check"></i><b>3.3.4</b> Medidas de subdivisão (separatrizes)</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#padronizacao-de-dados-z-scores"><i class="fa fa-check"></i><b>3.4</b> Padronizacao de dados (<em>z-scores</em>)</a></li>
<li class="chapter" data-level="3.5" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#medidas-de-forma-assimetria-curtose"><i class="fa fa-check"></i><b>3.5</b> Medidas de forma (assimetria &amp; curtose)</a></li>
<li class="chapter" data-level="3.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#diferentes-posi%C3%A7%C3%B5es-da-m%C3%A9dia-moda-e-mediana-2o-quartil"><i class="fa fa-check"></i><b>3.6</b> Diferentes posições da média, moda e mediana (2<span class="math inline">\(^{o}\)</span> quartil)</a></li>
<li class="chapter" data-level="3.7" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#apresentacao-descritiva-de-dados-na-forma-tabular"><i class="fa fa-check"></i><b>3.7</b> Apresentacao descritiva de dados na forma tabular</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#apresentacao-tabular-de-dados-qualitativos"><i class="fa fa-check"></i><b>3.7.1</b> Apresentacao tabular de dados qualitativos</a></li>
<li class="chapter" data-level="3.7.2" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#apresentacao-tabular-de-dados-quantitativos"><i class="fa fa-check"></i><b>3.7.2</b> Apresentacao tabular de dados quantitativos</a></li>
<li class="chapter" data-level="3.7.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#m%C3%A9dia-1"><i class="fa fa-check"></i><b>3.7.3</b> Média</a></li>
<li class="chapter" data-level="3.7.4" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#moda-1"><i class="fa fa-check"></i><b>3.7.4</b> Moda</a></li>
<li class="chapter" data-level="3.7.5" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#mediana-q_2d_5p_50"><i class="fa fa-check"></i><b>3.7.5</b> Mediana (<span class="math inline">\(=Q_{2}=D_{5}=P_{50}\)</span>)</a></li>
<li class="chapter" data-level="3.7.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#vari%C3%A2ncia"><i class="fa fa-check"></i><b>3.7.6</b> Variância</a></li>
<li class="chapter" data-level="3.7.7" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#quartis"><i class="fa fa-check"></i><b>3.7.7</b> Quartis</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="introducao-a-estatistica-descritiva.html"><a href="introducao-a-estatistica-descritiva.html#apresentacao-descritiva-de-dados-na-forma-grafica"><i class="fa fa-check"></i><b>3.8</b> Apresentacao descritiva de dados na forma grafica</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#gr%C3%A1ficos-para-uma-vari%C3%A1vel-qualitativa"><i class="fa fa-check"></i><b>3.8.1</b> Gráficos para uma variável qualitativa</a></li>
<li class="chapter" data-level="3.8.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#gr%C3%A1ficos-para-uma-vari%C3%A1vel-quantitativa"><i class="fa fa-check"></i><b>3.8.2</b> Gráficos para uma variável quantitativa</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html"><i class="fa fa-check"></i><b>4</b> Introdução ao cálculo de probabilidades</a>
<ul>
<li class="chapter" data-level="4.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#introdu%C3%A7%C3%A3o-hist%C3%B3rica"><i class="fa fa-check"></i><b>4.1</b> Introdução histórica</a></li>
<li class="chapter" data-level="4.2" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#conceitos-essenciais"><i class="fa fa-check"></i><b>4.2</b> Conceitos essenciais</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#experimentos-determin%C3%ADsticos-e-experimentos-aleat%C3%B3rios"><i class="fa fa-check"></i><b>4.2.1</b> Experimentos determinísticos e experimentos aleatórios</a></li>
<li class="chapter" data-level="4.2.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#o-espa%C3%A7o-amostral"><i class="fa fa-check"></i><b>4.2.2</b> O espaço amostral</a></li>
<li class="chapter" data-level="4.2.3" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#evento"><i class="fa fa-check"></i><b>4.2.3</b> Evento</a></li>
<li class="chapter" data-level="4.2.4" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#probabilidade"><i class="fa fa-check"></i><b>4.2.4</b> Probabilidade</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#probabilidade-da-uni%C3%A3o-de-eventos"><i class="fa fa-check"></i><b>4.3</b> Probabilidade da união de eventos</a></li>
<li class="chapter" data-level="4.4" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#probabilidade-de-eventos-condicionados"><i class="fa fa-check"></i><b>4.4</b> Probabilidade de eventos condicionados</a></li>
<li class="chapter" data-level="4.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#depend%C3%AAncia-e-independ%C3%AAncia-de-eventos"><i class="fa fa-check"></i><b>4.5</b> Dependência e independência de eventos</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#demonstra%C3%A7%C3%A3o-cl%C3%A1ssica-de-independ%C3%AAncia"><i class="fa fa-check"></i><b>4.5.1</b> Demonstração clássica de independência</a></li>
<li class="chapter" data-level="4.5.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#demonstra%C3%A7%C3%A3o-cl%C3%A1ssica-de-depend%C3%AAncia"><i class="fa fa-check"></i><b>4.5.2</b> Demonstração clássica de dependência</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#probabilidade-de-eventos-independentes-regra-da-cadeia"><i class="fa fa-check"></i><b>4.6</b> Probabilidade de eventos independentes (regra da cadeia)</a></li>
<li class="chapter" data-level="4.7" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-de-bayes"><i class="fa fa-check"></i><b>4.7</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="4.8" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teoremas-da-teoria-das-probabilidades"><i class="fa fa-check"></i><b>4.8</b> Teoremas da Teoria das probabilidades</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-01"><i class="fa fa-check"></i><b>4.8.1</b> Teorema 01</a></li>
<li class="chapter" data-level="4.8.2" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-02"><i class="fa fa-check"></i><b>4.8.2</b> Teorema 02</a></li>
<li class="chapter" data-level="4.8.3" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-03"><i class="fa fa-check"></i><b>4.8.3</b> Teorema 03</a></li>
<li class="chapter" data-level="4.8.4" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-04"><i class="fa fa-check"></i><b>4.8.4</b> Teorema 04</a></li>
<li class="chapter" data-level="4.8.5" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-05"><i class="fa fa-check"></i><b>4.8.5</b> Teorema 05</a></li>
<li class="chapter" data-level="4.8.6" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-06"><i class="fa fa-check"></i><b>4.8.6</b> Teorema 06</a></li>
<li class="chapter" data-level="4.8.7" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-07"><i class="fa fa-check"></i><b>4.8.7</b> Teorema 07</a></li>
<li class="chapter" data-level="4.8.8" data-path="introducao-ao-calculo-de-probabilidades.html"><a href="introducao-ao-calculo-de-probabilidades.html#teorema-08"><i class="fa fa-check"></i><b>4.8.8</b> Teorema 08</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introducao-a-variaveis-aleatorias.html"><a href="introducao-a-variaveis-aleatorias.html"><i class="fa fa-check"></i><b>5</b> Introdução a variáveis aleatórias</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introducao-a-variaveis-aleatorias.html"><a href="introducao-a-variaveis-aleatorias.html#variaveis-aleatorias-discretas-continuas"><i class="fa fa-check"></i><b>5.1</b> Variáveis aleatórias discretas e contínuas</a></li>
<li class="chapter" data-level="5.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#fun%C3%A7%C3%A3o-massa-de-probabilidade-probability-mass-function---pmf"><i class="fa fa-check"></i><b>5.2</b> Função massa de probabilidade (<em>Probability Mass Function - PMF</em>)</a></li>
<li class="chapter" data-level="5.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#fun%C3%A7%C3%A3o-cumulativa-de-probabilidade"><i class="fa fa-check"></i><b>5.3</b> Função cumulativa de probabilidade</a></li>
<li class="chapter" data-level="5.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#fun%C3%A7%C3%A3o-de-densidade-de-probabilidade-probability-density-function---pdf"><i class="fa fa-check"></i><b>5.4</b> Função de densidade de probabilidade (<em>Probability Density Function - PDF</em>)</a></li>
<li class="chapter" data-level="5.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#esperan%C3%A7a-e-vari%C3%A2ncia-de-uma-vari%C3%A1vel-aleat%C3%B3ria-discreta"><i class="fa fa-check"></i><b>5.5</b> Esperança e variância de uma variável aleatória discreta</a></li>
<li class="chapter" data-level="5.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#esperan%C3%A7a-e-vari%C3%A2ncia-de-uma-vari%C3%A1vel-aleat%C3%B3ria-cont%C3%ADnua"><i class="fa fa-check"></i><b>5.6</b> Esperança e variância de uma variável aleatória contínua</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html"><i class="fa fa-check"></i><b>6</b> Introdução a modelos teóricos de probabilidade</a>
<ul>
<li class="chapter" data-level="6.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#modelos-te%C3%B3ricos-de-probabilidade-para-vari%C3%A1veis-aleat%C3%B3rias-discretas"><i class="fa fa-check"></i><b>6.1</b> Modelos teóricos de probabilidade para variáveis aleatórias discretas</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#uniforme"><i class="fa fa-check"></i><b>6.1.1</b> Uniforme</a></li>
<li class="chapter" data-level="6.1.2" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#bernoulli"><i class="fa fa-check"></i><b>6.1.2</b> Bernoulli</a></li>
<li class="chapter" data-level="6.1.3" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#binomial"><i class="fa fa-check"></i><b>6.1.3</b> Binomial</a></li>
<li class="chapter" data-level="6.1.4" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#poisson"><i class="fa fa-check"></i><b>6.1.4</b> Poisson</a></li>
<li class="chapter" data-level="6.1.5" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#multinomial"><i class="fa fa-check"></i><b>6.1.5</b> Multinomial</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#modelos-t%C3%A9oricos-do-tempo-de-espera"><i class="fa fa-check"></i><b>6.2</b> Modelos téoricos do tempo de espera</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#geom%C3%A9trica"><i class="fa fa-check"></i><b>6.2.1</b> Geométrica</a></li>
<li class="chapter" data-level="6.2.2" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#binomial-negativa"><i class="fa fa-check"></i><b>6.2.2</b> Binomial Negativa</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#modelos-te%C3%B3ricos-de-probabilidade-para-vari%C3%A1veis-aleat%C3%B3rias-cont%C3%ADnuas"><i class="fa fa-check"></i><b>6.3</b> Modelos teóricos de probabilidade para variáveis aleatórias contínuas</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#uniforme-1"><i class="fa fa-check"></i><b>6.3.1</b> Uniforme</a></li>
<li class="chapter" data-level="6.3.2" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#exponencial"><i class="fa fa-check"></i><b>6.3.2</b> Exponencial</a></li>
<li class="chapter" data-level="6.3.3" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#normal"><i class="fa fa-check"></i><b>6.3.3</b> Normal</a></li>
<li class="chapter" data-level="6.3.4" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#student-t"><i class="fa fa-check"></i><b>6.3.4</b> Student “t”</a></li>
<li class="chapter" data-level="6.3.5" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#qui-quadrado"><i class="fa fa-check"></i><b>6.3.5</b> Qui-Quadrado</a></li>
<li class="chapter" data-level="6.3.6" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#fisher-snedecor-f"><i class="fa fa-check"></i><b>6.3.6</b> Fisher-Snedecor “F”</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="introducao-a-modelos-teoricos-de-probabilidade.html"><a href="introducao-a-modelos-teoricos-de-probabilidade.html#tabelas"><i class="fa fa-check"></i><b>6.4</b> Tabelas</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html"><i class="fa fa-check"></i><b>7</b> Introdução ao planejamento de pesquisas</a>
<ul>
<li class="chapter" data-level="7.1" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#planejamento-de-pesquisas"><i class="fa fa-check"></i><b>7.1</b> Planejamento de pesquisas</a></li>
<li class="chapter" data-level="7.2" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#tipos-de-pesquisas"><i class="fa fa-check"></i><b>7.2</b> Tipos de pesquisas</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#quanto-%C3%A0-finalidade"><i class="fa fa-check"></i><b>7.2.1</b> Quanto à finalidade</a></li>
<li class="chapter" data-level="7.2.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#quanto-%C3%A0-forma-de-abordagem"><i class="fa fa-check"></i><b>7.2.2</b> Quanto à forma de abordagem</a></li>
<li class="chapter" data-level="7.2.3" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#quanto-aos-objetivos"><i class="fa fa-check"></i><b>7.2.3</b> Quanto aos objetivos</a></li>
<li class="chapter" data-level="7.2.4" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#quanto-ao-desenvolvimento-no-tempo"><i class="fa fa-check"></i><b>7.2.4</b> Quanto ao desenvolvimento no tempo</a></li>
<li class="chapter" data-level="7.2.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#quanto-%C3%A0-natureza"><i class="fa fa-check"></i><b>7.2.5</b> Quanto à natureza</a></li>
<li class="chapter" data-level="7.2.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#quanto-%C3%A0-forma-de-obten%C3%A7%C3%A3o-dos-dados"><i class="fa fa-check"></i><b>7.2.6</b> Quanto à forma de obtenção dos dados</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#principais-etapas-de-uma-pesquisa"><i class="fa fa-check"></i><b>7.3</b> Principais etapas de uma pesquisa:</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#objetivo"><i class="fa fa-check"></i><b>7.3.1</b> Objetivo</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#popula%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>7.4</b> População</a></li>
<li class="chapter" data-level="7.5" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#censo"><i class="fa fa-check"></i><b>7.5</b> Censo</a></li>
<li class="chapter" data-level="7.6" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#amostra"><i class="fa fa-check"></i><b>7.6</b> Amostra</a></li>
<li class="chapter" data-level="7.7" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#planejamento-do-levantamento-amostral"><i class="fa fa-check"></i><b>7.7</b> Planejamento do levantamento amostral</a></li>
<li class="chapter" data-level="7.8" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#elabora%C3%A7%C3%A3o-dos-question%C3%A1rios"><i class="fa fa-check"></i><b>7.8</b> Elaboração dos questionários</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#tipos-de-perguntas"><i class="fa fa-check"></i><b>7.8.1</b> Tipos de perguntas:</a></li>
<li class="chapter" data-level="7.8.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#execu%C3%A7%C3%A3o-do-levantamento-amostral"><i class="fa fa-check"></i><b>7.8.2</b> Execução do levantamento amostral</a></li>
<li class="chapter" data-level="7.8.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#an%C3%A1lise-explorat%C3%B3ria-dos-dados"><i class="fa fa-check"></i><b>7.8.3</b> Análise exploratória dos dados</a></li>
<li class="chapter" data-level="7.8.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#resultados-e-conclus%C3%B5es"><i class="fa fa-check"></i><b>7.8.4</b> Resultados e conclusões</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#t%C3%A9cnicas-de-amostragem"><i class="fa fa-check"></i><b>7.9</b> Técnicas de amostragem</a></li>
<li class="chapter" data-level="7.10" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-probabil%C3%ADstica"><i class="fa fa-check"></i><b>7.10</b> Amostragem probabilística</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-aleat%C3%B3ria-simples-aas"><i class="fa fa-check"></i><b>7.10.1</b> Amostragem aleatória simples (AAS)</a></li>
<li class="chapter" data-level="7.10.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-aleat%C3%B3ria-sistem%C3%A1tica"><i class="fa fa-check"></i><b>7.10.2</b> Amostragem aleatória sistemática</a></li>
<li class="chapter" data-level="7.10.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-aleat%C3%B3ria-estratificada"><i class="fa fa-check"></i><b>7.10.3</b> Amostragem aleatória estratificada</a></li>
<li class="chapter" data-level="7.10.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-aleat%C3%B3ria-por-conglomerados"><i class="fa fa-check"></i><b>7.10.4</b> Amostragem aleatória por conglomerados</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-n%C3%A3o-probabil%C3%ADstica"><i class="fa fa-check"></i><b>7.11</b> Amostragem não probabilística</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#amostragem-por-conveni%C3%AAncia"><i class="fa fa-check"></i><b>7.11.1</b> Amostragem por conveniência</a></li>
<li class="chapter" data-level="7.11.2" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#amostragem-por-cotas"><i class="fa fa-check"></i><b>7.11.2</b> Amostragem por cotas</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#dimensionamento-de-amostras"><i class="fa fa-check"></i><b>7.12</b> Dimensionamento de amostras</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="introducao-ao-planejamento-de-pesquisas.html"><a href="introducao-ao-planejamento-de-pesquisas.html#erros"><i class="fa fa-check"></i><b>7.12.1</b> Erros</a></li>
<li class="chapter" data-level="7.12.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#determina%C3%A7%C3%A3o-do-tamanho-de-uma-amostra-para-estima%C3%A7%C3%A3o-da-m%C3%A9dia-populacional"><i class="fa fa-check"></i><b>7.12.2</b> Determinação do tamanho de uma amostra para estimação da média populacional</a></li>
<li class="chapter" data-level="7.12.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#determina%C3%A7%C3%A3o-do-tamanho-de-uma-amostra-para-estima%C3%A7%C3%A3o-da-propor%C3%A7%C3%A3o-populacional"><i class="fa fa-check"></i><b>7.12.3</b> Determinação do tamanho de uma amostra para estimação da proporção populacional</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html"><i class="fa fa-check"></i><b>8</b> Introdução às estatísticas epidemiológicas</a>
<ul>
<li class="chapter" data-level="8.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#tipos-de-estudos-epidemiol%C3%B3gicos"><i class="fa fa-check"></i><b>8.1</b> Tipos de estudos epidemiológicos</a></li>
<li class="chapter" data-level="8.2" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#estudos-transversais"><i class="fa fa-check"></i><b>8.2</b> Estudos transversais</a></li>
<li class="chapter" data-level="8.3" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#estudos-longitudinais"><i class="fa fa-check"></i><b>8.3</b> Estudos longitudinais</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#estudos-de-casos-e-controles"><i class="fa fa-check"></i><b>8.3.1</b> Estudos de casos e controles</a></li>
<li class="chapter" data-level="8.3.2" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#estudos-de-coorte"><i class="fa fa-check"></i><b>8.3.2</b> Estudos de coorte</a></li>
<li class="chapter" data-level="8.3.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#estudos-cl%C3%ADnicos-aleatorizados"><i class="fa fa-check"></i><b>8.3.3</b> Estudos clínicos aleatorizados</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#terminologia"><i class="fa fa-check"></i><b>8.4</b> Terminologia</a></li>
<li class="chapter" data-level="8.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#medidas-de-risco-morte-associa%C3%A7%C3%A3o-e-correla%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>8.5</b> Medidas de risco, morte, associação e correlação</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#incid%C3%AAncia"><i class="fa fa-check"></i><b>8.5.1</b> Incidência</a></li>
<li class="chapter" data-level="8.5.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#preval%C3%AAncia"><i class="fa fa-check"></i><b>8.5.2</b> Prevalência</a></li>
<li class="chapter" data-level="8.5.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#incid%C3%AAncia-cumulativa---ic-risco"><i class="fa fa-check"></i><b>8.5.3</b> Incidência cumulativa - IC (Risco)</a></li>
<li class="chapter" data-level="8.5.4" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#fatalidade-dos-casos-fc"><i class="fa fa-check"></i><b>8.5.4</b> Fatalidade dos Casos (FC)</a></li>
<li class="chapter" data-level="8.5.5" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#taxas-de-mortalidade-tm"><i class="fa fa-check"></i><b>8.5.5</b> Taxas de mortalidade (TM)</a></li>
<li class="chapter" data-level="8.5.6" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#sobrevida"><i class="fa fa-check"></i><b>8.5.6</b> Sobrevida</a></li>
<li class="chapter" data-level="8.5.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#taxas-mais-espec%C3%ADficas"><i class="fa fa-check"></i><b>8.5.7</b> Taxas mais específicas</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#medidas-de-associa%C3%A7%C3%A3o-em-estudos-de-coorte"><i class="fa fa-check"></i><b>8.6</b> Medidas de associação em estudos de coorte</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#incid%C3%AAncia-observada-de-nascimentos-com-baixo-peso-entre-m%C3%A3es-expostas-ao-risco-n%C3%A3o-fumantes-i_e"><i class="fa fa-check"></i><b>8.6.1</b> Incidência observada de nascimentos com baixo peso entre mães expostas ao risco (não fumantes): <span class="math inline">\(I_{e}\)</span></a></li>
<li class="chapter" data-level="8.6.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#incid%C3%AAncia-observada-de-nascimentos-com-baixo-peso-entre-m%C3%A3es-n%C3%A3o-expostas-ao-risco-n%C3%A3o-fumantes-i_0"><i class="fa fa-check"></i><b>8.6.2</b> Incidência observada de nascimentos com baixo peso entre mães não expostas ao risco (não fumantes): <span class="math inline">\(I_{0}\)</span></a></li>
<li class="chapter" data-level="8.6.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#preval%C3%AAncia-de-nascimentos-com-baixo-peso-na-popula%C3%A7%C3%A3o-estudada"><i class="fa fa-check"></i><b>8.6.3</b> Prevalência de nascimentos com baixo peso na população estudada</a></li>
<li class="chapter" data-level="8.6.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#diferen%C3%A7a-de-risco-risco-atribu%C3%ADvel---ra"><i class="fa fa-check"></i><b>8.6.4</b> Diferença de risco (Risco atribuível - RA)</a></li>
<li class="chapter" data-level="8.6.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#raz%C3%A3o-de-risco-risco-relativo---rr"><i class="fa fa-check"></i><b>8.6.5</b> Razão de risco (Risco relativo - RR)</a></li>
<li class="chapter" data-level="8.6.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#risco-atribu%C3%ADvel-proporcional-fra%C3%A7%C3%A3o-etiol%C3%B3gica---fe"><i class="fa fa-check"></i><b>8.6.6</b> Risco atribuível proporcional (Fração etiológica - FE)</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#odds-ratio-raz%C3%A3o-das-chances-em-studos-de-casos-e-controles"><i class="fa fa-check"></i><b>8.7</b> <em>Odds ratio</em> (Razão das chances) em studos de casos e controles</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#chance-odds-de-observar-um-desfecho-entre-os-casos"><i class="fa fa-check"></i><b>8.7.1</b> Chance (<em>odds</em>) de observar um desfecho entre os casos:</a></li>
<li class="chapter" data-level="8.7.2" data-path="introducao-as-estatisticas-epidemiologicas.html"><a href="introducao-as-estatisticas-epidemiologicas.html#chance-odds-de-observar-um-desfecho-entre-os-controles"><i class="fa fa-check"></i><b>8.7.2</b> Chance (<em>odds</em>) de observar um desfecho entre os controles:</a></li>
<li class="chapter" data-level="8.7.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#a-raz%C3%A3o-das-chances-entre-os-casos-e-controle-odds-ratio"><i class="fa fa-check"></i><b>8.7.3</b> A razão das chances entre os casos e controle (<em>odds ratio</em>):</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#correla%C3%A7%C3%A3o-linear-de-pearson"><i class="fa fa-check"></i><b>8.8</b> Correlação linear de Pearson</a></li>
<li class="chapter" data-level="8.9" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a"><i class="fa fa-check"></i><b>8.9</b> Intervalos de confiança</a>
<ul>
<li class="chapter" data-level="8.9.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#raz%C3%A3o-de-risco-risco-relativo---rr-1"><i class="fa fa-check"></i><b>8.9.1</b> Razão de risco (Risco relativo - RR)</a></li>
<li class="chapter" data-level="8.9.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#raz%C3%A3o-de-chances-odds-ratio---or"><i class="fa fa-check"></i><b>8.9.2</b> Razão de chances ( <em>odds ratio</em> - OR)</a></li>
<li class="chapter" data-level="8.9.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#diferen%C3%A7a-de-risco-risco-atribu%C3%ADvel---ra-1"><i class="fa fa-check"></i><b>8.9.3</b> Diferença de risco (Risco atribuível - RA)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="introducao-a-distribuicao-das-medias-e-diferencas-entre-medias-e-seus-intervalos-de-confianca.html"><a href="introducao-a-distribuicao-das-medias-e-diferencas-entre-medias-e-seus-intervalos-de-confianca.html"><i class="fa fa-check"></i><b>9</b> Introdução à distribuição das médias e diferenças entre médias e seus intervalos de confiança</a>
<ul>
<li class="chapter" data-level="9.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#distribui%C3%A7%C3%B5es-amostrais"><i class="fa fa-check"></i><b>9.1</b> Distribuições amostrais</a></li>
<li class="chapter" data-level="9.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-1"><i class="fa fa-check"></i><b>9.2</b> Intervalos de confiança</a></li>
<li class="chapter" data-level="9.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#distribui%C3%A7%C3%A3o-das-m%C3%A9dias-amostrais-e-seus-intervalos-de-confian%C3%A7a"><i class="fa fa-check"></i><b>9.3</b> Distribuição das médias amostrais e seus intervalos de confiança</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#fator-de-corre%C3%A7%C3%A3o-para-popula%C3%A7%C3%B5es-finitas"><i class="fa fa-check"></i><b>9.3.1</b> Fator de correção para populações finitas</a></li>
<li class="chapter" data-level="9.3.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalo-de-confian%C3%A7a-para-a-m%C3%A9dia-de-uma-popula%C3%A7%C3%A3o-normal"><i class="fa fa-check"></i><b>9.3.2</b> Intervalo de confiança para a média de uma população Normal</a></li>
<li class="chapter" data-level="9.3.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-m%C3%A9dia-de-uma-popula%C3%A7%C3%A3o-normal-com-vari%C3%A2ncia-conhecida-figura-reffigfig28"><i class="fa fa-check"></i><b>9.3.3</b> Intervalos de confiança para a média de uma população Normal com variância conhecida (Figura @ref(fig:fig28))</a></li>
<li class="chapter" data-level="9.3.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-m%C3%A9dia-de-uma-popula%C3%A7%C3%A3o-normal-de-vari%C3%A2ncia-desconhecida-mas-amostra-n%C3%A3o-t%C3%A3o-pequena-n-ge-30-figura-reffigfig55"><i class="fa fa-check"></i><b>9.3.4</b> Intervalos de confiança para a média de uma população Normal de variância desconhecida mas amostra não tão pequena: <span class="math inline">\(n \ge 30\)</span> (Figura @ref(fig:fig55))</a></li>
<li class="chapter" data-level="9.3.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-m%C3%A9dia-de-uma-popula%C3%A7%C3%A3o-normal-com-vari%C3%A2ncia-desconhecida-e-amostra-de-qualquer-tamanho-figura-reffigfig58"><i class="fa fa-check"></i><b>9.3.5</b> Intervalos de confiança para a média de uma população Normal com variância desconhecida e amostra de qualquer tamanho (Figura @ref(fig:fig58))</a></li>
<li class="chapter" data-level="9.3.6" data-path="introducao-a-distribuicao-das-medias-e-diferencas-entre-medias-e-seus-intervalos-de-confianca.html"><a href="introducao-a-distribuicao-das-medias-e-diferencas-entre-medias-e-seus-intervalos-de-confianca.html#fluxograma-auxiliar"><i class="fa fa-check"></i><b>9.3.6</b> Fluxograma auxiliar</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#distribui%C3%A7%C3%A3o-das-diferen%C3%A7as-das-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-e-seus-intervalos-de-confian%C3%A7a"><i class="fa fa-check"></i><b>9.4</b> Distribuição das diferenças das médias de duas populações Normais e seus intervalos de confiança</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-diferen%C3%A7a-das-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-nomrais-de-vari%C3%A2ncias-conhecidas-e-amostras-independentes-de-qualquer-tamanho"><i class="fa fa-check"></i><b>9.4.1</b> Intervalos de confiança para a diferença das médias de duas populações Nomrais de variâncias conhecidas e amostras independentes de qualquer tamanho</a></li>
<li class="chapter" data-level="9.4.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-diferen%C3%A7a-das-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-de-vari%C3%A2ncias-desconhecidas-e-amostras-independentes-grandes"><i class="fa fa-check"></i><b>9.4.2</b> Intervalos de confiança para a diferença das médias de duas populações Normais de variâncias desconhecidas e amostras independentes grandes</a></li>
<li class="chapter" data-level="9.4.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-diferen%C3%A7a-das-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-de-vari%C3%A2ncias-desconhecidas-mas-iguais"><i class="fa fa-check"></i><b>9.4.3</b> Intervalos de confiança para a diferença das médias de duas populações Normais de variâncias desconhecidas mas iguais</a></li>
<li class="chapter" data-level="9.4.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-diferen%C3%A7a-das-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-de-vari%C3%A2ncias-desconhecidas-e-desiguais"><i class="fa fa-check"></i><b>9.4.4</b> Intervalos de confiança para a diferença das médias de duas populações Normais de variâncias desconhecidas e desiguais</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#distribui%C3%A7%C3%A3o-das-diferen%C3%A7as-das-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-com-m%C3%A9dias-n%C3%A3o-independentes-e-seus-intervalos-de-confian%C3%A7a"><i class="fa fa-check"></i><b>9.5</b> Distribuição das diferenças das médias de duas populações Normais com médias não independentes e seus intervalos de confiança</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="introducao-a-distribuicao-das-medias-e-diferencas-entre-medias-e-seus-intervalos-de-confianca.html"><a href="introducao-a-distribuicao-das-medias-e-diferencas-entre-medias-e-seus-intervalos-de-confianca.html#fluxograma-auxiliar-1"><i class="fa fa-check"></i><b>9.5.1</b> Fluxograma auxiliar</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="introducao-a-distribuicao-das-proporcoes-e-seus-intervalos-de-confianca.html"><a href="introducao-a-distribuicao-das-proporcoes-e-seus-intervalos-de-confianca.html"><i class="fa fa-check"></i><b>10</b> Introdução à distribuição das proporções e seus intervalos de confiança</a>
<ul>
<li class="chapter" data-level="10.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#conceito-elementar-de-uma-propor%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>10.1</b> Conceito elementar de uma proporção</a></li>
<li class="chapter" data-level="10.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#distribui%C3%A7%C3%A3o-das-propor%C3%A7%C3%B5es-amostrais"><i class="fa fa-check"></i><b>10.2</b> Distribuição das proporções amostrais</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#simula%C3%A7%C3%B5es-ilustrativas-da-aproxima%C3%A7%C3%A3o-da-distribui%C3%A7%C3%A3o-das-propor%C3%A7%C3%B5es-amostrais-pela-distribui%C3%A7%C3%A3o-normal"><i class="fa fa-check"></i><b>10.2.1</b> Simulações ilustrativas da aproximação da distribuição das proporções amostrais pela distribuição Normal</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#a-aleatoriedade-das-propor%C3%A7%C3%B5es-amostrais-e-o-tamanho-amostral"><i class="fa fa-check"></i><b>10.3</b> A aleatoriedade das proporções amostrais e o tamanho amostral</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#simula%C3%A7%C3%B5es-ilustrativas-sobre-as-flutua%C3%A7%C3%B5es-das-propor%C3%A7%C3%B5es-amostrais-e-o-erro-amostral-fixado"><i class="fa fa-check"></i><b>10.3.1</b> Simulações ilustrativas sobre as flutuações das proporções amostrais e o erro amostral fixado</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-uma-propor%C3%A7%C3%A3o-pi-pela-aproxima%C3%A7%C3%A3o-da-binomial-pela-normal"><i class="fa fa-check"></i><b>10.4</b> Intervalos de confiança para uma proporção <span class="math inline">\(\Pi\)</span> pela aproximação da Binomial pela Normal</a></li>
<li class="chapter" data-level="10.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalo-de-confian%C3%A7a-para-pi-diretamente-da-distribui%C3%A7%C3%A3o-binomial"><i class="fa fa-check"></i><b>10.5</b> Intervalo de confiança para <span class="math inline">\(\Pi\)</span> diretamente da Distribuição Binomial</a></li>
<li class="chapter" data-level="10.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#pobabilidades-associadas-%C3%A0-observa%C3%A7%C3%A3o-de-uma-propor%C3%A7%C3%A3o-amostral-hatp"><i class="fa fa-check"></i><b>10.6</b> Pobabilidades associadas à observação de uma proporção amostral <span class="math inline">\(\hat{p}\)</span></a></li>
<li class="chapter" data-level="10.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-para-a-diferen%C3%A7a-entre-duas-propor%C3%A7%C3%B5es-pi_x-pi_ypela-aproxima%C3%A7%C3%A3o-da-binomial-pela-normal"><i class="fa fa-check"></i><b>10.7</b> Intervalos de confiança para a diferença entre duas proporções (<span class="math inline">\(\Pi_{X}-\Pi_{Y}\)</span>)pela aproximação da Binomial pela Normal</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html"><i class="fa fa-check"></i><b>11</b> Introdução a testes de hipóteses</a>
<ul>
<li class="chapter" data-level="11.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#filosofia-da-ci%C3%AAncia"><i class="fa fa-check"></i><b>11.1</b> Filosofia da ciência</a></li>
<li class="chapter" data-level="11.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#hist%C3%B3ria"><i class="fa fa-check"></i><b>11.2</b> História</a></li>
<li class="chapter" data-level="11.3" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html#conceitos"><i class="fa fa-check"></i><b>11.3</b> Conceitos</a></li>
<li class="chapter" data-level="11.4" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html#natureza-dos-erros"><i class="fa fa-check"></i><b>11.4</b> Natureza dos erros</a></li>
<li class="chapter" data-level="11.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#recomenda%C3%A7%C3%B5es-gerais"><i class="fa fa-check"></i><b>11.5</b> Recomendações gerais</a></li>
<li class="chapter" data-level="11.6" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html#efeito-do-limite-central"><i class="fa fa-check"></i><b>11.6</b> Efeito do limite central</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html#erro-global"><i class="fa fa-check"></i><b>11.6.1</b> Erro global</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#estruturas-das-hip%C3%B3teses"><i class="fa fa-check"></i><b>11.7</b> Estruturas das hipóteses</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#interpreta%C3%A7%C3%A3o-gr%C3%A1fica-dos-n%C3%ADveis-de-signific%C3%A2nciaconfian%C3%A7a"><i class="fa fa-check"></i><b>11.7.1</b> Interpretação gráfica dos níveis de significância/confiança</a></li>
<li class="chapter" data-level="11.7.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-bilateral"><i class="fa fa-check"></i><b>11.7.2</b> Teste de hipóteses Bilateral</a></li>
<li class="chapter" data-level="11.7.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-unilateral-%C3%A0-esquerda"><i class="fa fa-check"></i><b>11.7.3</b> Teste de hipóteses Unilateral à esquerda</a></li>
<li class="chapter" data-level="11.7.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-unilateral-%C3%A0-direita"><i class="fa fa-check"></i><b>11.7.4</b> Teste de hipóteses Unilateral à direita</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-a-m%C3%A9dia-mu-de-uma-popula%C3%A7%C3%A3o-normal"><i class="fa fa-check"></i><b>11.8</b> Teste de hipóteses para a média <span class="math inline">\(\mu\)</span> de uma população Normal</a>
<ul>
<li class="chapter" data-level="11.8.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#cen%C3%A1rios-poss%C3%ADveis"><i class="fa fa-check"></i><b>11.8.1</b> Cenários possíveis</a></li>
<li class="chapter" data-level="11.8.2" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html#roteiro-geral"><i class="fa fa-check"></i><b>11.8.2</b> Roteiro geral</a></li>
<li class="chapter" data-level="11.8.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#probabilidade-dos-intervalos-de-confian%C3%A7a-para-os-testes-de-hip%C3%B3teses-com-o-uso-da-estat%C3%ADstica-z-z-sim-mathcaln01"><i class="fa fa-check"></i><b>11.8.3</b> Probabilidade dos intervalos de confiança para os testes de hipóteses com o uso da estatística Z (<span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span>):</a></li>
<li class="chapter" data-level="11.8.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#probabilidade-dos-intervalos-de-confian%C3%A7a-para-os-testes-de-hip%C3%B3teses-com-o-uso-da-estat%C3%ADstica-t-tsim-t_n-1"><i class="fa fa-check"></i><b>11.8.4</b> Probabilidade dos intervalos de confiança para os testes de hipóteses com o uso da estatística T (<span class="math inline">\(T\sim t_{(n-1)}\)</span>):</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-a-raz%C3%A3o-de-duas-vari%C3%A2ncias-fracsigma_12sigma_22"><i class="fa fa-check"></i><b>11.9</b> Teste de hipóteses para a razão de duas variâncias (<span class="math inline">\(\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}\)</span>)</a></li>
<li class="chapter" data-level="11.10" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-as-m%C3%A9dias-mu_1mu_2-de-duas-popula%C3%A7%C3%B5es-normais-independentes"><i class="fa fa-check"></i><b>11.10</b> Teste de hipóteses para as médias (<span class="math inline">\(\mu_{1};\mu_{2}\)</span>) de duas populações Normais independentes</a>
<ul>
<li class="chapter" data-level="11.10.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#as-estruturas-poss%C3%ADveis-dos-testes-de-hip%C3%B3teses-relacionados-%C3%A0s-suas-m%C3%A9dias-ser%C3%A3o"><i class="fa fa-check"></i><b>11.10.1</b> As estruturas possíveis dos testes de hipóteses relacionados às suas médias serão:</a></li>
<li class="chapter" data-level="11.10.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#testes-de-hip%C3%B3teses-para-as-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-com-vari%C3%A2ncias-conhecidas-ou-n%C3%A3o-conhecidas-mas-o-tamanho-das-amostras-%C3%A9-grande-nge30-s2approxsigma2"><i class="fa fa-check"></i><b>11.10.2</b> Testes de hipóteses para as médias de duas populações Normais com variâncias conhecidas (ou não conhecidas mas o tamanho das amostras é grande: <span class="math inline">\(n\ge30\)</span>: <span class="math inline">\(S^{2}\approx\sigma^{2}\)</span>)</a></li>
<li class="chapter" data-level="11.10.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#testes-de-hip%C3%B3teses-para-as-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-com-vari%C3%A2ncias-desconhecidas-mas-iguais-teste-t-homoced%C3%A1stico-sigma_12sigma_22"><i class="fa fa-check"></i><b>11.10.3</b> Testes de hipóteses para as médias de duas populações Normais com variâncias desconhecidas mas iguais: teste “t’’ homocedástico (<span class="math inline">\(\sigma_{1}^{2}=\sigma_{2}^{2}=?\)</span>)</a></li>
<li class="chapter" data-level="11.10.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-as-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-normais-com-vari%C3%A2ncias-desconhecidas-e-desiguais-teste-t-heteroced%C3%A1stico-sigma_12-neq-sigma_22"><i class="fa fa-check"></i><b>11.10.4</b> Teste de hipóteses para as médias de duas populações Normais com variâncias desconhecidas e desiguais: teste “``t’’ heterocedástico (<span class="math inline">\(\sigma_{1}^{2} \neq \sigma_{2}^{2}=?\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="11.11" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-uma-propor%C3%A7%C3%A3o-pi-de-uma-popula%C3%A7%C3%A3o-binomial"><i class="fa fa-check"></i><b>11.11</b> Teste de hipóteses para uma proporção <span class="math inline">\(\Pi\)</span> de uma população binomial</a>
<ul>
<li class="chapter" data-level="11.11.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#estruturas-poss%C3%ADveis-para-as-hip%C3%B3teses"><i class="fa fa-check"></i><b>11.11.1</b> Estruturas possíveis para as hipóteses</a></li>
<li class="chapter" data-level="11.11.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#probabilidade-dos-intervalos-de-confian%C3%A7a-para-os-testes-de-hip%C3%B3teses-com-o-uso-da-estat%C3%ADstica-z-z-sim-mathcaln01-1"><i class="fa fa-check"></i><b>11.11.2</b> Probabilidade dos intervalos de confiança para os testes de hipóteses com o uso da estatística Z (<span class="math inline">\(Z \sim \mathcal{N}(0,1)\)</span>):</a></li>
</ul></li>
<li class="chapter" data-level="11.12" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#testes-n%C3%A3o-param%C3%A9tricos"><i class="fa fa-check"></i><b>11.12</b> Testes não paramétricos</a>
<ul>
<li class="chapter" data-level="11.12.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-qui-quadrado-para-verifica%C3%A7%C3%A3o-da-independ%C3%AAncia-homogeneidade"><i class="fa fa-check"></i><b>11.12.1</b> Teste Qui-quadrado para verificação da independência (homogeneidade)</a></li>
<li class="chapter" data-level="11.12.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#corre%C3%A7%C3%A3o-de-continuidade-em-tabelas-2x2"><i class="fa fa-check"></i><b>11.12.2</b> Correção de continuidade em tabelas 2x2</a></li>
<li class="chapter" data-level="11.12.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#coeficiente-de-conting%C3%AAncia-de-pearson-modificado-c"><i class="fa fa-check"></i><b>11.12.3</b> Coeficiente de contingência de Pearson (modificado: <span class="math inline">\(C^{*})\)</span> }</a></li>
<li class="chapter" data-level="11.12.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-qui-quadrado-para-verifica%C3%A7%C3%A3o-da-qualidade-do-ajuste-a-uma-distribui%C3%A7%C3%A3o-te%C3%B3rica-de-probabilidade"><i class="fa fa-check"></i><b>11.12.4</b> Teste Qui-quadrado para verificação da qualidade do ajuste a uma distribuição teórica de probabilidade</a></li>
<li class="chapter" data-level="11.12.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-signific%C3%A2ncia-para-as-m%C3%A9dias-de-duas-popula%C3%A7%C3%B5es-dependentes"><i class="fa fa-check"></i><b>11.12.5</b> Teste de significância para as médias de duas populações dependentes</a></li>
</ul></li>
<li class="chapter" data-level="11.13" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#fluxograma-auxiliar-para-escolha-da-estat%C3%ADstica-do-teste-de-hip%C3%B3teses"><i class="fa fa-check"></i><b>11.13</b> Fluxograma auxiliar para escolha da estatística do teste de hipóteses</a></li>
<li class="chapter" data-level="11.14" data-path="introducao-a-testes-de-hipoteses.html"><a href="introducao-a-testes-de-hipoteses.html#tabelas-1"><i class="fa fa-check"></i><b>11.14</b> Tabelas</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><i class="fa fa-check"></i><b>12</b> Introdução à Correlação Linear de Pearson e Regressão Linear Simples</a>
<ul>
<li class="chapter" data-level="12.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#contexto-hist%C3%B3rico"><i class="fa fa-check"></i><b>12.1</b> Contexto histórico</a></li>
<li class="chapter" data-level="12.2" data-path="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#conceitos-1"><i class="fa fa-check"></i><b>12.2</b> Conceitos</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#correla%C3%A7%C3%A3o-linear-versus-regress%C3%A3o"><i class="fa fa-check"></i><b>12.2.1</b> Correlação linear <em>versus</em> regressão</a></li>
<li class="chapter" data-level="12.2.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#correla%C3%A7%C3%A3o-versus-causa%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>12.2.2</b> Correlação <em>versus</em> causação</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#diagrama-de-dispers%C3%A3o"><i class="fa fa-check"></i><b>12.3</b> Diagrama de dispersão</a></li>
<li class="chapter" data-level="12.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#coeficiente-de-correla%C3%A7%C3%A3o-linear-de-pearson"><i class="fa fa-check"></i><b>12.4</b> Coeficiente de correlação linear de Pearson</a></li>
<li class="chapter" data-level="12.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-a-correla%C3%A7%C3%A3o-linear-na-popula%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>12.5</b> Teste de hipóteses para a correlação linear na população</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#outros-testes-de-hip%C3%B3teses-sobre-a-correla%C3%A7%C3%A3o-linear-na-popula%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>12.5.1</b> Outros testes de hipóteses sobre a correlação linear na população</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#regress%C3%A3o-linear-simples"><i class="fa fa-check"></i><b>12.6</b> Regressão linear simples</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#introdu%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>12.6.1</b> Introdução</a></li>
<li class="chapter" data-level="12.6.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#linearidade-nos-par%C3%A2metros"><i class="fa fa-check"></i><b>12.6.2</b> Linearidade nos parâmetros</a></li>
<li class="chapter" data-level="12.6.3" data-path="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#nomenclatura"><i class="fa fa-check"></i><b>12.6.3</b> Nomenclatura</a></li>
<li class="chapter" data-level="12.6.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#m%C3%A9todo-dos-m%C3%ADnimos-quadrados"><i class="fa fa-check"></i><b>12.6.4</b> Método dos mínimos quadrados</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#modelo-de-regress%C3%A3o-linear-sob-erros-normais"><i class="fa fa-check"></i><b>12.7</b> Modelo de regressão linear sob erros Normais</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#propriedades-estat%C3%ADsticas-dos-estimadores-de-m%C3%ADnimos-quadrados"><i class="fa fa-check"></i><b>12.7.1</b> Propriedades Estatísticas dos Estimadores de Mínimos Quadrados</a></li>
<li class="chapter" data-level="12.7.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#pressupostos-do-modelo-de-regress%C3%A3o-linear"><i class="fa fa-check"></i><b>12.7.2</b> Pressupostos do Modelo de Regressão Linear</a></li>
<li class="chapter" data-level="12.7.3" data-path="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#propriedades-dos-estimadores-sob-erro-normal"><i class="fa fa-check"></i><b>12.7.3</b> Propriedades dos Estimadores sob Erro Normal</a></li>
<li class="chapter" data-level="12.7.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#implica%C3%A7%C3%B5es-da-normalidade"><i class="fa fa-check"></i><b>12.7.4</b> Implicações da Normalidade</a></li>
<li class="chapter" data-level="12.7.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#linearidade-na-rela%C3%A7%C3%A3o-entre-a-vari%C3%A1vel-preditora-x-e-a-vari%C3%A1vel-resposta-y"><i class="fa fa-check"></i><b>12.7.5</b> Linearidade na relação entre a variável preditora <span class="math inline">\(X\)</span> e a variável resposta <span class="math inline">\(Y\)</span>:</a></li>
<li class="chapter" data-level="12.7.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#homogeneidade-da-vari%C3%A2ncia-de-varepsilon-homocedasticidade"><i class="fa fa-check"></i><b>12.7.6</b> Homogeneidade da variância de <span class="math inline">\(\varepsilon\)</span> (homocedasticidade):</a></li>
<li class="chapter" data-level="12.7.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#inconsist%C3%AAncia-de-observa%C3%A7%C3%B5es-outliers"><i class="fa fa-check"></i><b>12.7.7</b> Inconsistência de observações (outliers)</a></li>
<li class="chapter" data-level="12.7.8" data-path="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#pontos-influentes-com-capacidade-de-alavanca-leverage"><i class="fa fa-check"></i><b>12.7.8</b> Pontos influentes com capacidade de alavanca (<span class="math inline">\(leverage\)</span>):</a></li>
<li class="chapter" data-level="12.7.9" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#independ%C3%AAncia"><i class="fa fa-check"></i><b>12.7.9</b> Independência</a></li>
<li class="chapter" data-level="12.7.10" data-path="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#normalidade"><i class="fa fa-check"></i><b>12.7.10</b> Normalidade</a></li>
<li class="chapter" data-level="12.7.11" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#vari%C3%A1veis-omitidas-do-modelo"><i class="fa fa-check"></i><b>12.7.11</b> Variáveis omitidas do modelo</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-signific%C3%A2ncia-global-do-modelo"><i class="fa fa-check"></i><b>12.8</b> Teste de significância (global) do modelo</a></li>
<li class="chapter" data-level="12.9" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-o-coef.-angular-beta"><i class="fa fa-check"></i><b>12.9</b> Teste de hipóteses para o coef. angular <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="12.10" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#teste-de-hip%C3%B3teses-para-o-coef.-angular-alpha"><i class="fa fa-check"></i><b>12.10</b> Teste de hipóteses para o coef. angular <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="12.11" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#coeficiente-de-determina%C3%A7%C3%A3o-r2"><i class="fa fa-check"></i><b>12.11</b> Coeficiente de determinação <span class="math inline">\(R^{2}\)</span></a></li>
<li class="chapter" data-level="12.12" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalos-de-confian%C3%A7a-nos-modelos-de-regress%C3%A3o-linear-simples"><i class="fa fa-check"></i><b>12.12</b> Intervalos de confiança nos modelos de regressão linear simples</a>
<ul>
<li class="chapter" data-level="12.12.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalo-de-confian%C3%A7a-para-a-resposta-m%C3%A9dia-do-modelo-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha"><i class="fa fa-check"></i><b>12.12.1</b> Intervalo de confiança para a resposta média do modelo sob um nível de significância <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="12.12.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalo-de-predi%C3%A7%C3%A3o-para-novas-observa%C3%A7%C3%B5es-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha"><i class="fa fa-check"></i><b>12.12.2</b> Intervalo de predição para novas observações sob um nível de significância <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="12.12.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalo-confian%C3%A7a-para-a-estimativa-a-do-par%C3%A2metro-alpha-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha"><i class="fa fa-check"></i><b>12.12.3</b> Intervalo confiança para a estimativa <span class="math inline">\(a\)</span> do parâmetro <span class="math inline">\(\alpha\)</span> sob um nível de significância <span class="math inline">\(\alpha\)</span></a></li>
<li class="chapter" data-level="12.12.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#intervalo-confian%C3%A7a-para-a-estimativa-b-do-par%C3%A2metro-beta-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha"><i class="fa fa-check"></i><b>12.12.4</b> Intervalo confiança para a estimativa <span class="math inline">\(b\)</span> do parâmetro <span class="math inline">\(\beta\)</span> sob um nível de significância <span class="math inline">\(\alpha\)</span></a></li>
</ul></li>
<li class="chapter" data-level="12.13" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#verifica%C3%A7%C3%B5es-gr%C3%A1ficas-visuais-das-premissas-do-mmqo"><i class="fa fa-check"></i><b>12.13</b> Verificações gráficas (visuais) das premissas do MMQO</a></li>
<li class="chapter" data-level="12.14" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#verifica%C3%A7%C3%B5es-adicionais"><i class="fa fa-check"></i><b>12.14</b> Verificações adicionais</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="introducao-a-regressao-linear-multipla.html"><a href="introducao-a-regressao-linear-multipla.html"><i class="fa fa-check"></i><b>13</b> Introdução à Regressão Linear Múltipla</a>
<ul>
<li class="chapter" data-level="13.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#introdu%C3%A7%C3%A3o-1"><i class="fa fa-check"></i><b>13.1</b> Introdução</a></li>
<li class="chapter" data-level="13.2" data-path="introducao-a-regressao-linear-multipla.html"><a href="introducao-a-regressao-linear-multipla.html#procedimentos-iniciais"><i class="fa fa-check"></i><b>13.2</b> Procedimentos iniciais</a></li>
<li class="chapter" data-level="13.3" data-path="introducao-a-regressao-linear-multipla.html"><a href="introducao-a-regressao-linear-multipla.html#engenharia-de-features"><i class="fa fa-check"></i><b>13.3</b> Engenharia de features</a></li>
<li class="chapter" data-level="13.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#regress%C3%A3o-linear-m%C3%BAltipla"><i class="fa fa-check"></i><b>13.4</b> Regressão Linear Múltipla</a></li>
<li class="chapter" data-level="13.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#resolu%C3%A7%C3%A3o-do-sistema-de-equa%C3%A7%C3%B5es-matriciais-1"><i class="fa fa-check"></i><b>13.5</b> Resolução do sistema de equações matriciais</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="introducao-a-modelagem-de-processos-estocasticos.html"><a href="introducao-a-modelagem-de-processos-estocasticos.html"><i class="fa fa-check"></i><b>14</b> Introdução à modelagem de processos estocásticos</a>
<ul>
<li class="chapter" data-level="14.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#modelos-determin%C3%ADsticos-e-estoc%C3%A1sticos"><i class="fa fa-check"></i><b>14.1</b> Modelos determinísticos e estocásticos</a></li>
<li class="chapter" data-level="14.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#dedu%C3%A7%C3%A3o-e-indu%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>14.2</b> Dedução e indução</a></li>
<li class="chapter" data-level="14.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#processos-estoc%C3%A1sticos-temporais-espaciais-e-espa%C3%A7otemporais"><i class="fa fa-check"></i><b>14.3</b> Processos estocásticos temporais, espaciais e espaçotemporais</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#processos-estoc%C3%A1sticos-temporais"><i class="fa fa-check"></i><b>14.3.1</b> Processos Estocásticos Temporais</a></li>
<li class="chapter" data-level="14.3.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#processos-estoc%C3%A1sticos-espaciais"><i class="fa fa-check"></i><b>14.3.2</b> Processos Estocásticos Espaciais</a></li>
<li class="chapter" data-level="14.3.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#processos-estoc%C3%A1sticos-espa%C3%A7otemporais"><i class="fa fa-check"></i><b>14.3.3</b> Processos Estocásticos Espaçotemporais</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="introducao-a-modelagem-de-processos-estocasticos.html"><a href="introducao-a-modelagem-de-processos-estocasticos.html#processo-de-poisson"><i class="fa fa-check"></i><b>14.4</b> Processo de Poisson</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="introducao-a-modelagem-de-processos-estocasticos.html"><a href="introducao-a-modelagem-de-processos-estocasticos.html#natureza"><i class="fa fa-check"></i><b>14.4.1</b> Natureza</a></li>
<li class="chapter" data-level="14.4.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#processo-de-poisson-com-classifica%C3%A7%C3%A3o-de-eventos"><i class="fa fa-check"></i><b>14.4.2</b> Processo de Poisson com classificação de eventos</a></li>
<li class="chapter" data-level="14.4.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#processos-de-poisson-n%C3%A3o-homog%C3%AAneos"><i class="fa fa-check"></i><b>14.4.3</b> Processos de Poisson não homogêneos</a></li>
<li class="chapter" data-level="14.4.4" data-path="introducao-a-modelagem-de-processos-estocasticos.html"><a href="introducao-a-modelagem-de-processos-estocasticos.html#tempo-de-espera-em-um-processo-de-poisson"><i class="fa fa-check"></i><b>14.4.4</b> Tempo de espera em um processo de Poisson</a></li>
<li class="chapter" data-level="14.4.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#distribui%C3%A7%C3%A3o-condicional-dos-tempos-de-chegada"><i class="fa fa-check"></i><b>14.4.5</b> Distribuição condicional dos tempos de chegada</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#simula%C3%A7%C3%B5es-monte-carlo"><i class="fa fa-check"></i><b>14.5</b> Simulações Monte Carlo</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#introdu%C3%A7%C3%A3o-2"><i class="fa fa-check"></i><b>14.5.1</b> Introdução</a></li>
<li class="chapter" data-level="14.5.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#fundamenta%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>14.5.2</b> Fundamentação</a></li>
<li class="chapter" data-level="14.5.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#n%C3%BAmeros-aleat%C3%B3rios-e-pseudoaleat%C3%B3rios"><i class="fa fa-check"></i><b>14.5.3</b> Números Aleatórios e Pseudoaleatórios</a></li>
<li class="chapter" data-level="14.5.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#gera%C3%A7%C3%A3o-de-amostras-aleat%C3%B3rias-de-distribui%C3%A7%C3%B5es-de-probabilidade"><i class="fa fa-check"></i><b>14.5.4</b> Geração de amostras aleatórias de distribuições de probabilidade</a></li>
<li class="chapter" data-level="14.5.5" data-path="introducao-a-modelagem-de-processos-estocasticos.html"><a href="introducao-a-modelagem-de-processos-estocasticos.html#exemplo-1-goodwin-e-wright-2009"><i class="fa fa-check"></i><b>14.5.5</b> Exemplo 1 (Goodwin e Wright, 2009)</a></li>
<li class="chapter" data-level="14.5.6" data-path="introducao-a-modelagem-de-processos-estocasticos.html"><a href="introducao-a-modelagem-de-processos-estocasticos.html#exemplo-2-the-elite-pottery-company-goodwin-e-wright-2009"><i class="fa fa-check"></i><b>14.5.6</b> Exemplo 2: The Elite Pottery Company (Goodwin e Wright, 2009)</a></li>
<li class="chapter" data-level="14.5.7" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#exemplo-3-integra%C3%A7%C3%A3o-num%C3%A9rica-usando-o-m%C3%A9todo-de-monte-carlo"><i class="fa fa-check"></i><b>14.5.7</b> Exemplo 3: Integração Numérica Usando o Método de Monte Carlo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="numeros-indices.html"><a href="numeros-indices.html"><i class="fa fa-check"></i><b>15</b> Introdução a números índices</a>
<ul>
<li class="chapter" data-level="15.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#defini%C3%A7%C3%A3o"><i class="fa fa-check"></i><b>15.1</b> Definição</a></li>
<li class="chapter" data-level="15.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#caracter%C3%ADsticas-principais"><i class="fa fa-check"></i><b>15.2</b> Características principais</a></li>
<li class="chapter" data-level="15.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#aplica%C3%A7%C3%B5es"><i class="fa fa-check"></i><b>15.3</b> Aplicações</a></li>
<li class="chapter" data-level="15.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#n%C3%BAmeros-%C3%ADndice-relativos-simples-apenas-um-produto-est%C3%A1-sendo-analisado."><i class="fa fa-check"></i><b>15.4</b> Números índice relativos simples: apenas um produto está sendo analisado.</a></li>
<li class="chapter" data-level="15.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#n%C3%BAmeros-%C3%ADndice-compostos-mais-de-um-produto-est%C3%A1-sendo-analisado-cesta-de-produtos."><i class="fa fa-check"></i><b>15.5</b> Números índice compostos: mais de um produto está sendo analisado (cesta de produtos).</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#m%C3%A9todo-dos-agregados-simples"><i class="fa fa-check"></i><b>15.5.1</b> Método dos agregados simples</a></li>
<li class="chapter" data-level="15.5.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#m%C3%A9todo-dos-agregados-ponderados"><i class="fa fa-check"></i><b>15.5.2</b> Método dos agregados ponderados</a></li>
<li class="chapter" data-level="15.5.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#%C3%ADndice-de-fisher-m%C3%A9dia-geom%C3%A9trica"><i class="fa fa-check"></i><b>15.5.3</b> Índice de Fisher (Média geométrica)</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="numeros-indices.html"><a href="numeros-indices.html#exemplo-completo"><i class="fa fa-check"></i><b>15.6</b> Exemplo completo</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#%C3%ADndices-simples-pre%C3%A7os-quantidades-e-valoresreceitas"><i class="fa fa-check"></i><b>15.6.1</b> Índices Simples (preços, quantidades e valores/receitas)</a></li>
<li class="chapter" data-level="15.6.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#%C3%ADndices-agregativos"><i class="fa fa-check"></i><b>15.6.2</b> Índices Agregativos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="orientacoes-gerais.html"><a href="orientacoes-gerais.html"><i class="fa fa-check"></i><b>16</b> Orientações Gerais</a>
<ul>
<li class="chapter" data-level="16.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#informa%C3%A7%C3%B5es-administrativas"><i class="fa fa-check"></i><b>16.1</b> Informações administrativas</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="orientacoes-gerais.html"><a href="orientacoes-gerais.html#regimento-geral-da-uel"><i class="fa fa-check"></i><b>16.1.1</b> Regimento geral da UEL</a></li>
<li class="chapter" data-level="16.1.2" data-path="orientacoes-gerais.html"><a href="orientacoes-gerais.html#amparos-e-apoios-na-uel"><i class="fa fa-check"></i><b>16.1.2</b> Amparos e apoios na UEL</a></li>
<li class="chapter" data-level="16.1.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#tutoriais-para-os-estudantes-da-gradua%C3%A7%C3%A3o-da-uel"><i class="fa fa-check"></i><b>16.1.3</b> Tutoriais para os estudantes da graduação da UEL</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#programas-de-atividade-acad%C3%AAmica"><i class="fa fa-check"></i><b>16.2</b> Programas de atividade acadêmica</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#geografia-1sta004---estat%C3%ADstica-aplicada-%C3%A0-geografia"><i class="fa fa-check"></i><b>16.2.1</b> Geografia: 1STA004 - Estatística Aplicada à Geografia</a></li>
<li class="chapter" data-level="16.2.2" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#qu%C3%ADmica-2sta032---estat%C3%ADstica"><i class="fa fa-check"></i><b>16.2.2</b> Química: 2STA032 - Estatística</a></li>
<li class="chapter" data-level="16.2.3" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#farm%C3%A1cia-2sta010---elementos-de-bioestat%C3%ADstica"><i class="fa fa-check"></i><b>16.2.3</b> Farmácia: 2STA010 - Elementos de bioestatística</a></li>
<li class="chapter" data-level="16.2.4" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#computa%C3%A7%C3%A3o-2sta030---estat%C3%ADstica"><i class="fa fa-check"></i><b>16.2.4</b> Computação: 2STA030 - Estatística</a></li>
<li class="chapter" data-level="16.2.5" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#engenharia-civil-2sta016---estat%C3%ADstica-e-probabilidades-202502"><i class="fa fa-check"></i><b>16.2.5</b> Engenharia Civil: 2STA016 - Estatística e probabilidades (2025/02)</a></li>
<li class="chapter" data-level="16.2.6" data-path="12-correlacao_e_regressao_linear_simples.html"><a href="#ci%C3%AAncia-de-dados-e-intelig%C3%AAncia-artifical-2sta011---probabilidade"><i class="fa fa-check"></i><b>16.2.6</b> Ciência de dados e Inteligência Artifical: 2STA011 - Probabilidade</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://fjrcosta.github.io/apostila/" target="blank">FJCosta Github</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"><div class="line-block">UNIVERSIDADE ESTADUAL DE LONDRINA<br />
CCE - Centro de Ciências Exatas<br />
DSTA - Departamento de Estatística (sala 11)<br />
Prof. M.e Eng.<span class="math inline">\(^{o}\)</span> Felinto Junior Da Costa<br />
<a href="mailto:fjcosta@uel.br" class="email">fjcosta@uel.br</a></div></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Capítulo 12</span> Introdução à Correlação Linear de Pearson e Regressão Linear Simples<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><br></p>
<hr />
<figure class="image">
<img src="images12/teaser.jpg" alt="Figure" width="35%" height="auto" style="display: block; margin:auto">
<figcaption style="font-size: 20px;">
<blockquote>
“Essentially, all models are wrong,but some are useful […]” (George Edward Pelham Box, 1919 - 2013)
</figcaption>
</figure>
</blockquote>
<hr />
<div id="contexto-histórico" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Contexto histórico<a href="#contexto-hist%C3%B3rico" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<figure class="image">
<img src="images12/Francis_Galton.png" alt="Figure" width="30%" height="auto" style="display: block; margin: auto;">
<figcaption style="font-size: 20px;">
<blockquote>
Sir Francis Galton (1822-1911), antropólogo e meteorologista inglês, propôs no artigo escrito em conjunto com J. D. Hamilton Dickson (<em>Family Likeness in Stature</em>) apresentado à <em>Royal Society of London</em> em 21 de janeiro de 1886, expressar por uma função uma relação que observou entre estaturas de pais e seus filhos e descendentes.
</figcaption>
</figure>
</blockquote>
<p><br></p>
<p>Nesse artigo, Galton verificou que, embora houvesse uma tendência de que pais mais altos tivessem filhos altos (e pais mais baixos, filhos mais baixos), a estatura média de crianças nascidas de pais com dada altura tendia a <strong>regredir</strong> à altura média da população como um todo. Nas palavras de Galton isso seria uma <strong>regressão à mediocridade</strong>: pais mais altos que a estatura média têm filhos mais baixos que eles</p>
<p><br></p>
<blockquote>
<p>“Each peculiarity in a man is shared by his kinsman but, on the average, in a less degree[…] (Cada peculiaridade em um homem é compartilhada por seus parentes, mas, em média, em menor grau[…]-trad. livre)”</p>
</blockquote>
<p><br></p>
<figure class="image">
<img src="images12/pearson_reg.png" alt="Figure" width="40%" height="auto" style="display: block; margin: auto;">
<figcaption style="font-size: 20px;">
<blockquote>
A <em>Lei da Regressão</em> de Galton foi referendada por Karl Pearson (<em>On the Laws of Inheritance</em>, 1903) poucos anos depois, quando analisou os dados de milhares de registros de estatura, tamanho do antebraço e da palma.
</figcaption>
</figure>
</blockquote>
<p><br></p>
<p>Em latim o prefixo <em>co</em> remete ao significado <em>colaboração</em> , <em>união</em> ou até <em>simultaneidade</em>. Correlação significa, portanto, uma relação mútua entre dois termos, uma correspondência.</p>
<blockquote>
<p>Em <em>Correlations and their Measurement, chiefly from Anthropometric Data</em>, apresentado à <em>Royal Society of London</em> em dezembro de 1888, ele observou aquilo que viria a conceituar como <em>co-relação</em> ou <em>correlação de estrutura</em>.</p>
</blockquote>
<blockquote>
<p>Galton afirmou ao analisar o tamanho do braço com o da perna de um indivíduo que que dois órgãos são ditos serem correlacionados quando a variação de um é acompanhada, na média, pela variação para mais ou menos do outro:</p>
</blockquote>
<ul>
<li>se a correlação fosse alta, uma pessoa com um braço longo teria também uma perna longa;</li>
<li>se a correlação fosse moderada, o comprimento da perna não seria tão longo e,</li>
<li>se não houvesse correlação, o comprimento de sua perna seria o comprimento médio desse membro na população.</li>
</ul>
<p><br></p>
<figure class="image">
<img src="images12/correlacao.png" alt="Figure" width="35%" height="auto" style="display: block; margin: auto;">
<figcaption style="font-size: 20px;">
<blockquote>
“…Assim, ele naturalmente atingiu uma linha de regressão reta com variabilidade constante para todas as matrizes de um caractere para um dado caractere de um segundo. Talvez fosse melhor para o progresso do cálculo correlacional que este simples caso especial fosse exposto primeiro: é tão facilmente compreendido pelo iniciante[…]”
</figcaption>
</figure>
</blockquote>
<hr />
<p><br></p>
<figure class="image">
<img src="images12/gauss.png" alt="Figure" width="30%" height="auto" style="display: block; margin: auto;">
<figcaption style="font-size: 20px;">
<blockquote>
Houve um momento que Johann Carl Friedrich Gauss considerou sua descoberta (1795) da regressão estatística como “trivial”. O método dos mínimos quadrados parecia tão óbvio para Carl Friedrich Gauss que ele imaginou não ter sido o primeiro a usá-lo. Ele não declarou publicamente sua descoberta até alguns anos depois ( <em>Theoria motus corporum coelestium in sectionibus conicis solem ambientium</em>, 1809), quando seu contemporâneo Adrien-Marie Legendre ( <em>Nouvelles méthodes pour la détermination des orbites des comètes</em>, 1805) publicou o método. Quando Gauss sugeriu que ele o havia usado antes deu-se partida a uma das mais famosas disputas de antecedência na história da ciência. Gauss acabaria recebendo a maior parte do crédito como fundador da regressão, mas não sem uma briga.
</figcaption>
</figure>
</blockquote>
<hr />
<p><br></p>
</div>
<div id="conceitos-1" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Conceitos<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#conceitos-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p>Em estatística, a expressão <em>correlação</em> faz referência à relação existente entre variáveis, digamos <em>X</em> e <em>Y</em> que pode assumir diferentes padrões: linear ou não linear (quadrática, cúbica, exponencial …).</p>
<p>A <em>autocorrelação</em> refere-se à correlação de uma série temporal consigo mesma em diferentes defasagens temporais (<em>lags</em>). Formalmente, para uma série temporal <span class="math inline">\(X_t\)</span>, a autocorrelação de ordem <span class="math inline">\(k\)</span> é definida como a correlação entre <span class="math inline">\(X_t\)</span> e <span class="math inline">\(X_{t-k}\)</span>, medindo a dependência linear entre observações separadas por <span class="math inline">\(k\)</span> períodos de tempo ou unidades espaciais.</p>
<hr />
<div id="correlação-linear-versus-regressão" class="section level3 hasAnchor" number="12.2.1">
<h3><span class="header-section-number">12.2.1</span> Correlação linear <em>versus</em> regressão<a href="#correla%C3%A7%C3%A3o-linear-versus-regress%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<blockquote>
<p>a análise de correlação tem como principal objetivo medir a força ou o grau de associação linear entre as duas variáveis.</p>
</blockquote>
<blockquote>
<p>na análise de regressão linear o objetivo primário é expressar matematicamente uma relação linear entre duas variáveis de modo a possibilitar obter estimativas de uma para um valor não amostrado da outra, contruir intervalos de confiança para essas estimativas e testar variadas hipóteses.</p>
</blockquote>
<hr />
</div>
<div id="correlação-versus-causação" class="section level3 hasAnchor" number="12.2.2">
<h3><span class="header-section-number">12.2.2</span> Correlação <em>versus</em> causação<a href="#correla%C3%A7%C3%A3o-versus-causa%C3%A7%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Embora a análise de regressão lide com o comportamento de uma variável em relação a outra(s), isso não implica necessariamente em causação. É preciso levar em conta que uma relação estatística <em>por si só</em> não implica logicamente uma causação. Para atribuir uma relação de causação deve-se lançar mão de considerações <em>a priori</em> ou teóricas.</p>
<blockquote>
<p>Considerem a correlação existente entre a altura dos alunos de 6 a 17 anos e as notas médias anuais obtidas em matemática. Naturalmente não é o incremento que os alunos sofrem em suas alturas na fase de crescimento que causa a melhora nas notas; mas sim processos biológicos e comportamentais que resultam em melhorias na capacidade cognitiva.</p>
</blockquote>
<hr />
</div>
</div>
<div id="diagrama-de-dispersão" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> Diagrama de dispersão<a href="#diagrama-de-dispers%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<figure class="image">
<img src="images12/scatter.png" alt="Figure" width="55%" height="auto" style="display: block; margin: auto;">
<figcaption style="font-size: 20px;">
<blockquote>
Descrito pela primeira vez por Francis Galton ( <em>Regression Towards Mediocrity in Hereditary Stature</em> , 1886), os diagramas de dispersão ( <em>scatterplot</em> ) ou gráficos de dispersão são representações de dados de duas (tipicamente) ou mais variáveis que são organizadas em um gráfico. O gráfico de dispersão utiliza coordenadas cartesianas para exibir valores de um conjunto de dados. Os dados são exibidos como uma coleção de pontos, cada um com o valor de uma variável determinando a posição no eixo horizontal e o valor da outra variável determinando a posição no eixo vertical (em caso de duas variáveis).
</figcaption>
</figure>
</blockquote>
<p><br></p>
<p>Considerem as simulações da dispersão de alguns valores de duas variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. Vemos que em alguns casos nos parece ser razoável tentar exprimir qualquer tipo de relação entre os valores de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>; todavia, há situações onde claramente vemos alguma forma de relação.</p>
<p>Essas formas bem poderiam ser expressas, aproximadamente, por diferentes funções como:</p>
<ul>
<li>lineares (retas) ou</li>
<li>não lineares (curvas).</li>
</ul>
<p>Vemos também que essas formas de associação entre os valores de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> podem ser diretas ou inversamente proporcionais (“positiva” ou “negativa”). Estamos particularmente interessados em quantificar o grau da relação dos valores de <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> nos padrões lineares. (SIMULADOR 1)</p>
<hr />
</div>
<div id="coeficiente-de-correlação-linear-de-pearson" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Coeficiente de correlação linear de Pearson<a href="#coeficiente-de-correla%C3%A7%C3%A3o-linear-de-pearson" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<blockquote>
<p>O coeficiente de correlação linear (ou coeficiente de correlação produto momento de <em>Pearson</em>) expressa a medida da intensidade da associação <strong>linear</strong> entre duas variáveis.</p>
</blockquote>
<p><br></p>
<figure class="image">
<img src="images12/ro_r.png" alt="Figure" width="100%" height="auto" style="display: block; margin: auto;">
</figure>
<figcaption style="font-size: 20px;">
A notação adotada para o coeficiente de correlação linear de Pearson depende dos dados analisados: se são dados amostrais ou populacionais:
- população: pela letra grega <span class="math inline">\(\rho\)</span> (“rô”)
- amostra: pela letra latina <em>r</em>
</figcaption>
<hr />
<p><br></p>
<p>Trabalhando-se com dados de uma amostra, o estimador da correlação linear populacional <span class="math inline">\(\rho\)</span> é:</p>
<p><br></p>
<p><span class="math display">\[r  =  \frac{\sum _{i=1}^{n}{x}_{i} \cdot {y}_{i} - \frac{\sum _{i=1}^{n}{x}_{i}\sum _{i=1}^{n}{y}_{i}}{n}}{\sqrt{\left(\sum _{i=1}^{n}{x}_{i}^{2}-\frac{{\left(\sum _{i=1}^{n}{x}_{i}\right)}^{2}}{n}\right)\cdot \left[\sum_{i=1}^{n}{y}_{i}^{2}-\frac{{\left(\sum _{i=1}^{n}{y}_{i}\right)}^{2}}{n}\right]}},\]</span></p>
<p>em que <span class="math inline">\(x_{i}\)</span>: é o iésimo valor observado da variável <em>X</em>, <span class="math inline">\(y_{i}\)</span>: é o iésimo valor observado da variável <em>Y</em>, <span class="math inline">\(n\)</span> é o número de pares de valores observados.</p>
<p><br></p>
<p><strong>Observação:</strong> Equivalente à expressão:</p>
<p><br></p>
<p><span class="math display">\[r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2 \cdot \sum_{i=1}^{n}(y_i - \bar{y})^2}}.\]</span></p>
<p><br></p>
<p>Ou, simplificadamente:</p>
<p><br></p>
<p><span class="math display">\[
r = \frac{{S}_{xy}}{\sqrt{{S}_{xx}\cdot {S}_{yy}}}
\]</span></p>
<p><br></p>
<p>em que <span class="math inline">\(S_{xy} = \sum _{i=1}^{n} x_{i}y_{i}\)</span> - <span class="math inline">\(\frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n}\)</span>, <span class="math inline">\(S_{xx} = \sum _{i=1}^{n} x_{i}^{2}\)</span> - <span class="math inline">\(\frac{(\sum _{i=1}^{n} x_{i})^{2}}{n}\)</span>, <span class="math inline">\({S}_{yy}=\sum _{i=1}^{n}y_{i}^{2}\)</span> - <span class="math inline">\(\frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}\)</span> e <span class="math inline">\(n\)</span> é o número de pares de valores observados.</p>
<hr />
<p>O cálculo do coeficiente de correlação linear de Pearson assemelha-se a uma <em>análise de variância</em></p>
<p><br></p>
<figure class="image">
<img src="images12/var_regressao.png" alt="Figure" width="65%" height="auto" style="display: block; margin: auto;">
</figure>
<p><br></p>
<p>Vejamos:</p>
<p><br></p>
<p><span class="math display">\[
y - \stackrel{-}{y} = (\hat{y} - \stackrel{-}{y})  + (y - \hat{y}).
\]</span></p>
<p><br></p>
<p>Elevando-se ao quadrado ambos os termos, para todos os valores observados, teremos:</p>
<p><br></p>
<p><span class="math display">\[
\sum _{i=1}^{n} ({y_{i}} - \stackrel{-}{y_{i}})^{2} =
\sum _{i=1}^{n} (\hat{y_{i}} - \stackrel{-}{y_{i}})^{2}   +
\sum _{i=1}^{n} (y_{i} - \hat{y_{i}})^{2}
\]</span></p>
<p><br></p>
<p>A quantidade à esquerda mede a variação total dos <em>y</em> (<em>Soma de quadrados total</em>) e as quantidades à direita são a <em>Soma de quadrados da regressão</em> e a <em>Soma de quadrados dos resíduos</em>.</p>
<p><br></p>
<p>A definição abaixo de <span class="math inline">\(r\)</span> exprime é <em>fração da variação total</em> dos <span class="math inline">\(y\)</span> que está sendo explicada por sua <em>regressão linear</em> com <span class="math inline">\(x\)</span>.</p>
<p><br></p>
<p><span class="math display">\[
r=\sqrt{\frac{\sum _{i=1}^{n} (\hat{y_{i}} - \stackrel{-}{y_{i}})^{2}}{\sum _{i=1}^{n} ({y_{i}} - \stackrel{-}{y_{i}})^{2}}}.
\]</span></p>
<hr />
<p>Observações:</p>
<ul>
<li><p>a faixa de variação do coeficiente de correlação linear de Pearson é: <span class="math inline">\(-1 \le r \le 1\)</span>,</p></li>
<li><p>a correlação linear observada entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> é simétrica; ou seja, é a mesma que se medida entre as variáveis <span class="math inline">\(Y\)</span> e <span class="math inline">\(X\)</span>,</p></li>
<li><p>mede apenas a associação linear entre duas variáveis e, portanto, não tem sentido usá-lo na quantificação de relações que não sejam lineares,</p></li>
<li><p>a possibilidade de uma <strong>correlação linear negativa</strong> virá do resultado do <em>numerador</em> (<span class="math inline">\(S_{xy}\)</span>), pois no denominador temos duas somas de quadrados,</p></li>
<li><p>o coeficiente de correlação mede apenas a <strong>intensidade</strong> das relações lineares entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> e não estabelece <em>per si</em> nenhuma relação de causação.</p></li>
</ul>
<p>Se <span class="math inline">\(r \approx 0\)</span>, não há evidência de relação linear entre as variáveis na amostra observada. Neste caso, variações em uma variável não estão linearmente associadas a variações sistemáticas na outra.</p>
<p>Se <span class="math inline">\(r \neq 0\)</span>, há evidência de relação linear entre as variáveis, cuja direção e intensidade são determinadas pelo sinal e magnitude de <span class="math inline">\(r\)</span>:</p>
<p>-quando <span class="math inline">\(r &gt; 0\)</span>, a relação linear é : incrementos em uma variável tendem a ser acompanhados por incrementos na outra, e decréscimos em uma variável tendem a ser acompanhados por decréscimos na outra;<br />
-quando <span class="math inline">\(r &lt; 0\)</span>, a relação linear é : incrementos em uma variável tendem a ser acompanhados por decréscimos na outra, e vice-versa.</p>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 1: Um jornal deseja verificar a eficácia de seus anúncios na venda de carros usados e para isso realizou um levantamento de todos os seus anúncios e informações dos resultados obtidos pelas empresas que o contrataram e dele extraiu uma pequena amostra. A tabela a seguir mostra o número de anúncios e o correspondente número de veículos vendidos por 6 companhias que usaram apenas este jornal como veículo de propaganda. Existe alguma relação linear entre as variáveis? Construa o diagrama de dispersão e calcule o coeficiente de correlação linear.</p>
</blockquote>
<center>
<div class="small-equation80">
<table>
<caption>
Quadro de dados da quantidade de carros vendidos por 6 empresas
distintas pela quantidade de anúncios feitos
</caption>
<thead>
<tr>
<th style="text-align: center;">
Companhia
</th>
<th style="text-align: center;">
Anúncios feitos (X)
</th>
<th style="text-align: center;">
Carros vendidos (Y)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
A
</td>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
</tr>
<tr>
<td style="text-align: center;">
B
</td>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
</tr>
<tr>
<td style="text-align: center;">
C
</td>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
</tr>
<tr>
<td style="text-align: center;">
D
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
</tr>
<tr>
<td style="text-align: center;">
E
</td>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
</tr>
<tr>
<td style="text-align: center;">
F
</td>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
</tr>
</tbody>
</table>
</div>
</center>
<p><br></p>
<p><img src="apostila_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
<table>
<caption>
Quadro para cálculo do coeficiente de correlação linear
(<span class="math inline">\(r\)</span>)
</caption>
<thead>
<tr>
<th style="text-align: center;">
Companhia
</th>
<th style="text-align: center;">
Anúncios (X)
</th>
<th style="text-align: center;">
Carros vendidos (Y)
</th>
<th style="text-align: center;">
<span
class="math inline"><em>x</em><sub><em>i</em></sub> * <em>y</em><sub><em>i</em></sub></span>
</th>
<th style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>i</em></sub><sup>2</sup></span>
</th>
<th style="text-align: center;">
<span class="math inline"><em>y</em><sub><em>i</em></sub><sup>2</sup></span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
A
</td>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
<td style="text-align: center;">
10286
</td>
<td style="text-align: center;">
5476
</td>
<td style="text-align: center;">
19321
</td>
</tr>
<tr>
<td style="text-align: center;">
B
</td>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
<td style="text-align: center;">
4860
</td>
<td style="text-align: center;">
2025
</td>
<td style="text-align: center;">
11664
</td>
</tr>
<tr>
<td style="text-align: center;">
C
</td>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
<td style="text-align: center;">
4704
</td>
<td style="text-align: center;">
2304
</td>
<td style="text-align: center;">
9604
</td>
</tr>
<tr>
<td style="text-align: center;">
D
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
<td style="text-align: center;">
2736
</td>
<td style="text-align: center;">
1296
</td>
<td style="text-align: center;">
5776
</td>
</tr>
<tr>
<td style="text-align: center;">
E
</td>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
<td style="text-align: center;">
1674
</td>
<td style="text-align: center;">
729
</td>
<td style="text-align: center;">
3844
</td>
</tr>
<tr>
<td style="text-align: center;">
F
</td>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
<td style="text-align: center;">
912
</td>
<td style="text-align: center;">
256
</td>
<td style="text-align: center;">
3249
</td>
</tr>
<tr>
<td style="text-align: center;">
Totais
</td>
<td style="text-align: center;">
246
</td>
<td style="text-align: center;">
540
</td>
<td style="text-align: center;">
25172
</td>
<td style="text-align: center;">
12086
</td>
<td style="text-align: center;">
53458
</td>
</tr>
</tbody>
</table>
<hr />
<p>Sendo <span class="math inline">\(n= 6\)</span> temos:</p>
<p><span class="math display">\[
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n} = 25172 - \frac{246 \cdot 540}{6} = 3032\\
S_{xx} = \sum _{i=1}^{n} x_{i}^{2} - \frac{(\sum _{i=1}^{n} x_{i})^{2}}{n} = 12086 - \frac{246^2}{6} = 2000\\
{S}_{yy} = \sum _{i=1}^{n}y_{i}^{2} - \frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}=   53458 - \frac{540^2}{6} = 4858
\]</span></p>
<p>Portanto:</p>
<p><span class="math display">\[
r = \frac{{s}_{xy}}{\sqrt{{s}_{xx}\cdot {s}_{yy}}} = \frac{3032}{\sqrt{2000 \cdot 4858}} = 0,9727
\]</span></p>
<hr />
<p><br></p>
</div>
<div id="teste-de-hipóteses-para-a-correlação-linear-na-população" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> Teste de hipóteses para a correlação linear na população<a href="#teste-de-hip%C3%B3teses-para-a-correla%C3%A7%C3%A3o-linear-na-popula%C3%A7%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<blockquote>
<p>O coeficiente de correlação populacional <span class="math inline">\(\rho\)</span> sempre é estimado a partir do coeficiente de correlação amostral <span class="math inline">\(r\)</span>. Para se realizar inferências concernentes a <span class="math inline">\(\rho\)</span> a partir de <span class="math inline">\(r\)</span> temos que ter o conhecimento da distribuição amostral dos coeficientes de correlação linear <span class="math inline">\(r\)</span>.</p>
</blockquote>
<p><br></p>
<p>Para se testar a existência de correlação na população um teste de hipóteses na estrutura seguinte (bilateral) pode ser proposto:</p>
<p><br></p>
<p><span class="math display">\[
\begin{cases}
    H_{0}:\rho = 0 \hspace{0.1cm} \text{, ie. a correlação linear entre X e Y é nula} \\
    H_{1}:\rho \ne 0 \hspace{0.1cm} \text{, ie. a correlação linear entre X e Y não é nula} \\
\end{cases}
\]</span></p>
<hr />
<p>Lembrando a tradicional analogia de que um <em>teste de hipóteses</em> guarda uma certa semelhança a um julgamento: caso não haja indício forte o suficiente para comprovar a culpa do acusado ele é tecnicamente declarado <em>não culpado</em> (e não <em>inocente</em>).</p>
<p>Seguindo esse raciocínio, o <em>indício ou evidência</em> que nos permitirá rejeitar a hipótese nula virá de uma <em>evidência amostral</em> e a <em>significância</em> dessa <em>evidência amostral</em> será calculada a partir da estatística (<span class="math inline">\({t}_{calc}\)</span>), que considera o o coeficiente de correlação amostral <span class="math inline">\(r\)</span> e o tamanho da amostra <span class="math inline">\(n\)</span> e a comparação de seu valor a um valor limite de uma distribuição de probabilidade chamada t de Student (<span class="math inline">\(t_{tab}\)</span>), adequada para a variável aleatória <span class="math inline">\(r\)</span>:</p>
<p><br></p>
<p><span class="math display">\[
{t}_{calc}=\frac{r\cdot\sqrt{n-2}}{\sqrt{1-{r}^{2}}}\\
T \sim t_{(n-2)}
\]</span></p>
<p><br></p>
<p><strong>Pressuposto importante:</strong> Para que o teste de correlação de Pearson seja <strong>exato</strong>, a distribuição bivariada <span class="math inline">\((X,Y)\)</span> deve seguir uma distribuição normal bivariada. No entanto, o teste é razoavelmente robusto a violações deste pressuposto quando o tamanho amostral é grande (n&gt;30). Para amostras pequenas ou quando há forte evidência de não-normalidade, alternativas não-paramétricas como o coeficiente de correlação de Spearman devem ser consideradas.</p>
<p><br></p>
<p><img src="apostila_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" />
<br></p>
<p><strong>Rejeita-se a hipótese nula</strong> (<span class="math inline">\(H_{0}:\rho = 0 \hspace{0.1cm} \text{, ie. a correlação linear entre X e Y é nula}\)</span>) se o valor da estatística calculada for tão extremo que se verifique:</p>
<blockquote>
<p>br&gt;</p>
</blockquote>
<p><span class="math display">\[
t_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]}\\
\text{ou}\\
t_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}\\
\]</span>
<br></p>
<p>ou, equivalentemente, <span class="math inline">\(|t_{calc}| \ge {t}_{tab\left[1-\frac{\alpha}{2};\left(n-2\right)\right]}\)</span>, em que <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao <em>nível de significância</em> pretendido (<span class="math inline">\(\alpha\)</span>) com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se individualizadas por nível de significância e graus de liberdade.</p>
<hr />
<p>As curvas da família “t” possuem simetria em relação a um eixo vertical no valor de máxima densidade. O valor tabelado dessa estatística acha-se associado à área sob ela pois é uma função densidade de probabilidade: a totalidade da área sob essa curva é igual a 1 (probabilidade de 100%)</p>
<p>Assim, se consultarmos em uma tabela o valor “t” para um nível de significância <span class="math inline">\(\alpha\)</span> qualquer, correspodente assim a um nível de confiança de (<span class="math inline">\(1-\alpha\)</span>), qualquer veremos que ele será igual, <em>em módulo</em>, ao valor “t” no outro extremo dessa curva.</p>
<p>Por essa razão muitas tabelas apresentam valores dessa estatística sob os títulos de <em>monocaudal</em> ou <em>bicaudal</em> pois estão apresentando os valores para um determinado nível de significância (<span class="math inline">\(\alpha\)</span>): área sob a curva, situado apenas em um lado (ou <em>subdividido</em> nos dois ramos da curva nas tabelas chamadas “bilaterais”).</p>
<p>O teste de hipótese que iremos realizar é um <em>teste bilateral</em>; assim, o gráfico apropriado para se decidir pela rejeição ou não da hipótese nula assume a forma mostrada nessa simulação. (SIMULADOR 2 COM t)</p>
<hr />
<div id="outros-testes-de-hipóteses-sobre-a-correlação-linear-na-população" class="section level3 hasAnchor" number="12.5.1">
<h3><span class="header-section-number">12.5.1</span> Outros testes de hipóteses sobre a correlação linear na população<a href="#outros-testes-de-hip%C3%B3teses-sobre-a-correla%C3%A7%C3%A3o-linear-na-popula%C3%A7%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Outros tipos de testes só podem ser realizados através da estatística <span class="math inline">\(\zeta\)</span> (zeta) de Fisher. A transformação <span class="math inline">\(Z\)</span> proposta por Fisher produz uma estatística que possui distribuição aproximadamente Normal. Para essa situação a estatística a ser utilizada é dada por:</p>
<p><span class="math display">\[
\zeta = \frac{1}{2}\ln\frac{(1+r)}{(1-r)}
\]</span></p>
<p>que possui uma distribuição aproximadamente Normal, com média e desvio padrão:</p>
<p><span class="math display">\[
\mu_{\zeta} =  \frac{1}{2}\ln\frac{(1+\rho_{0})}{(1-\rho_{0})} \text{    e    }
\sigma_{\zeta} = \frac{1}{\sqrt{n-3}}
\]</span></p>
<p>Transformando-se <span class="math inline">\(\zeta\)</span> em unidades padrão (pela subtração de <span class="math inline">\(\mu_{\zeta}\)</span> e divisão por <span class="math inline">\(\sigma_{\zeta}\)</span>), chega-se à estatística tabelada:</p>
<p><span class="math display">\[z = \frac{\zeta - \mu_{\zeta}}{\sigma_{\zeta}} = (\zeta - \mu_{\zeta}) \cdot \sqrt{n-3}\]</span></p>
<p>que, sob <span class="math inline">\(H_0: \rho = \rho_0\)</span>, segue aproximadamente uma distribuição Normal padrão <span class="math inline">\(N(0,1)\)</span>.</p>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 2: Faça o teste de hipóteses para a correlação linear <span class="math inline">\(\rho\)</span> a partir da correlação amostral <span class="math inline">\(r\)</span> calculada no exercício dos anúncios de veículos, sob um nível de significância (<span class="math inline">\(\alpha\)</span>) de 0,05.</p>
</blockquote>
<p>No exercício referido obtivemos um valor para a correlação linear de Pearson de <span class="math inline">\(r=0,9727\)</span>. A partir desse valor podemos calcular o valor de nossa estatística <span class="math inline">\({t}_{calc}\)</span> para o teste:</p>
<p><span class="math display">\[
{t}_{calc}=\frac{r\cdot\sqrt{n-2}}{\sqrt{1-{r}^{2}}} = 8,38
\]</span></p>
<p>Rejeitaremos a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se:</p>
<p><span class="math display">\[
t_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]}\\
\text{ou}\\
t_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}
\]</span></p>
<p>Da tabela extraímos o valor de nossa estatística de comparação a um nível de significância <span class="math inline">\(\alpha=5\%\)</span> e, para um tamanho amostral <span class="math inline">\(n=6\)</span>, temos como graus de liberdade <span class="math inline">\(n-2=4\)</span> (<span class="math inline">\(t_{tab}=2,776\)</span>).
Vê-se que o valor calculado da estatística “t” encontra-se além dos limites estabelecidos pela estatística de comparação (<span class="math inline">\(t_{tab}\)</span>) para um nível de significância de <span class="math inline">\(\alpha=5\%\)</span>. (SIMULADOR 2 COM t)</p>
<p><br></p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#cb1-1" tabindex="-1"></a><span class="co"># Dados do Exemplo 1</span></span>
<span id="cb1-2"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#cb1-2" tabindex="-1"></a>anuncios <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">74</span>, <span class="dv">45</span>, <span class="dv">48</span>, <span class="dv">36</span>, <span class="dv">27</span>, <span class="dv">16</span>)</span>
<span id="cb1-3"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#cb1-3" tabindex="-1"></a>carros_vendidos <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">139</span>, <span class="dv">108</span>, <span class="dv">98</span>, <span class="dv">76</span>, <span class="dv">62</span>, <span class="dv">57</span>)</span>
<span id="cb1-4"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#cb1-4" tabindex="-1"></a><span class="co"># Teste usando função nativa do R (para comparação)</span></span>
<span id="cb1-5"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#cb1-5" tabindex="-1"></a>teste <span class="ot">&lt;-</span> <span class="fu">cor.test</span>(anuncios, carros_vendidos)</span>
<span id="cb1-6"><a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#cb1-6" tabindex="-1"></a><span class="fu">print</span>(teste)</span></code></pre></div>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  anuncios and carros_vendidos
## t = 8.3853, df = 4, p-value = 0.001107
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7652742 0.9971267
## sample estimates:
##       cor 
## 0.9727146</code></pre>
<hr />
<p><br></p>
</div>
</div>
<div id="regressão-linear-simples" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> Regressão linear simples<a href="#regress%C3%A3o-linear-simples" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<div id="introdução" class="section level3 hasAnchor" number="12.6.1">
<h3><span class="header-section-number">12.6.1</span> Introdução<a href="#introdu%C3%A7%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Considerem a proposição de John Maynard Keynes para a relação entre o consumo e a renda, onde ele postulava haver uma relação positiva entre ambos: uma mudança em uma das variáveis iria alterar a outra. Seu modelo funcional para essa relação, com <span class="math inline">\(Y\)</span> sendo as despesas de consumo e <span class="math inline">\(X\)</span> a renda, é:</p>
<p><span class="math display">\[
Y = \alpha + \beta \cdot X
\]</span></p>
<p>Esse modelo admite que a verdadeira relação entre <span class="math inline">\(Y\)</span> e <span class="math inline">\(X\)</span> seja uma linha reta e que a observação <span class="math inline">\(Y\)</span> para cada nível de <span class="math inline">\(X\)</span> seja uma variável aleatória. Assim, o valor esperado de <span class="math inline">\(Y\)</span> para cada valor de <span class="math inline">\(X\)</span> é:</p>
<p><span class="math display">\[
E(Y | X) = \alpha + \beta \cdot X
\]</span></p>
<p>É um modelo puramente teórico, de limitada aplicabilidade prática, pois pretende exprimir por uma relação exata (<em>determinística</em>) o consumo e a renda, quando se sabe que grande parte das relações entre duas variáveis não são exatas.</p>
<p>Ao se fixar um único valor para a variável explicativa, observa-se que há flutuações nos valores observados da variável explicada. Essa inexatidão, esse desvio do valor observado <span class="math inline">\(Y_i\)</span> em relação ao seu valor esperado, pode ser expresso da seguinte maneira:</p>
<p><span class="math display">\[
\varepsilon_i = Y_i - E(Y | X_i)
\]</span></p>
<p>de modo que o modelo completo pode ser expresso como:</p>
<p><span class="math display">\[
Y_i = E(Y | X_i) + \varepsilon_i = \alpha + \beta \cdot X_i + \varepsilon_i
\]</span></p>
<p>Nesse modelo, os componentes são:</p>
<ul>
<li><span class="math inline">\(\alpha\)</span>: intercepto da reta, representando o valor esperado de <span class="math inline">\(Y\)</span> quando <span class="math inline">\(X = 0\)</span> (no contexto de Keynes, um consumo mínimo observado mesmo quando a renda é nula, em razão de programas de assistência governamental).</li>
<li><span class="math inline">\(\beta\)</span>: inclinação da reta, representando a variação esperada de <span class="math inline">\(Y\)</span> para um aumento unitário em <span class="math inline">\(X\)</span> (a propensão marginal a consumir: <span class="math inline">\(\frac{\Delta C}{\Delta Y}\)</span>).</li>
<li><span class="math inline">\(E(Y | X_i) = \alpha + \beta \cdot X_i\)</span>: componente sistemático ou determinístico, representando o gasto médio de todas as famílias com um mesmo nível de renda.</li>
<li><span class="math inline">\(\varepsilon_i\)</span>: termo de erro ou distúrbio estocástico, admitido como substituto para todas as demais variáveis omitidas ou negligenciadas no modelo e que podem afetar <span class="math inline">\(Y\)</span>.</li>
</ul>
<hr />
</div>
<div id="linearidade-nos-parâmetros" class="section level3 hasAnchor" number="12.6.2">
<h3><span class="header-section-number">12.6.2</span> Linearidade nos parâmetros<a href="#linearidade-nos-par%C3%A2metros" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Um modelo de regressão pode ser linear nas variáveis ou nos parâmetros. A linearidade nos parâmetros é a relevante para a formulação da teoria da regressão.</p>
<p>Uma função é <strong>linear nos parâmetros</strong> se pode ser expressa como uma combinação linear dos parâmetros, onde nenhum parâmetro está elevado a uma potência ou multiplicado por outro parâmetro.</p>
<p><strong>Exemplos de modelos lineares nos parâmetros:</strong></p>
<ul>
<li><span class="math inline">\(Y = \alpha + \beta X^2\)</span> (linear nos parâmetros, não linear em <span class="math inline">\(X\)</span>)</li>
<li><span class="math inline">\(Y = \alpha + \beta \ln(X)\)</span></li>
<li><span class="math inline">\(Y = \alpha + \beta_1 X + \beta_2 X^2\)</span></li>
</ul>
<p><strong>Exemplos de modelos NÃO lineares nos parâmetros:</strong></p>
<ul>
<li><span class="math inline">\(Y = \alpha e^{\beta X}\)</span></li>
<li><span class="math inline">\(Y = \alpha X^{\beta}\)</span></li>
</ul>
<p>No contexto deste curso, o modelo será linear tanto nos parâmetros quanto na variável.</p>
<hr />
</div>
<div id="nomenclatura" class="section level3 hasAnchor" number="12.6.3">
<h3><span class="header-section-number">12.6.3</span> Nomenclatura<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#nomenclatura" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Nessa função:</p>
<ul>
<li><span class="math inline">\(Y\)</span>: variável dependente (ou explicada, resposta, endógena) — aqui, representando o consumo.</li>
<li><span class="math inline">\(X\)</span>: variável independente (ou explicativa, preditora, exógena) — aqui, representando a renda.</li>
</ul>
<hr />
<p>Se o termo de erro <span class="math inline">\(\varepsilon_i\)</span> representa todas aquelas variáveis omitidas no modelo (mas que, coletivamente, afetam <span class="math inline">\(Y\)</span>), <strong>por que não formular um modelo de regressão com o máximo de variáveis possíveis?</strong></p>
<p><br></p>
<ul>
<li><strong>Embasamento teórico vago</strong>: A teoria existente suporta com certeza apenas algumas variáveis; o termo de erro <span class="math inline">\(\varepsilon_i\)</span> serve como um substituto para todas as variáveis excluídas no modelo.</li>
<li><strong>Princípio da parcimônia</strong>: Um modelo mais simples que explique bem a relação é preferível.</li>
<li><strong>Forma funcional equivocada</strong>: Em gráficos de dispersão, é mais fácil inferir a relação entre duas variáveis do que com muitas.</li>
<li><strong>Limitação na quantidade de observações</strong>: Muitas variáveis exigem mais observações para garantir a precisão do modelo.</li>
</ul>
<hr />
<p><br></p>
<p>Sendo inviável (muitas vezes impossível) impossível observar toda a população e construir um <em>modelo populacional</em>, focamos o estudo em uma parte observada dessa população: uma <em>amostra</em>. Um modelo funcional estimado com base em uma <em>amostra</em> apresenta <strong>estimativas</strong> dos parâmetros da função que descreve a população de origem (os quais são desconhecidos). Por isso, adota-se uma notação diferente para a <strong>função de regressão amostral</strong> em sua forma <em>estocástica</em>:</p>
<p><span class="math display">\[
\hat{Y} = a + b \cdot X
\]</span></p>
<p>em que <span class="math inline">\(\hat{Y}\)</span> é um estimador de <span class="math inline">\(E(Y | X)\)</span>, <span class="math inline">\(a\)</span> é uma estimativa do parâmetro <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(b\)</span> é uma estimativa do parâmetro <span class="math inline">\(\beta\)</span>.</p>
<hr />
<p><br></p>
<p>Para um determinado valor de <span class="math inline">\(X = x_i\)</span>, temos uma observação amostral <span class="math inline">\(Y = y_i\)</span> que pode ser expressa pela <strong>função de regressão amostral</strong> como:</p>
<p><span class="math display">\[
y_i = \hat{y}_i + e_i \\
y_i = a + b \cdot x_i + e_i
\]</span></p>
<p>em que <span class="math inline">\(\hat{y}_i\)</span> é o valor estimado de <span class="math inline">\(Y_i\)</span> para um determinado <span class="math inline">\(X_i\)</span>, <span class="math inline">\(e_i\)</span> é o erro amostral, que representa a diferença entre o valor observado <span class="math inline">\(y_i\)</span> e o valor estimado <span class="math inline">\(\hat{y}_i\)</span>.</p>
<p><br></p>
<blockquote>
<p>Mas, como estimar <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>?</p>
</blockquote>
<hr />
<p><br></p>
</div>
<div id="método-dos-mínimos-quadrados" class="section level3 hasAnchor" number="12.6.4">
<h3><span class="header-section-number">12.6.4</span> Método dos mínimos quadrados<a href="#m%C3%A9todo-dos-m%C3%ADnimos-quadrados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Na literatura estatística há vários métodos de estimação dos parâmetros de um modelo de regressão linear, dentre os quais:</p>
<ul>
<li><p><strong>Método dos mínimos quadrados</strong>: desenvolvido por Carl Friedrich Gauss (1795), publicado por Adrien-Marie Legendre (1805), Friedrich Robert Helmert (1872).</p></li>
<li><p><strong>Método dos momentos</strong>: introduzido por Pafnuty Chebyshev (1887), desenvolvido por Karl Pearson (1894-1895), e posteriormente generalizado por Lars Peter Hansen (Método Generalizado dos Momentos - GMM, 1982).</p></li>
<li><p><strong>Método da máxima verossimilhança</strong>: formas rudimentares foram utilizadas por Carl Friedrich Gauss, Pierre-Simon Laplace, Thorvald N. Thiele e Francis Ysidro Edgeworth; a versão moderna foi criada e popularizada por Ronald Aylmer Fisher (1912-1922).</p></li>
</ul>
<hr />
<div id="contexto-histórico-1" class="section level4 hasAnchor" number="12.6.4.1">
<h4><span class="header-section-number">12.6.4.1</span> Contexto histórico<a href="#contexto-hist%C3%B3rico-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>Desde tempos remotos as pessoas têm se interessado pelo problema de escolher o melhor valor único (médio) para resumir as informações fornecidas por várias observações, cada uma sujeita a erro.</p>
<p>O problema de se estimar as constantes na equação da linha reta que melhor se ajusta a três ou mais pontos não colineares no plano (x, y) cujas coordenadas são pares de valores associados de duas variáveis relacionadas: <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> remonta a Galileu Galilei (1632).</p>
<blockquote>
<p>Credita-se Johann Carl Friedrich Gauss como o desenvolvedor das bases fundamentais do Método dos mínimos quadrados, em 1795, quando Gauss tinha apenas dezoito anos.</p>
</blockquote>
<p>Mas o Método dos mínimos quadrados foi publicado pela primeira vez por por Adrien-Marie Legendre (1752-1833) em 1805: <em>Nouvelles méthodes pour la détermination des orbites des comètes</em>.</p>
<hr />
<p>Alguns demonstradores:</p>
<ul>
<li>Robert Adrain (1775-1843) em 1808: <em>Research concerning the probabilities of the errors which happen in making observations</em><br />
</li>
<li>Johann Carl Friedrich Gauss (1777-1855) em 1809: <em>Theoria motus corporum coelestium</em></li>
<li>Pierre-Simon Laplace (1749-1827) em 1810: <em>Theorie analytique des Probabilite</em> - Johann Carl Friedrich Gauss (1777-1855) em 1823: <em>Theoria combinationis observationum erroribus obnoxiae</em></li>
<li>James Ivory (1765-1842) em 1825: <em>On the Method of the Least Squares</em>.</li>
</ul>
<hr />
<p>Para o modelo <span class="math inline">\(y_{i}= a + b.x_{i}\)</span> na simulação mostrada:</p>
<ul>
<li><strong>problema</strong>: determinar as constantes <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> da equação de uma linha reta que melhor se ajusta a três ou mais pontos não colineares</li>
<li><strong>solução</strong>: minimizar a soma dos quadrados dos resíduos como mostrado na simulação.</li>
</ul>
<p><span class="math display">\[
\sum _{i=1}^{n}{e}_{i}^{2} \rightarrow 0
\]</span></p>
<p>A grande vantagem do método dos mínimos quadrados é que ele é um método puramente geométrico, e não faz nenhuma suposição sobre a distribuição dos dados ou dos erros (resíduos).</p>
<p>Em outras palavras, ele é aplicado sem se preocupar com a natureza probabilística dos erros (resíduos). O objetivo é apenas ajustar a melhor reta possível para um conjunto de pontos de dados. (SIMULADOR 3)</p>
<hr />
<p>Matematicamente, a partir da igualdade:</p>
<p><span class="math display">\[
\sum _{i=1}^{n} [ y_{i} - \hat{y} ]^{2} = \sum _{i=1}^{n}{\left[yi-\left(a+b{x}_{i}\right)\right]}^{2}
\]</span></p>
<p>a solução passar por derivar-se em relação a: <span class="math inline">\(a|b \text{  fixo}\)</span>, e em relação b: <span class="math inline">\(b|a  \text{    fixo}\)</span>, igualando-se a <em>zero</em>:</p>
<p><span class="math display">\[
\frac{\delta }{\delta a}\sum _{i=1}^{n}{\left[y_i-\left(a + b \cdot x_{i}\right)\right]}^{2}= 2 \cdot \sum _{i=1}^{n}\left(y_{i} - a - b \cdot x_{i}\right)\left(-1\right)=0 \\
\frac{\delta }{\delta b}\sum _{i=1}^{n}{\left[y_i-\left(a + b \cdot x_{i}\right)\right]}^{2}= 2\cdot \sum _{i=1}^{n}\left(y_{i} - a - b \cdot x_{i}\right)\left(-x_i\right)=0
\]</span></p>
<p>Expandindo as derivadas e simplificando (dividindo por 2 e removendo os sinais negativos):</p>
<p><span class="math display">\[
\sum _{i=1}^{n}\left(y_{i}-a-b \cdot x_{i}\right) = 0 \\
\sum _{i=1}^{n}\left(y_{i}-a-b \cdot x_{i}\right) \cdot x_i = 0
\]</span></p>
<p>Desenvolvendo a primeira equação:</p>
<p><span class="math display">\[
\sum _{i=1}^{n}y_{i} - \sum _{i=1}^{n}a - \sum _{i=1}^{n}b \cdot x_{i} = 0 \\
\sum _{i=1}^{n}y_{i} - n \cdot a - b \cdot \sum _{i=1}^{n}x_{i} = 0
\]</span></p>
<p>Desenvolvendo a segunda equação:</p>
<p><span class="math display">\[
\sum _{i=1}^{n}y_{i} \cdot x_i - \sum _{i=1}^{n}a \cdot x_i - \sum _{i=1}^{n}b \cdot x_{i}^2 = 0 \\
\sum _{i=1}^{n}y_{i} \cdot x_i - a \cdot \sum _{i=1}^{n}x_i - b \cdot \sum _{i=1}^{n}x_{i}^2 = 0
\]</span></p>
<p>Rearranjando ambas as equações, obtemos o <strong>sistema de equações normais</strong>:</p>
<p><span class="math display">\[
\begin{cases}
n \cdot a + \left(\sum_{i=1}^{n}x_{i}\right) \cdot b = \sum_{i=1}^{n}y_{i} \\
\left(\sum_{i=1}^{n}x_{i}\right) \cdot a + \left(\sum_{i=1}^{n}x_{i}^{2}\right) \cdot b = \sum_{i=1}^{n}x_{i} \cdot y_{i}
\end{cases}
\]</span></p>
<p>ou, equivalentemente:</p>
<p><span class="math display">\[
\begin{cases}
a \cdot n + b \cdot \sum_{i=1}^{n}x_{i} = \sum_{i=1}^{n}y_{i} \\
a \cdot \sum_{i=1}^{n}x_{i} + b \cdot \sum_{i=1}^{n}x_{i}^{2} = \sum_{i=1}^{n}x_{i} \cdot y_{i}
\end{cases}
\]</span></p>
<p>Após algumas manipulações algébricas obtemos as seguintes expressões para as estimativas: <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>:</p>
<p><span class="math display">\[
b\cdot n+a\cdot \sum _{i=1}^{n}{x}_{i}=\sum _{i=1}^{n}{y}_{i}
\]</span></p>
<p><span class="math display">\[
b\cdot \sum _{i=1}^{n}{x}_{i}+a\cdot \sum _{i=1}^{n}{x}_{i}^{2}=\sum _{i=1}^{n}{x}_{i}\cdot {y}_{i}
\]</span></p>
<p>chegando-se à <strong>estimativa</strong> <span class="math inline">\(b\)</span> do parâmetro <span class="math inline">\(\beta\)</span>, dada pelo <strong>estimador de mínimos quadrados</strong>:</p>
<p><span class="math display">\[
b=\frac{n\cdot \left(\sum _{i=1}^{n}{x}_{i}{y}_{i}\right)-\sum _{i=1}^{n}{x}_{i}\sum _{i=1}^{n}{y}_{i}}{n\cdot \sum _{i=1}^{n}{x}_{i}^{2}-{\left(\sum _{i=1}^{n}{x}_{i}\right)}^{2}}
\]</span></p>
<p>e à <strong>estimativa</strong> <span class="math inline">\(a\)</span> do parâmetro <span class="math inline">\(\alpha\)</span>, dada pelo <strong>estimador de mínimos quadrados</strong>:</p>
<p><span class="math display">\[
a=\frac{\left(\sum _{i=1}^{n}{x}_{i}^{2}\right)\cdot \left(\sum _{i=1}^{n}{y}_{i}\right)-\left(\sum _{i=1}^{n}{x}_{i}{y}_{i}\right)\cdot \left(\sum _{i=1}^{n}{x}_{i}\right)}{n\cdot \left(\sum _{i=1}^{n}{x}_{\stackrel{.}{i}}^{2}\right)-{\left(\sum _{i=1}^{n}{x}_{i}\right)}^{2}}
\]</span></p>
<hr />
<p>Se definirmos <span class="math inline">\(S_{xy}\)</span> e <span class="math inline">\(S_{xx}\)</span> como sendo:</p>
<p><span class="math display">\[
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n}
\]</span></p>
<p>e</p>
<p><span class="math display">\[
S_{xx} = \sum _{i=1}^{n} x_{i}^{2} - \frac{(\sum _{i=1}^{n} x_{i})^{2}}{n}
\]</span>
então podemos escrever:</p>
<p><span class="math display">\[
b = \frac{S_{xy}}{S_ {xx}}\\
\text{e} \\
a = \stackrel{-}{y} - b\cdot\stackrel{-}{x}.
\]</span></p>
<p>Uma vez que</p>
<p><span class="math display">\[
\stackrel{-}{y}=\frac{\sum _{i=1}^{n}{y}_{i}}{n}\\
\text{e}\\
\stackrel{-}{x}=\frac{\sum _{i=1}^{n}{x}_{i}}{n}
\]</span></p>
<p>o estimador <strong><span class="math inline">\(a\)</span></strong> pode ser reescrito na forma:</p>
<p><span class="math display">\[
a = \frac{\sum _{i=1}^{n}{y}_{i} - b . \sum _{i=1}^{n}{x}_{i}}{n}
\]</span></p>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 3: Um jornal deseja verificar a eficácia de seus anúncios na venda de carros usados e para isso realizou um levantamento de todos os seus anúncios e informações dos resultados obtidos pelas empresas que o contrataram e dele extraiu uma pequena amostra. A tabela abaixo mostra o número de anúncios e o correspondente número de veículos vendidos por 6 companhias que usaram apenas este jornal como veículo de propaganda. Obtenha a equação de regressão linear simples e estime o número de carros vendidos para um volume de 70 anúncios?</p>
</blockquote>
<center>
<div class="small-equation80">
<table>
<caption>
Quadro de dados da quantidade de carros vendidos por 6 empresas
distintas em função da quantidade de anúncios feitos
</caption>
<thead>
<tr>
<th style="text-align: center;">
Companhia
</th>
<th style="text-align: center;">
Anúncios feitos (X)
</th>
<th style="text-align: center;">
Carros vendidos (Y)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
A
</td>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
</tr>
<tr>
<td style="text-align: center;">
B
</td>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
</tr>
<tr>
<td style="text-align: center;">
C
</td>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
</tr>
<tr>
<td style="text-align: center;">
D
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
</tr>
<tr>
<td style="text-align: center;">
E
</td>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
</tr>
<tr>
<td style="text-align: center;">
F
</td>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
</tr>
</tbody>
</table>
</div>
</center>
<hr />
<p><br></p>
<table>
<caption>
Quadro para cálculo das estimativas <span class="math inline"><em>a</em></span> e <span class="math inline"><em>b</em></span> dos parâmetros do modelo
</caption>
<thead>
<tr>
<th style="text-align: center;">
Companhia
</th>
<th style="text-align: center;">
Anúncios (<span class="math inline"><em>x</em></span>)
</th>
<th style="text-align: center;">
Carros vendidos (<span class="math inline"><em>y</em></span>)
</th>
<th style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>i</em></sub>.<em>y</em><sub><em>i</em></sub></span>
</th>
<th style="text-align: center;">
<span class="math inline"><em>x</em><sub><em>i</em></sub><sup>2</sup></span>
</th>
<th style="text-align: center;">
<span class="math inline"><em>y</em><sub><em>i</em></sub><sup>2</sup></span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
A
</td>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
<td style="text-align: center;">
10286
</td>
<td style="text-align: center;">
5476
</td>
<td style="text-align: center;">
19321
</td>
</tr>
<tr>
<td style="text-align: center;">
B
</td>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
<td style="text-align: center;">
4860
</td>
<td style="text-align: center;">
2025
</td>
<td style="text-align: center;">
11664
</td>
</tr>
<tr>
<td style="text-align: center;">
C
</td>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
<td style="text-align: center;">
4704
</td>
<td style="text-align: center;">
2304
</td>
<td style="text-align: center;">
9604
</td>
</tr>
<tr>
<td style="text-align: center;">
D
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
<td style="text-align: center;">
2736
</td>
<td style="text-align: center;">
1296
</td>
<td style="text-align: center;">
5776
</td>
</tr>
<tr>
<td style="text-align: center;">
E
</td>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
<td style="text-align: center;">
1674
</td>
<td style="text-align: center;">
729
</td>
<td style="text-align: center;">
3844
</td>
</tr>
<tr>
<td style="text-align: center;">
F
</td>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
<td style="text-align: center;">
912
</td>
<td style="text-align: center;">
256
</td>
<td style="text-align: center;">
3249
</td>
</tr>
<tr>
<td style="text-align: center;">
Totais
</td>
<td style="text-align: center;">
246
</td>
<td style="text-align: center;">
540
</td>
<td style="text-align: center;">
25172
</td>
<td style="text-align: center;">
12086
</td>
<td style="text-align: center;">
53458
</td>
</tr>
<tr>
<td style="text-align: center;">
Valor médio
</td>
<td style="text-align: center;">
41
</td>
<td style="text-align: center;">
90
</td>
<td style="text-align: center;">
</td>
<td style="text-align: center;">
</td>
<td style="text-align: center;">
</td>
</tr>
</tbody>
</table>
</center>
<hr />
<p><br></p>
<p>Sendo <span class="math inline">\(n= 6\)</span>, <span class="math inline">\(\stackrel{-}{y}= 90\)</span> e <span class="math inline">\(\stackrel{-}{x} = 41\)</span>:</p>
<p><span class="math display">\[
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n} = 25172 - \frac{246 \cdot 540}{6} = 3032 \\
S_{xx} = \sum _{i=1}^{n} x_{i}^{2} - \frac{(\sum _{i=1}^{n} x_{i})^{2}}{n} = 12086 - \frac{246^2}{6} = 2000 \\
{S}_{yy} = \sum _{i=1}^{n}y_{i}^{2} - \frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}=   53458 - \frac{540^2}{6} = 4858
\]</span></p>
<p><br></p>
<p>As estimativas dos parâmetros do modelo serão:</p>
<p><span class="math display">\[
b = \frac{S_{xy}}{S_ {xx}} = \frac{3032}{2000} = 1,5160
\]</span></p>
<p>e</p>
<p><span class="math display">\[
a = \stackrel{-}{y} - b\cdot\stackrel{-}{x} = 90 - 1,5160 \cdot 41 = 27,844
\]</span></p>
<hr />
<p><br></p>
<p>e o modelo toma a seguinte forma <span class="math inline">\(\hat{y} = 27,844 + 1,5160 \cdot x\)</span>. Para um volume de anúncios de 70 veiculações teremos, em média, 134 carros vendidos.</p>
<hr />
<p><br></p>
<pre><code>## Equação: Y = 27.844 + 1.5160 * X</code></pre>
<pre><code>## Predição para 70 anúncios: 134 carros</code></pre>
<p><br></p>
<hr />
</div>
</div>
</div>
<div id="modelo-de-regressão-linear-sob-erros-normais" class="section level2 hasAnchor" number="12.7">
<h2><span class="header-section-number">12.7</span> Modelo de regressão linear sob erros Normais<a href="#modelo-de-regress%C3%A3o-linear-sob-erros-normais" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<div id="propriedades-estatísticas-dos-estimadores-de-mínimos-quadrados" class="section level3 hasAnchor" number="12.7.1">
<h3><span class="header-section-number">12.7.1</span> Propriedades Estatísticas dos Estimadores de Mínimos Quadrados<a href="#propriedades-estat%C3%ADsticas-dos-estimadores-de-m%C3%ADnimos-quadrados" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>O método dos mínimos quadrados (MMQ) é um procedimento puramente algébrico e geométrico que fornece estimativas para <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span>. Para compreender as propriedades estatísticas dessas estimativas, devemos distinguir dois conjuntos de pressupostos:</p>
<div id="o-teorema-de-gauss-markov-e-os-estimadores-blue" class="section level4 hasAnchor" number="12.7.1.1">
<h4><span class="header-section-number">12.7.1.1</span> O Teorema de Gauss-Markov e os Estimadores BLUE<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#o-teorema-de-gauss-markov-e-os-estimadores-blue" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>O <strong>Teorema de Gauss-Markov</strong> estabelece que, sob certas condições, os estimadores de MQO são os <strong>BLUE</strong> (<em>Best Linear Unbiased Estimators</em>), ou seja, possuem a <strong>menor variância</strong> possível dentro da classe de todos os estimadores lineares e não-enviesados.</p>
<p><br></p>
<p><strong>Pressupostos de Gauss-Markov</strong> (para garantir BLUE):</p>
<ol style="list-style-type: decimal">
<li><p><strong>Linearidade nos parâmetros</strong>: O modelo deve ser linear em relação aos parâmetros <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>, ou seja, a variável dependente <span class="math inline">\(Y\)</span> pode ser expressa como uma combinação linear desses parâmetros: <span class="math inline">\(Y_i = \alpha + \beta X_i + \varepsilon_i\)</span>.</p>
<p><strong>Importante:</strong> A linearidade refere-se aos <strong>parâmetros</strong>, não necessariamente à variável <span class="math inline">\(X\)</span>. Por exemplo, os modelos <span class="math inline">\(Y = \alpha + \beta X^2 + \varepsilon\)</span> ou <span class="math inline">\(Y = \alpha + \beta \ln(X) + \varepsilon\)</span> ainda são <strong>lineares nos parâmetros</strong> <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>, mesmo que a relação com <span class="math inline">\(X\)</span> seja não-linear. Por outro lado, modelos como <span class="math inline">\(Y = \alpha \cdot e^{\beta X} + \varepsilon\)</span> ou <span class="math inline">\(Y = \alpha \cdot X^{\beta} + \varepsilon\)</span> <strong>não são lineares</strong> nos parâmetros (embora possam ser linearizados por transformações logarítmicas).</p></li>
</ol>
<hr />
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Exogeneidade (ou Independência Média)</strong>: A média condicional dos erros é zero dado qualquer valor de <span class="math inline">\(X\)</span>: <span class="math inline">\(E[\varepsilon_i | X_i] = 0\)</span>. Isto implica que não há correlação sistemática entre a variável explicativa <span class="math inline">\(X\)</span> e o termo de erro <span class="math inline">\(\varepsilon\)</span>.</p>
<p><strong>Importante:</strong> Este pressuposto garante que <span class="math inline">\(X\)</span> não carrega informação sobre o erro médio, ou seja, conhecer o valor de <span class="math inline">\(X_i\)</span> não nos ajuda a prever <span class="math inline">\(\varepsilon_i\)</span>. Violações deste pressuposto ocorrem quando há variáveis omitidas relevantes (que estão em <span class="math inline">\(\varepsilon\)</span> mas correlacionadas com <span class="math inline">\(X\)</span>), erros de medida em <span class="math inline">\(X\)</span>, ou simultaneidade (quando <span class="math inline">\(Y\)</span> também influencia <span class="math inline">\(X\)</span>). Quando este pressuposto é violado, os estimadores de MQO são <strong>enviesados</strong>.</p></li>
</ol>
<hr />
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Homocedasticidade (Variância Constante)</strong>: A variância do erro é constante para todas as observações, independentemente do valor de <span class="math inline">\(X\)</span>: <span class="math inline">\(Var(\varepsilon_i | X_i) = \sigma^2\)</span> para todo <span class="math inline">\(i\)</span>.</p>
<p><strong>Importante:</strong> Este pressuposto estabelece que a dispersão dos erros ao redor da linha de regressão é a mesma para todos os níveis de <span class="math inline">\(X\)</span>. A violação deste pressuposto — <strong>heterocedasticidade</strong> — ocorre quando <span class="math inline">\(Var(\varepsilon_i | X_i) = \sigma_i^2\)</span> varia com <span class="math inline">\(X_i\)</span>. Por exemplo, em dados de renda familiar versus gastos com alimentação, a variabilidade dos gastos tende a aumentar com a renda. Sob heterocedasticidade, os estimadores de MQO permanecem não-enviesados, mas <strong>perdem eficiência</strong> (não são mais BLUE) e os <strong>erros padrão</strong> usuais ficam incorretos, comprometendo testes de hipóteses e intervalos de confiança.</p></li>
</ol>
<hr />
<ol start="4" style="list-style-type: decimal">
<li><p><strong>Ausência de Autocorrelação (Independência dos Erros)</strong>: Os erros de observações diferentes não estão correlacionados entre si: <span class="math inline">\(Cov(\varepsilon_i, \varepsilon_j) = 0\)</span> para todo <span class="math inline">\(i \neq j\)</span>, ou equivalentemente, <span class="math inline">\(E[\varepsilon_i \cdot \varepsilon_j] = 0\)</span> para <span class="math inline">\(i \neq j\)</span>.</p>
<p><strong>Importante:</strong> Este pressuposto é especialmente relevante para dados de <strong>séries temporais</strong> ou dados com estrutura <strong>espacial</strong>. Em séries temporais, a autocorrelação ocorre quando o erro no período <span class="math inline">\(t\)</span> está correlacionado com o erro no período <span class="math inline">\(t-1, t-2\)</span>, etc. Por exemplo, em dados mensais de vendas, choques positivos tendem a persistir por vários meses. Em dados espaciais, propriedades vizinhas tendem a ter erros correlacionados. Sob autocorrelação, os estimadores de MQO permanecem não-enviesados, mas <strong>perdem eficiência</strong> e os <strong>erros padrão</strong> são subestimados, levando a intervalos de confiança artificialmente estreitos e rejeição excessiva de <span class="math inline">\(H_0\)</span> em testes.</p></li>
</ol>
<blockquote>
<p><strong>Observação fundamental:</strong> O Teorema de Gauss-Markov <strong>não exige normalidade</strong> dos erros. Sob esses quatro pressupostos, os estimadores de MQO já são os melhores estimadores lineares não-enviesados, mesmo que os erros não sejam normalmente distribuídos.</p>
</blockquote>
<hr />
</div>
<div id="a-necessidade-da-normalidade-para-inferência-estatística" class="section level4 hasAnchor" number="12.7.1.2">
<h4><span class="header-section-number">12.7.1.2</span> A Necessidade da Normalidade para Inferência Estatística<a href="#a-necessidade-da-normalidade-para-infer%C3%AAncia-estat%C3%ADstica" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>Embora o Teorema de Gauss-Markov garanta que os estimadores sejam BLUE, <strong>ele não nos permite fazer inferências estatísticas</strong> tais como construir intervalos de confiança ou realizar testes de hipóteses.</p>
<blockquote>
<p>Para realizar inferências estatísticas, devemos fazer uma <strong>suposição adicional</strong>: introduzimos o <strong>modelo de regressão linear com erro normal</strong>, que assume que os erros (<span class="math inline">\(\varepsilon_i\)</span>) são variáveis aleatórias <strong>Normalmente distribuídas</strong> com média zero e variância constante: <span class="math inline">\(\varepsilon_i \sim N(0, \sigma^2)\)</span></p>
</blockquote>
<hr />
</div>
</div>
<div id="pressupostos-do-modelo-de-regressão-linear" class="section level3 hasAnchor" number="12.7.2">
<h3><span class="header-section-number">12.7.2</span> Pressupostos do Modelo de Regressão Linear<a href="#pressupostos-do-modelo-de-regress%C3%A3o-linear" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consolidando os pressupostos de Gauss-Markov com a normalidade, temos que as premissas do modelo de regressão linear podem ser classificadas em <strong>quatro categorias</strong>:</p>
<p><br></p>
<ol style="list-style-type: decimal">
<li><strong>Linearidade</strong>: A relação entre a variável preditora <span class="math inline">\(X\)</span> e a variável resposta <span class="math inline">\(Y\)</span> é linear nos parâmetros; o valor esperado da variável resposta é uma função linear da variável preditora</li>
</ol>
<hr />
<ol start="2" style="list-style-type: decimal">
<li><p><strong>Normalidade</strong>: <span class="math inline">\(\varepsilon_i \sim N(0, \sigma^2)\)</span> — os erros são normalmente distribuídos com média zero e variância constante.</p>
<p><strong>Importante:</strong> Este pressuposto é <strong>adicional</strong> aos pressupostos de Gauss-Markov e não é necessário para garantir que os estimadores de MQO sejam BLUE. A normalidade dos erros é fundamental para: (i) garantir que os estimadores <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> sejam também normalmente distribuídos, permitindo o uso das distribuições <span class="math inline">\(t\)</span> e <span class="math inline">\(F\)</span> para inferência; (ii) construir intervalos de confiança válidos; (iii) realizar testes de hipóteses em <strong>amostras pequenas</strong>. Para <strong>amostras grandes</strong>, o Teorema Central do Limite garante que os estimadores sejam aproximadamente normais mesmo sem este pressuposto. A violação da normalidade compromete principalmente a validade de intervalos de confiança e testes em amostras pequenas (<span class="math inline">\(n &lt; 30\)</span>).</p></li>
</ol>
<hr />
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Independência estatística dos resíduos</strong>: <span class="math inline">\(Cov(\varepsilon_i, \varepsilon_j) = E(\varepsilon_i \cdot \varepsilon_j) = 0\)</span> para <span class="math inline">\(i \neq j\)</span>, e, em particular, nenhuma correlação entre erros de observações sucessivas no caso de dados provenientes de uma série.</p>
<p><strong>Importante:</strong> Este pressuposto estabelece que o erro associado a uma observação não fornece informação sobre o erro de outra observação. A violação deste pressuposto — <strong>autocorrelação</strong> ou <strong>correlação serial</strong> — é particularmente comum em: (i) <strong>séries temporais</strong>, onde choques em <span class="math inline">\(t\)</span> persistem em períodos subsequentes <span class="math inline">\(t+1, t+2, ...\)</span>; (ii) <strong>dados espaciais</strong>, onde observações geograficamente próximas tendem a ter erros correlacionados; (iii) <strong>dados em painel</strong>, com observações repetidas da mesma unidade ao longo do tempo. A presença de autocorrelação não enviesa os estimadores de MQO, mas os torna <strong>ineficientes</strong> (não são mais BLUE), e os <strong>erros padrão usuais</strong> ficam <strong>subestimados</strong>, levando a intervalos de confiança artificialmente estreitos e rejeição excessiva de <span class="math inline">\(H_0\)</span> em testes. A detecção pode ser feita pelo teste de Durbin-Watson ou análise gráfica dos resíduos ao longo do tempo.</p></li>
</ol>
<hr />
<ol start="4" style="list-style-type: decimal">
<li><p><strong>Homocedasticidade</strong>: <span class="math inline">\(Var(\varepsilon_i) = E(\varepsilon_i^2) = \sigma^2\)</span> — a variância dos resíduos é constante quando analisada frente aos valores estimados pelo modelo (<span class="math inline">\(\hat{Y}\)</span>), a variável preditora (<span class="math inline">\(X\)</span>) ou o tempo de coleta nos casos de dados provenientes de uma série.</p>
<p><strong>Importante:</strong> Este pressuposto requer que a dispersão dos erros seja <strong>uniforme</strong> ao longo de toda a amplitude de <span class="math inline">\(X\)</span> ou <span class="math inline">\(\hat{Y}\)</span>. A violação deste pressuposto — <strong>heterocedasticidade</strong> — ocorre quando <span class="math inline">\(Var(\varepsilon_i) = \sigma_i^2\)</span> varia sistematicamente, sendo comum em: (i) dados de <strong>corte transversal</strong> com unidades de diferentes tamanhos (ex: renda e gastos de famílias, onde famílias ricas têm maior variabilidade); (ii) dados onde a <strong>precisão da medição</strong> varia entre observações; (iii) modelos onde a variável dependente cresce exponencialmente. Sob heterocedasticidade, os estimadores de MQO permanecem <strong>não-enviesados</strong> e <strong>consistentes</strong>, mas perdem <strong>eficiência</strong> (não são BLUE), e os <strong>erros padrão</strong> calculados pela fórmula usual ficam <strong>incorretos</strong> (geralmente subestimados), comprometendo testes de hipóteses e intervalos de confiança. A detecção pode ser feita por gráficos de resíduos versus valores ajustados ou testes formais (Breusch-Pagan, White). Correções incluem transformações (Box-Cox, logarítmica) ou uso de erros padrão robustos (White, HC).—</p></li>
</ol>
<hr />
</div>
<div id="propriedades-dos-estimadores-sob-erro-normal" class="section level3 hasAnchor" number="12.7.3">
<h3><span class="header-section-number">12.7.3</span> Propriedades dos Estimadores sob Erro Normal<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#propriedades-dos-estimadores-sob-erro-normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Demonstra-se que, para um modelo <span class="math inline">\(Y_{i}=\alpha+\beta\cdot X_{i}+\varepsilon_{i}\)</span> que:</p>
<ul>
<li><span class="math inline">\(b\)</span> é um estimador não tendencioso do parâmetro <span class="math inline">\(\beta\)</span> com:</li>
</ul>
<p><span class="math display">\[
E\left(b\right)=\beta \\
\text{e} \\
Var\left(b\right)=\frac{{\sigma }^{2}}{{S}_{xx}}
\]</span></p>
<ul>
<li><span class="math inline">\(a\)</span> é um estimador não tendencioso do parâmetro <span class="math inline">\(\alpha\)</span> com:</li>
</ul>
<p><span class="math display">\[
E\left(a\right)=\alpha\\
\text{e} \\
Var\left(a\right)={\sigma }^{2}\cdot \left(\frac{1}{n}+\frac{{\stackrel{-}{X}}^{2}}{{S}_{xx}}\right)
\]</span></p>
<ul>
<li><span class="math inline">\(\hat{\sigma^{2}}\)</span> é um estimador não tendencioso de <span class="math inline">\(\sigma^{2}\)</span>:</li>
</ul>
<p><span class="math display">\[
\hat{\sigma^{2}} =  \text{QMR} = \frac{S_{yy} -b  \cdot S{xy}}{n-2}
\]</span></p>
<p>Assim as variâncias dos estimadores <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> serão,</p>
<p><span class="math display">\[
s_{b} = \sqrt{\frac{{\hat{\sigma}}^{2}}{{S}_{xx}}}  = \sqrt{\frac{\text{QMRES}}{S_{xx}}}
\]</span></p>
<p><span class="math display">\[
s_{a} = \sqrt{{\hat{\sigma} }^{2}\cdot \left(\frac{1}{n}+\frac{{\stackrel{-}{x}}^{2}}{{S}_{xx}}\right)} = \sqrt{\text{QMRES} \cdot \left(\frac{1}{n}+\frac{{\stackrel{-}{x}}^{2}}{{S}_{xx}}\right)}
\]</span></p>
<p>lembrando que:</p>
<p><span class="math display">\[
S_{yy} = \sum (Y_i - \bar{Y})^2 \\
S_{xy} = \sum (X_i - \bar{X})(Y_i - \bar{Y}),
\]</span></p>
<p>e <span class="math inline">\(n - 2\)</span> representa os graus de liberdade, já que dois parâmetros (<span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>) são estimados.</p>
<hr />
</div>
<div id="implicações-da-normalidade" class="section level3 hasAnchor" number="12.7.4">
<h3><span class="header-section-number">12.7.4</span> Implicações da Normalidade<a href="#implica%C3%A7%C3%B5es-da-normalidade" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<blockquote>
<p>A normalidade dos resíduos <span class="math inline">\(\varepsilon_i\)</span> garante que os estimadores <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> também sejam Normalmente distribuídos, o que é fundamental para realizar testes de hipóteses e construir intervalos de confiança nos modelos de regressão linear.</p>
</blockquote>
<hr />
<p><br></p>
<blockquote>
<p>Isso permite o uso de distribuições de referência, como as distribuições <span class="math inline">\(t\)</span> e <span class="math inline">\(F\)</span>, especialmente em amostras pequenas, onde a variância dos estimadores não pode ser assumida como conhecida com precisão.</p>
</blockquote>
<hr />
<p><br></p>
<blockquote>
<p>Na estimação de um modelo de regressão linear simples com erro Normal (na forma <span class="math inline">\(Y=\beta_{0}+\beta_{1}X+ \varepsilon\)</span>) muitas premissas preliminarmente como válidas deverão ser efetivamente verificadas a posteriori, na chamada etapa de diagnóstico do modelo, de modo a que a condução de inferências com esse modelo sejam dotada de razoável segurança.</p>
</blockquote>
<hr />
<p><br></p>
<blockquote>
<p>Se qualquer uma dessas premissas for violada então uma conclusão científica baseada em resultados advindos desse modelo de regressão poderá estar seriamente comprometida. As violações desses pressupostos não podem ser detectadas pelas estatísticas de resumo do modelo que usualmente se dipõe logo após sua estimação: estatísticas <span class="math inline">\(t\)</span>, <span class="math inline">\(F\)</span> dos testes de significância ou então o coeficiente de determinação <span class="math inline">\(R^{2}\)</span>.</p>
</blockquote>
<hr />
<p><br></p>
<blockquote>
<p>Assim, é sobretudo fundamental examinar mais aprofundadamente o modelo de modo a se assegurar com razoável confiança de sua adequação aos dados antes de se avançar com seu uso. A esse exame denominamos diagnóstico do modelo.</p>
</blockquote>
<hr />
</div>
<div id="linearidade-na-relação-entre-a-variável-preditora-x-e-a-variável-resposta-y" class="section level3 hasAnchor" number="12.7.5">
<h3><span class="header-section-number">12.7.5</span> Linearidade na relação entre a variável preditora <span class="math inline">\(X\)</span> e a variável resposta <span class="math inline">\(Y\)</span>:<a href="#linearidade-na-rela%C3%A7%C3%A3o-entre-a-vari%C3%A1vel-preditora-x-e-a-vari%C3%A1vel-resposta-y" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>A violação da linearidade é extremamente graves pois um modelo ajustado a dados não lineares leva a previsões equivocadas não somente para valores situados além das fronteiras amostrais (como se usualmente observa) mas também para valores próximos ao seu centro.</p>
<blockquote>
<p>Uma técnica gráfica para se verificar a linearidade da relação é através de dois gráficos:</p>
</blockquote>
<ul>
<li>valores observados em relação aos valores estimados; ou/e,</li>
<li>resíduos contra valores estimados (ou valores observados).</li>
</ul>
<p><img src="apostila_files/figure-html/unnamed-chunk-11-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Os padrões desejados nos gráficos acima deve assemelhar-se a:</p>
<ul>
<li>pontos dispersos de modo aproximadamente simétrico em torno de uma linha diagonal; e,</li>
<li>pontos dispersos de modo aproximadamente simétrico em torno de uma linha horizontal, com uma variância aproximadamente homogênea.</li>
</ul>
<p>Relações não lineares devem ser tratadas por meio da aplicação de uma transformação não linear adequada ao padrão da relação na variável resposta ou no variável preditora.</p>
<p>Para dados estritamente positivos com uma relação não linear a transformação com a função logaritmo pode ser uma opção. Se uma a transformação com o uso da função logaritmo é aplicada apenas à variável resposta isso equivalente a assumir que ela cresce (ou decai) exponencialmente como uma função da variável preditora.</p>
<p>Outra possibilidade a considerar é adicionar outra variável preditora na forma de uma função não linear como, por exepmplo, nos padrões de dispersão que mostrem uma curva parabólica onde pode fazer sentido regredir <span class="math inline">\(Y\)</span> em função de <span class="math inline">\(X\)</span> e <span class="math inline">\(X^{2}\)</span>.</p>
<p>Finalmente, a relação não linear observada pode decorrer da omissão de outra(s) variáveis importantes que explicam ou corrigem o padrão não linear quando então modelos de regressão linear múltipla devem ser estudados.</p>
<hr />
</div>
<div id="homogeneidade-da-variância-de-varepsilon-homocedasticidade" class="section level3 hasAnchor" number="12.7.6">
<h3><span class="header-section-number">12.7.6</span> Homogeneidade da variância de <span class="math inline">\(\varepsilon\)</span> (homocedasticidade):<a href="#homogeneidade-da-vari%C3%A2ncia-de-varepsilon-homocedasticidade" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>A violação da homogeneidade de variância dos resíduos (heterocedasticidade) resulta numa estimação imprecisa do verdadeiro desvio padrão dos erros das estimativas e acarreta em intervalos de confiança irreais: são mais amplos ou mais estreitos do que deveriam ser, e resultam em elevada imprecisão nas inferências feitas com estatísticas baseadas na variância (<span class="math inline">\(t\)</span>, <span class="math inline">\(F\)</span>).</p>
<p>Com variância constante (homocedasticidade) temos que <span class="math inline">\(Var(\varepsilon|X_{i})=\sigma^{2}\)</span>; todavia o que se observa em muitas situações é que a variância está relacionada de algum modo funcional com a média (<span class="math inline">\(\sigma^{2}=\mathcal{f}(X)\)</span>) e, assim:</p>
<p><span class="math display">\[
\begin{aligned}
Var(\varepsilon_{i}|X_{i})=\sigma^{2}_{i} \\
E(\varepsilon_{i}^{2})=\sigma^{2}_{i}
\end{aligned}
\]</span></p>
<p>Na presença de heterocedasticidade nos resíduos, os estimadores de mínimos quadrados continuam sendo não viesados e consistentes, mas perdem eficiência. Equivale a dizer que haverá um outro estimador para os parâmetros do modelo que terá uma variância menor e menos tendencioso:</p>
<p><span class="math display">\[
\begin{aligned}
Var(b^{*}) &lt; Var(b)
\end{aligned}
\]</span></p>
<blockquote>
<p>Uma técnica gráfica para se verificar a homocedasticidade dos resíduos é através dos gráficos:</p>
</blockquote>
<ul>
<li>resíduos contra valores estimados; ou,</li>
<li>resíduos contra a variável preditora</li>
</ul>
<p><img src="apostila_files/figure-html/unnamed-chunk-12-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>Os padrões desejados nos gráficos acima deve assemelhar-se a pontos dispersos de modo aproximadamente simétrico em torno de um eixo horizontal e que não exibam, sistematicamente, nenhum padrão de crescimento ou decaimento na amplitude visual de sua dispersão como nas imagens acima.</p>
<p>Gráficos dos valores absolutos dos resíduos (ou do quadrado dos resíduos pois os sinais dos resíduos não são significativos para o propósito desse exame) contra a variável preditora <span class="math inline">\(X\)</span> ou em relação aos valores ajustados também são úteis para o diagnóstico da heterocedasticidade da variância dos resíduos.</p>
<p>Esses gráficos são recomendados quando não há muitas observações no conjunto de dados pois a plotagem dos resíduos absolutos ou seus quadrados coloca as informações sobre a alteração das suas magnitudes acima da linha horizontal do zero o que facilita a inspeção visual de possíveis alterações de sua magnitude em relação a outra variável adotada no gráfico.</p>
<p>A heterocedasticidade pode ser um subproduto de uma violação significativa das premissas de linearidade e/ou independência, caso em que todas essas violações podem ser conjuntamente corrigidas com a aplicação de uma transformação de potência na variável dependente que terá como objetivos:</p>
<ul>
<li>linearizar o ajuste tanto quanto possível; e/ou,</li>
<li>estabilizar a variância dos resíduos.</li>
</ul>
<p>Algum cuidado e discernimento é requerido pois esses dois objetivos podem conflitar entre si. Geralmente opta-se em estabilizar a variância dos resíduos primeiramente para, só então analisar linearização das relações.</p>
<p>As transformações sugeridas pela família Box-Cox (1964) em função dos valor que maximizam a verissimilhança perfilada são:</p>
<ul>
<li>se <span class="math inline">\(\lambda\)</span>=-2 <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\frac{1}{Y^{2}}\)</span></li>
<li>se <span class="math inline">\(\lambda\)</span>=-1 <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\frac{1}{Y}\)</span></li>
<li>se <span class="math inline">\(\lambda\)</span>=-0,5 <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\frac{1}{\sqrt{Y}}\)</span></li>
<li>se <span class="math inline">\(\lambda\)</span>=0 <span class="math inline">\(\rightarrow\)</span> log(Y)</li>
<li>se <span class="math inline">\(\lambda\)</span>=0,50 <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(\sqrt{Y}\)</span></li>
<li>se <span class="math inline">\(\lambda\)</span>=1 <span class="math inline">\(\rightarrow\)</span> Y</li>
<li>se <span class="math inline">\(\lambda\)</span>=2 <span class="math inline">\(\rightarrow\)</span> <span class="math inline">\(Y^{2}\)</span></li>
</ul>
<p><img src="apostila_files/figure-html/unnamed-chunk-13-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>## 
## Lambda ótimo da transformação Box-Cox: 0.8282828</code></pre>
<hr />
<div id="teste-de-hipóteses-para-verificação-da-homogeneidade-da-variância-em-regressão" class="section level4 hasAnchor" number="12.7.6.1">
<h4><span class="header-section-number">12.7.6.1</span> Teste de hipóteses para verificação da homogeneidade da variância em regressão:<a href="#teste-de-hip%C3%B3teses-para-verifica%C3%A7%C3%A3o-da-homogeneidade-da-vari%C3%A2ncia-em-regress%C3%A3o" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<ul>
<li>teste de Breuch-Pagan</li>
<li>teste de Park</li>
</ul>
<p><span class="math display">\[
\begin{cases}
H_{0}: Var(\varepsilon|X_{i}) = \sigma^{2} \text{ ou seja, constante para todo } i  \\
H_{1}: Var(\varepsilon|X_{i}) = \sigma^{2}_{i} \text{,  varia com  } i
\end{cases}
\]</span></p>
<pre><code>## 
## Teste de Breusch-Pagan para heterocedasticidade:</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  modelo
## BP = 0.1428, df = 1, p-value = 0.7055</code></pre>
<pre><code>## 
## Call:
## lm(formula = ln_residuos_sq ~ ln_anuncios)
## 
## Residuals:
##       1       2       3       4       5       6 
## -1.6962  2.3590 -0.5698  0.7380  0.3550 -1.1861 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)    9.095      5.082   1.790    0.148
## ln_anuncios   -1.706      1.397  -1.221    0.289
## 
## Residual standard error: 1.647 on 4 degrees of freedom
## Multiple R-squared:  0.2717, Adjusted R-squared:  0.08956 
## F-statistic: 1.492 on 1 and 4 DF,  p-value: 0.289</code></pre>
<hr />
</div>
</div>
<div id="inconsistência-de-observações-outliers" class="section level3 hasAnchor" number="12.7.7">
<h3><span class="header-section-number">12.7.7</span> Inconsistência de observações (outliers)<a href="#inconsist%C3%AAncia-de-observa%C3%A7%C3%B5es-outliers" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Outliers são observações extremas afastadas das demais observações que formam a amostra e sua identificação deve ser feita já na análise descritiva que antecede todo estudo estatístico.</p>
<p>Essas observações podem ser resultado dos mais variados erros de medição (observadores diferentes, equipamentos descalibrados, instrumentos de medição diversos) quando então, nessa hipótese e confirmado o erro de registro, devem ser descartados com discernimento.</p>
<p>Todavia na maior parte dos experimentos a identificação desse tipo de erro na etapa descritiva não é possível e, nessas situações, a análise dos residuos gerados pelo modelo na estimação de cada observação é a principal ferramenta.</p>
<p>A principal razão para sua identificação é que esses pontos extremos podem ter grande repercussão e exercer grande influência nas estimativas do modelo. Uma observação é influente se uma uma pequena modificação em seu valor ou sua exclusão do modelo produz alterações significativas nas estimativas dos parâmetros.</p>
<blockquote>
<p>Uma técnica gráfica para se verificar a presença observações outliers é através dos gráficos:</p>
</blockquote>
<ul>
<li>resíduos contra valores estimados; e/ou,</li>
<li>resíduos contra a variável preditora</li>
</ul>
<p><img src="apostila_files/figure-html/unnamed-chunk-15-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>A plotagem de resíduos estudentizados é particularmente útil para distinguir as observações cujos resíduos distem muitos desvios padrão da média zero.</p>
<p>Os padrões desejados nos gráficos acima deve assemelhar-se a pontos dispersos de modo aproximadamente simétrico em torno do eixo horizontal zero, que não exibam, sistematicamente, nenhum padrão de crescimento ou decaimento na amplitude visual de sua dispersão. Uma regra comum para amostras grandes (n&gt;30) é considerar resíduos estudentizados com afstamentos em valor absoluto de quatro ou mais desvios padrão serem outliers.</p>
<hr />
</div>
<div id="pontos-influentes-com-capacidade-de-alavanca-leverage" class="section level3 hasAnchor" number="12.7.8">
<h3><span class="header-section-number">12.7.8</span> Pontos influentes com capacidade de alavanca (<span class="math inline">\(leverage\)</span>):<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#pontos-influentes-com-capacidade-de-alavanca-leverage" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Os elementos <span class="math inline">\(h_{ii}\)</span> da diagonal da matriz de projeção (H) tem importante papel no diagnóstico de pontos influentes. Há diferentes opiniões sobre os valores críticos para essa medida:</p>
<ul>
<li><span class="math inline">\(h_{ii}&gt;2\frac{p}{n}\)</span> (Hoaglin, D. C. and Welsch, R. E, 1978. The hat matrix in regression and ANOVA)</li>
<li><span class="math inline">\(h_{ii}&gt; 3\frac{p}{n}\)</span></li>
</ul>
<p>em que <span class="math inline">\(p\)</span> é o número de parâmetros estimados no modelo (<span class="math inline">\(\hat{\beta_{0}}\)</span> e <span class="math inline">\(\hat{\beta_{1}}\)</span>: 2 para uma regressão linear simples).</p>
<pre><code>## 
## Pontos de alavanca (leverage):</code></pre>
<pre><code>## Limite de Hoaglin (2p/n): 0.6666667</code></pre>
<pre><code>## Limite alternativo (3p/n): 1</code></pre>
<pre><code>## 
## Valores de leverage:</code></pre>
<pre><code>##         1         2         3         4         5         6 
## 0.7111667 0.1746667 0.1911667 0.1791667 0.2646667 0.4791667</code></pre>
<pre><code>## 
## Pontos com leverage alto (&gt; 0.6666667 ):</code></pre>
<pre><code>## 1 
## 1</code></pre>
<p><img src="apostila_files/figure-html/unnamed-chunk-16-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>David Sam Jayakumar e A. Sulthan (Exact distribution of Hat Values and Identification of Leverage Points, 2014) propuseram a distribuição teóricas exata para os valores da diagonal da matriz de projeção <a href="http://www.researchgate.net/publication/265423863">link de acesso ao recurso</a>.</p>
<hr />
<div id="dfbeta-difference-in-betas" class="section level4 hasAnchor" number="12.7.8.1">
<h4><span class="header-section-number">12.7.8.1</span> DFBeta (<em>Difference in Betas</em>):<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#dfbeta-difference-in-betas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>A estatística <span class="math inline">\(DFBeta\)</span> indica o quanto cada coeficiente de regressão <span class="math inline">\(\hat{\beta_{j}}\)</span> se altera em unidades de desvio padrão quando a i-ésima observação for removida:</p>
<p><span class="math display">\[
DFBeta_{(j,i)}=\frac{\hat{\beta_{j}}-\hat{\beta_{j(i)}}}{ \sqrt{S_{i}^{2}C_{(jj)}}}  
\]</span></p>
<p>onde <span class="math inline">\(C_{(jj)}\)</span> é o j-ésimo elemento da diagonal da matriz <span class="math inline">\((X^{t}X)^{-1}\)</span> e:</p>
<p><span class="math display">\[
S_{i}^{2}=\frac{(n-p-1)QMRes - \hat{\varepsilon_{i}} (1-h_{ii}) }{(n-p)}
\]</span></p>
<p>Valores superiores a <span class="math inline">\(|DFBeta_{(ji)}|&gt; \frac{2}{\sqrt{n}}\)</span> requerem exame mais detalhado.</p>
<pre><code>## 
## DFBetas:</code></pre>
<pre><code>## Limite crítico (2/sqrt(n)): 0.8164966</code></pre>
<pre><code>##    (Intercept)    Anuncios
## 1  0.195037416 -0.28329527
## 2  0.224169407  0.23766189
## 3 -0.008116745 -0.05503666
## 4 -0.249969539  0.10420091
## 5 -0.511395622  0.35414723
## 6  0.751401519 -0.62068520</code></pre>
<hr />
</div>
<div id="dffits-difference-in-fits" class="section level4 hasAnchor" number="12.7.8.2">
<h4><span class="header-section-number">12.7.8.2</span> DFFits (<em>Difference in fits</em>)::<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#dffits-difference-in-fits" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>A estatística <span class="math inline">\(DFFits\)</span> indica a influência da i-ésima observação medindo o quanto os valores preditos se modificam, em unidades de desvio padrão, se aquela observação for removida:</p>
<p><span class="math display">\[
DFFits= \frac{\hat{Y}-\hat{Y_{i}} }{\sqrt{S_{i}^{2} h_{ii}}}
\]</span></p>
<p>Valores superiores a <span class="math inline">\(|DFFits|&gt; 2\sqrt{\frac{p}{n}}\)</span> requerem exame mais detalhado.</p>
<pre><code>## 
## DFFits:</code></pre>
<pre><code>## Limite crítico (2*sqrt(p/n)): 1.154701</code></pre>
<pre><code>##          1          2          3          4          5          6 
## -0.3237622  1.1105026 -0.1537358 -0.3944983 -0.5819966  0.7685811</code></pre>
<hr />
</div>
<div id="distância-de-cook" class="section level4 hasAnchor" number="12.7.8.3">
<h4><span class="header-section-number">12.7.8.3</span> Distância de Cook:<a href="#dist%C3%A2ncia-de-cook" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>A estatítica proposta por Denis R. Cook mede a influência de um determinado dado da amostra no que tange a quanto ele está afetando a linha de regressão, sendo medida pelo quanto a linha de regressão se alteraria caso esse dado fosse removido da da análise: ele exerce um destacado impacto da estimativa dos parâmetros do modelo. A influência na locação (afastamento de alguma observação da vizinhança do resto dos dados) pode ser investigada pelo gráfico feito das distâncias de Cook contra os valores ajustados.</p>
<p>Há vários critérios para se definir um valor limite para a estatística de Cook:</p>
<ul>
<li><span class="math inline">\(D_{i}&gt;1\)</span>: Cook e Weisberg, 1982 e Chatterjee, Hadi e Price, 2000;<br />
</li>
<li>duas vezes a média das distâncias de Cook;</li>
<li><span class="math inline">\(\frac{4}{n}&lt;D_{i}&lt;1\)</span>: Bollen et al, 1990; e,</li>
<li>o valor crítico do quantil da distribuição F para uma significância igual a 0.5 com df1=p e f2=n-p. </li>
</ul>
<pre><code>## 
## Distância de Cook:</code></pre>
<pre><code>## Limite de Cook &amp; Weisberg: 1</code></pre>
<pre><code>## Limite alternativo (2*média): 0.3145568</code></pre>
<pre><code>##          1          2          3          4          5          6 
## 0.06890349 0.27941333 0.01524820 0.08382924 0.17189204 0.32438402</code></pre>
<p><img src="apostila_files/figure-html/unnamed-chunk-19-1.png" width="672" style="display: block; margin: auto;" /></p>
<hr />
</div>
</div>
<div id="independência" class="section level3 hasAnchor" number="12.7.9">
<h3><span class="header-section-number">12.7.9</span> Independência<a href="#independ%C3%AAncia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Quando as observações da amostra são independentes o que se espera é que seus resíduos apresentem-se aleatoriamente dispersos em torno da linha horizontal (zero) quando dispostos na sequência em que foram coletadas. O que se pretende aqui é verificar se há correlação serial entre as observações.</p>
<p>A autocorrelação pode ser definida como a correlação entre integrantes de séries de observações ordenadas no tempo (como as séries temporais) ou no espaço (como nos dados de corte transversal) quando então os resíduos de duas observações guardam correlação diferente de zero entre si:</p>
<p><span class="math display">\[
\begin{aligned}
cov(\hat{\varepsilon_{i}}, \hat{\varepsilon_{j}}|x_{i}, x_{j}) \neq 0  \\
i \neq j
\end{aligned}
\]</span></p>
<hr />
<p>A correlação serial pode decorrer:</p>
<ul>
<li>inércia: quando os efeitos na alteração da variável <span class="math inline">\(X\)</span> demoram a se manifestar na variável <span class="math inline">\(Y\)</span> (muito comum em dados econômicos);</li>
<li>forma funcional do modelo incorreta;</li>
<li>variáveis importantes foram omitidas.</li>
</ul>
<blockquote>
<p>A verificação da independência resíduos <span class="math inline">\(\hat{\varepsilon}\)</span> pode ser verificada informalmente através de vários modos gráficos dentre os quais destacam-se:</p>
</blockquote>
<ul>
<li>resíduos contra o tempo ou ordem no qual as observações foram realizadas; e,</li>
<li>observações contra o tempo ou ordem no qual foram realizadas (um gráfico sequencial).</li>
</ul>
<p><img src="apostila_files/figure-html/unnamed-chunk-20-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>O que se espera é que nenhuma relação funcional seja percebida. Há ferramentas estatísticas apropriadas para se analisar dados provenientes de séries.</p>
<hr />
</div>
<div id="normalidade" class="section level3 hasAnchor" number="12.7.10">
<h3><span class="header-section-number">12.7.10</span> Normalidade<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#normalidade" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<blockquote>
<p>A Normalidade dos resíduos <span class="math inline">\(\hat{\varepsilon}\)</span> pode ser verificada informalmente através de vários modos gráficos dentre os quais descam-se:</p>
</blockquote>
<ul>
<li>pela comparação de suas frequências às frequências esperadas de uma distribuições Normal: 68%: <span class="math inline">\(\pm 1\)</span> desvio padrão; 90%: <span class="math inline">\(\pm 1.65\)</span> desvio padrão; 95%: <span class="math inline">\(\pm 1.96\)</span> desvio padrão;</li>
<li>gráficos de caixas;</li>
<li>histogramas;</li>
<li>gráficos dos quantis teóricos da distribuição Normal padronizada contra os quantis amostrais dos resíduos (QQ plot);</li>
<li>gráfico com envoltória simulada dos resíduos (Brian David Ripley em Modelling Spatial Patterns, 1977).</li>
</ul>
<p><img src="apostila_files/figure-html/unnamed-chunk-21-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre><code>## 
## Frequências dos resíduos padronizados:</code></pre>
<pre><code>## Dentro de ±1 DP: 83.33 % (esperado: 68%)</code></pre>
<pre><code>## Dentro de ±1.65 DP: 100 % (esperado: 90%)</code></pre>
<pre><code>## Dentro de ±1.96 DP: 100 % (esperado: 95%)</code></pre>
<p>Se os valores de uma amostra provêm de uma distribuição Normal, então os valores das estatísticas de ordem contruídas com os resíduos e os <span class="math inline">\(Z_{i}\)</span> correspondentes obtidos da distribuição Normal padrão são linearmente relacionados e, assim, o gráfico dos valores deve ter o aspecto aproximado de uma reta.</p>
<hr />
<p>Alguns aspectos desse gráfico diferentes de uma reta têm como provável causa:</p>
<ul>
<li>“S”: indica distribuições com caudas muito curtas, isto é, distribuições cujos valores estão muito próximos da média;</li>
<li>“S invertido”: indica distribuições com caudas muito longas e, portanto, presença de muitos valores extremos; e,</li>
<li>“J” e “J invertido”: indicam distribuições assimétricas, positivas e negativas, respectivamente.</li>
</ul>
<p>A análise do modelo com respeito à Normalidade de seus resíduos é, em muitos aspectos, mais difícil do que para as outras verificações.</p>
<p>A menos que o tamanho da amostra seja muito grande (<span class="math inline">\(n \sim 300\)</span>) a variação aleatória impõe sérias dificuldades para se estudar a natureza da distribuição de probabilidade da variável em estudo. Outros tipos de desvios podem também afetar a distribuição dos resíduos como quando a função é inadequada ou quando a variância não é constante. Assim, pequenos desvios dos resíduos em relação à distribuição Normal podem ser tolerados pois não causam problemas sérios na estimação do modelo.</p>
<hr />
<div id="testes-para-normalidade-dos-resíduos" class="section level4 hasAnchor" number="12.7.10.1">
<h4><span class="header-section-number">12.7.10.1</span> Testes para Normalidade dos resíduos:<a href="#testes-para-normalidade-dos-res%C3%ADduos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>Para uma análise formal da Normalidade há vários testes definidos:</p>
<ul>
<li><span class="math inline">\(K^{2}\)</span> de D’agostino (Ralph D’agostino);</li>
<li>Jarque-Bera (Carlos Jarque e Anil K. Bera);</li>
<li>Anderson-Darling (Theodore Wilbur Anderson e Donald Alan Darling);</li>
<li>Cramer-von Mises (H. Cramer e R.E. von Mises);</li>
<li>Lilliefors (Hubert W. Lilliefors);</li>
<li>Shapiro-Francia (Samuel Sandford Shapiro e S. Francia);</li>
<li><span class="math inline">\(X^{2}\)</span> de Karl Pearson;</li>
<li>Shapiro-Wilk (Samuel Sandford Shapiro e Martin Bradbury Wilk);</li>
<li>Kolmogorov-Smirnov (Andrey Kolmogorov e Nikolai Smirnov); e,</li>
<li>teste de correlação linear entre os resíduos padronizados ordenados e os quantis teóricos da distribuição Normal padronizada;</li>
</ul>
<hr />
</div>
</div>
<div id="variáveis-omitidas-do-modelo" class="section level3 hasAnchor" number="12.7.11">
<h3><span class="header-section-number">12.7.11</span> Variáveis omitidas do modelo<a href="#vari%C3%A1veis-omitidas-do-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p>Caso os dados sob análise possuam mais variáveis preditoras é prudente plotar um gráfico dos resíduos contra cada uma delas para que eventuais efeitos na variável resposta sejam descartados.</p>
<p>O objetivo desta análise adicional é determinar se há quaisquer outras variáveis que possam contribuir na explicação da variável resposta e assim, o padrão visual dos resíduos não pode diferir do padrão apresentado quando se plotam os resíduos contra a variável incorporada no modelo, não só na aleatoridade de sua dispersão mas também nas frequências ou concentrações mostradas acima ou abaixo da linha base (zero).</p>
<hr />
</div>
</div>
<div id="teste-de-significância-global-do-modelo" class="section level2 hasAnchor" number="12.8">
<h2><span class="header-section-number">12.8</span> Teste de significância (global) do modelo<a href="#teste-de-signific%C3%A2ncia-global-do-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p>O modelo <span class="math inline">\(\hat{Y} = a + b \cdot X\)</span> pode ser decomposto em duas partes:</p>
<ul>
<li>variação explicada: <span class="math inline">\(a + b \cdot X\)</span></li>
<li>variação residual: <span class="math inline">\(\hat{Y}-Y\)</span>, a diferença entre um valor estimado e o realmente observado.</li>
</ul>
<p>Se a variação explicada for significativamente superior à variação residual, teremos um bom indicativo de existe regressão linear entre as variáveis <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> e o modelo a está explicando razoavelmente bem.</p>
<p>Essa verificação é realizada pela <strong>análise de variância</strong>.</p>
<hr />
<p><br></p>
<center>
<div class="small-equation80">
<table>
<caption>
Quadro para a Análise de variância do modelo
</caption>
<tbody>
<tr>
<td style="text-align: left;">
Fonte
</td>
<td style="text-align: left;">
Graus
</td>
<td style="text-align: left;">
Soma
</td>
<td style="text-align: left;">
Quadrados
</td>
<td style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>c</em><em>a</em><em>l</em></sub></span>
</td>
<td style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>t</em><em>a</em><em>b</em></sub></span>
</td>
</tr>
<tr>
<td style="text-align: left;">
da variação
</td>
<td style="text-align: left;">
de liberdade
</td>
<td style="text-align: left;">
de quadrados
</td>
<td style="text-align: left;">
médios
</td>
<td style="text-align: left;">
</td>
<td style="text-align: left;">
</td>
</tr>
<tr>
<td style="text-align: left;">
REGRESSÃO
</td>
<td style="text-align: left;">
k = 1
</td>
<td style="text-align: left;">
<span class="math inline"><em>b</em> ⋅ <em>S</em><sub><em>x</em><em>y</em></sub></span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(QMREG = \frac{b
\cdot S_{xy}}{1}\)</span></span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(F_{calc}=
\frac{QMREG}{QMRES}\)</span></span>
</td>
<td style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>t</em><em>a</em><em>b</em>[1, (<em>n</em> − 2); <em>α</em>]</sub></span>
</td>
</tr>
<tr>
<td style="text-align: left;">
RESÍDUOS
</td>
<td style="text-align: left;">
n-k-1 = n-2
</td>
<td style="text-align: left;">
<span class="math inline"><em>S</em><sub><em>y</em><em>y</em></sub> − <em>b</em> ⋅ <em>S</em><sub><em>x</em><em>y</em></sub></span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(QMRES =
\frac{S_{yy} -b \cdot S_{xy}}{n-2}\)</span></span>
</td>
<td style="text-align: left;">
-
</td>
<td style="text-align: left;">
-
</td>
</tr>
<tr>
<td style="text-align: left;">
TOTAL
</td>
<td style="text-align: left;">
k+(n-k-1) = n-1
</td>
<td style="text-align: left;">
<span class="math inline"><em>S</em><sub><em>y</em><em>y</em></sub></span>
</td>
<td style="text-align: left;">
-
</td>
<td style="text-align: left;">
-
</td>
<td style="text-align: left;">
-
</td>
</tr>
</tbody>
</table>
</div>
</center>
<hr />
<p><br></p>
<p>Sendo SQTOTAL = SQREG - SQRES, em que:</p>
<p><br></p>
<p><span class="math display">\[
SQRES = S_{yy} - b\cdot S_{xy}\\
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n}\\
{S}_{yy}=\sum _{i=1}^{n} y_{i}^{2} - \frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}
\]</span></p>
<hr />
<p>A verificação da existência ou não de regressão linear na população é necessário testar o parâmetro <span class="math inline">\(\beta\)</span> e, para tanto, propomos as seguintes hipóteses:</p>
<p><span class="math display">\[
\begin{cases}
H_{0}: \beta = \beta_{0}  \\
H_{1}: \beta \ne 0  
\end{cases}
\]</span></p>
<p>Usualmente <span class="math inline">\(\beta_{0}=0\)</span>, indicando não haver regressão na população.</p>
<p>A estatística calculada (<span class="math inline">\({F}_{calc}\)</span>) será comparada a uma estatística <span class="math inline">\(F_{tab}\)</span> tabelada da Distribuição “F” (Ronald Aylmer Fisher-George Waddel Snedecor).</p>
<p><span class="math inline">\(F_{tab}\)</span> é o quantil de ordem <span class="math inline">\(\alpha\)</span> da Distribuição “F” (Ronald Aylmer Fisher-George Waddel Snedecor) com graus de liberdade <span class="math inline">\(1,(n-2)\)</span> (numerador e denominador, respectivamente).</p>
<p>Rejeita-se a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se:</p>
<p><span class="math display">\[
F_{calc}= \frac{QMREG}{QMRES} \ge F_{tab[1,(n-2); \alpha]}
\]</span></p>
<p>em um teste unilateral à direita: <span class="math inline">\((\alpha)\in \text{right tail}\)</span>.</p>
<hr />
<p>Vejam nessa simulação o gráfico da função densidade de probabilidade “F” (Ronald Aylmer Fisher-George Waddel Snedecor) com graus de liberdade no numerador e denominador: <span class="math inline">\(1, (n-2)\)</span> e nível de significância <span class="math inline">\((\alpha)\in \text{right tail}\)</span>. (SIMULADOR 4)</p>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 4 Uma indústria farmacêutica vende um remédio para aliviar os sintomas do resfriado. Após dois anos de operação ela coletou as informações trimestrais de vendas desse produto e despesas com sua propaganda. Estime um modelo de regressão linear simples e teste a existência da regressão pela ANOVA a um nível de significância de 5%</p>
</blockquote>
<center>
<div class="small-equation70">
<table>
<caption>
Quadro de despesas de propaganda (<span class="math inline"><em>X</em></span>) e receitas de vendas (<span class="math inline"><em>Y</em></span>)
</caption>
<thead>
<tr>
<th style="text-align: center;">
Trimestre
</th>
<th style="text-align: center;">
Despesas (X)
</th>
<th style="text-align: center;">
Vendas (Y)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
1
</td>
<td style="text-align: center;">
11
</td>
<td style="text-align: center;">
25
</td>
</tr>
<tr>
<td style="text-align: center;">
2
</td>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
13
</td>
</tr>
<tr>
<td style="text-align: center;">
3
</td>
<td style="text-align: center;">
3
</td>
<td style="text-align: center;">
8
</td>
</tr>
<tr>
<td style="text-align: center;">
4
</td>
<td style="text-align: center;">
9
</td>
<td style="text-align: center;">
20
</td>
</tr>
<tr>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
12
</td>
<td style="text-align: center;">
25
</td>
</tr>
<tr>
<td style="text-align: center;">
6
</td>
<td style="text-align: center;">
6
</td>
<td style="text-align: center;">
12
</td>
</tr>
<tr>
<td style="text-align: center;">
7
</td>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
10
</td>
</tr>
<tr>
<td style="text-align: center;">
8
</td>
<td style="text-align: center;">
9
</td>
<td style="text-align: center;">
15
</td>
</tr>
</tbody>
</table>
</div>
</center>
<hr />
<p><br></p>
<center>
<div class="small-equation80">
<table>
<caption>
Quadro para cálculo das estimativas dos parâmetros do
modelo
</caption>
<thead>
<tr>
<th style="text-align: center;">
Trimestre
</th>
<th style="text-align: center;">
Despesas (X)
</th>
<th style="text-align: center;">
Vendas (Y)
</th>
<th style="text-align: center;">
<span class="math inline"><em>X</em> ⋅ <em>Y</em></span>
</th>
<th style="text-align: center;">
<span class="math inline"><em>X</em><sup>2</sup></span>
</th>
<th style="text-align: center;">
<span class="math inline"><em>Y</em><sup>2</sup></span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
1
</td>
<td style="text-align: center;">
11
</td>
<td style="text-align: center;">
25
</td>
<td style="text-align: center;">
275
</td>
<td style="text-align: center;">
121
</td>
<td style="text-align: center;">
625
</td>
</tr>
<tr>
<td style="text-align: center;">
2
</td>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
13
</td>
<td style="text-align: center;">
65
</td>
<td style="text-align: center;">
25
</td>
<td style="text-align: center;">
169
</td>
</tr>
<tr>
<td style="text-align: center;">
3
</td>
<td style="text-align: center;">
3
</td>
<td style="text-align: center;">
8
</td>
<td style="text-align: center;">
24
</td>
<td style="text-align: center;">
9
</td>
<td style="text-align: center;">
64
</td>
</tr>
<tr>
<td style="text-align: center;">
4
</td>
<td style="text-align: center;">
9
</td>
<td style="text-align: center;">
20
</td>
<td style="text-align: center;">
180
</td>
<td style="text-align: center;">
81
</td>
<td style="text-align: center;">
400
</td>
</tr>
<tr>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
12
</td>
<td style="text-align: center;">
25
</td>
<td style="text-align: center;">
300
</td>
<td style="text-align: center;">
144
</td>
<td style="text-align: center;">
625
</td>
</tr>
<tr>
<td style="text-align: center;">
6
</td>
<td style="text-align: center;">
6
</td>
<td style="text-align: center;">
12
</td>
<td style="text-align: center;">
72
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
144
</td>
</tr>
<tr>
<td style="text-align: center;">
7
</td>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
10
</td>
<td style="text-align: center;">
50
</td>
<td style="text-align: center;">
25
</td>
<td style="text-align: center;">
100
</td>
</tr>
<tr>
<td style="text-align: center;">
8
</td>
<td style="text-align: center;">
9
</td>
<td style="text-align: center;">
15
</td>
<td style="text-align: center;">
135
</td>
<td style="text-align: center;">
81
</td>
<td style="text-align: center;">
225
</td>
</tr>
<tr>
<td style="text-align: center;">
Totais
</td>
<td style="text-align: center;">
60
</td>
<td style="text-align: center;">
128
</td>
<td style="text-align: center;">
1101
</td>
<td style="text-align: center;">
522
</td>
<td style="text-align: center;">
2352
</td>
</tr>
<tr>
<td style="text-align: center;">
Valor médio
</td>
<td style="text-align: center;">
7,50
</td>
<td style="text-align: center;">
16,00
</td>
<td style="text-align: center;">
-
</td>
<td style="text-align: center;">
-
</td>
<td style="text-align: center;">
-
</td>
</tr>
</tbody>
</table>
</div>
</center>
<hr />
<p>Sendo <span class="math inline">\(n= 8\)</span>, <span class="math inline">\(\stackrel{-}{y}= 16\)</span> e <span class="math inline">\(\stackrel{-}{x} = 7,50\)</span>, calculamos:</p>
<p><span class="math display">\[
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n} = 1101 - \frac{60 \cdot 128}{8} = 141 \\
S_{xx} = \sum _{i=1}^{n} x_{i}^{2} - \frac{(\sum _{i=1}^{n} x_{i})^{2}}{n} = 522 - \frac{60^2}{8} = 72\\
{S}_{yy} = \sum _{i=1}^{n}y_{i}^{2} - \frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}=   2352 - \frac{128^2}{8} = 304
\]</span></p>
<hr />
<p>As estimativas dos parâmetros do modelo serão:</p>
<p><span class="math display">\[
b = \frac{S_{xy}}{S_ {xx}} = \frac{141}{72} = 1,9583\\
a = \stackrel{-}{y} - b\cdot\stackrel{-}{x} = 16 - 1,9583 \cdot 7,50 = 1,3125
\]</span></p>
<p><br></p>
<p>O modelo toma a seguinte forma:</p>
<p><span class="math display">\[
\hat{y} = 1,3125 + 1,9583 \cdot x
\]</span></p>
<hr />
<p><br></p>
<center>
<div class="small-equation70">
<table>
<caption>
Quadro para análise de variância do modelo
</caption>
<thead>
<tr>
<th style="text-align: left;">
Fonte da variação
</th>
<th style="text-align: left;">
Graus de liberdade
</th>
<th style="text-align: left;">
Soma de quadrados
</th>
<th style="text-align: left;">
Quadrados médios
</th>
<th style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>c</em><em>a</em><em>l</em></sub></span>
</th>
<th style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>t</em><em>a</em><em>b</em></sub></span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
REGRESSÃO
</td>
<td style="text-align: left;">
k = 1
</td>
<td style="text-align: left;">
<span class="math inline"><em>b</em>.<em>S</em><sub><em>x</em><em>y</em></sub> = 1, 9583.141 = 276, 12</span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(QMREG =
\frac{b.S_{xy}}{1}=276,12\)</span></span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(F_{calc} =
\frac{QMREG}{QMRES} = 59,50\)</span></span>
</td>
<td style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>t</em><em>a</em><em>b</em>[1, (<em>n</em> − 2); <em>α</em>]</sub> = <em>F</em><sub><em>t</em><em>a</em><em>b</em>[1, 6; 5%</sub> = 5, 987</span>
</td>
</tr>
<tr>
<td style="text-align: left;">
RESÍDUOS
</td>
<td style="text-align: left;">
n-k-1 = n-2 = 6
</td>
<td style="text-align: left;">
<span class="math inline"><em>S</em><sub><em>y</em><em>y</em></sub> − <em>b</em> ⋅ <em>S</em><sub><em>x</em><em>y</em></sub> = 304 − 1, 9583 ⋅ 141 = 27, 87</span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(QMRES =
\frac{S_{yy} -b \cdot S_{xy}}{n-2} = 4,64\)</span></span>
</td>
<td style="text-align: left;">
—
</td>
<td style="text-align: left;">
—
</td>
</tr>
<tr>
<td style="text-align: left;">
TOTAL
</td>
<td style="text-align: left;">
k+(n-k-1) = n-1 = 7
</td>
<td style="text-align: left;">
<span class="math inline"><em>S</em><sub><em>y</em><em>y</em></sub> = 304</span>
</td>
<td style="text-align: left;">
—
</td>
<td style="text-align: left;">
—
</td>
<td style="text-align: left;">
—
</td>
</tr>
</tbody>
</table>
</div>
<p>Conclusão: frente ao resultado da análise dos dados rejeita-se a hipótese sob um nível de significância de 5%. (SIMULADOR 4)</p>
</center>
<hr />
</div>
<div id="teste-de-hipóteses-para-o-coef.-angular-beta" class="section level2 hasAnchor" number="12.9">
<h2><span class="header-section-number">12.9</span> Teste de hipóteses para o coef. angular <span class="math inline">\(\beta\)</span><a href="#teste-de-hip%C3%B3teses-para-o-coef.-angular-beta" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>O teste de hipóteses para o coeficiente angular <span class="math inline">\(\beta\)</span> pode ser proposto da forma que se segue:</p>
<p><span class="math display">\[
\begin{cases}
H_{0}: \beta  = \beta_{0}  \hspace{0.5cm} \\
H_{1}: \beta  \ne \beta_{0} \hspace{0.5cm}  
\end{cases}
\]</span></p>
<p>Usualmente fazemos <span class="math inline">\(\beta_{0}=0\)</span>, indicando não haver regressão.</p>
<p>Estatística do teste:</p>
<p><span class="math display">\[
t_{calc}=\frac{b-\beta_{0}}{s_{b}}
\]</span></p>
<hr />
<p><br></p>
<p>Rejeita-se a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se:</p>
<p><span class="math display">\[
{t}_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]}\\
\text{ou}\\
{t}_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}
\]</span></p>
<p>em um teste bilateral: <span class="math inline">\((\frac{\alpha}{2})\in \text{left tail}; (\frac{\alpha}{2})\in \text{right tail}\)</span>.</p>
<p>Sendo <span class="math inline">\(t_{tab}\)</span> o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido (<span class="math inline">\(\alpha\)</span>) com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se na forma de linhas (graus de liberdade) e colunas (nível de significância).</p>
<hr />
<p><br></p>
<p>Vejam nessa simulaçao o gráfico da função densidade de probabilidade “t” de Student (William Sealy Gosset, 1876-1937) com graus de liberdade: <span class="math inline">\((n-2)\)</span> e nível de significância: <span class="math inline">\((\frac{\alpha}{2})\in \text{left tail}; (\frac{\alpha}{2})\in \text{right tail}\)</span>. (SIMULADOR 2 COM t)</p>
<hr />
</div>
<div id="teste-de-hipóteses-para-o-coef.-angular-alpha" class="section level2 hasAnchor" number="12.10">
<h2><span class="header-section-number">12.10</span> Teste de hipóteses para o coef. angular <span class="math inline">\(\alpha\)</span><a href="#teste-de-hip%C3%B3teses-para-o-coef.-angular-alpha" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p>O teste de hipóteses para o coeficiente linear <span class="math inline">\(\alpha\)</span> pode ser proposto da forma que se segue:</p>
<p><span class="math display">\[
\begin{cases}
H_{0}: \alpha = \alpha_{0} \\
H_{1}: \alpha \ne \alpha_{0}
\end{cases}
\]</span></p>
<p>Usualmente <span class="math inline">\(\alpha_{0} =0\)</span> indicando que a regressão passa pela origem.</p>
<p>Estatística do teste:</p>
<p><span class="math display">\[
{t}_{calc}=\frac{a-{\alpha }_{0}}{{s}_{a}}
\]</span></p>
<hr />
<p><br></p>
<p>Rejeita-se a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se:</p>
<p><span class="math display">\[
t_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]} \\
\text{ou}\\
t_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}
\]</span></p>
<p>em um teste bilateral: <span class="math inline">\((\frac{\alpha}{2})\in \text{left tail}; (\frac{\alpha}{2})\in \text{right tail}\)</span>.</p>
<p>Sendo <span class="math inline">\(t_{tab}\)</span> o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido (<span class="math inline">\(\alpha\)</span>) com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se na forma de linhas (graus de liberdade) e colunas (nível de significância).</p>
<hr />
<p><br></p>
<p>Vejam nessa simulaçao o gráfico da função densidade de probabilidade “t” de Student (William Sealy Gosset, 1876-1937) com graus de liberdade: <span class="math inline">\((n-2)\)</span> e nível de significância: <span class="math inline">\((\frac{\alpha}{2})\in \text{left tail}; (\frac{\alpha}{2})\in \text{right tail}\)</span>. (SIMULADOR 2 COM t)</p>
<hr />
</div>
<div id="coeficiente-de-determinação-r2" class="section level2 hasAnchor" number="12.11">
<h2><span class="header-section-number">12.11</span> Coeficiente de determinação <span class="math inline">\(R^{2}\)</span><a href="#coeficiente-de-determina%C3%A7%C3%A3o-r2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p>O coeficiente de determinação amostral (<span class="math inline">\(R^{2}\)</span>) é uma medida estatística que informa o quanto da variação observada na variável <span class="math inline">\(Y\)</span> está sendo explicada no modelo pela relação linear estabelecida com a variável <span class="math inline">\(X\)</span>.</p>
<p><span class="math display">\[
R^{2} = \frac{\text{variação explicada}}{\text{variação total}} \\
R^{2}=\frac{b\cdot Sxy}{{S}_{yy}}
\]</span></p>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 5: O faturamento de uma loja durante o período de janeiro a gosto de 2010 é dado pela tabela abaixo (milhares de R$). Construa um modelo, calcule a correlação existente, teste a existência da regressão pela ANOVA, a correlação linear obtida, as estimativas de seus coeficientes <span class="math inline">\(a\)</span> e <span class="math inline">\(b\)</span> de seus coeficientes <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>, a um nível de significância de 5%</p>
</blockquote>
<center>
<table>
<caption>
Quadro do faturamento: meses (<span class="math inline"><em>X</em></span>); faturamento (<span class="math inline"><em>Y</em></span>)
</caption>
<thead>
<tr>
<th style="text-align: center;">
Meses
</th>
<th style="text-align: center;">
(<span class="math inline"><em>X</em></span>)
</th>
<th style="text-align: center;">
Faturamento (<span class="math inline"><em>Y</em></span>)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
Janeiro
</td>
<td style="text-align: center;">
1
</td>
<td style="text-align: center;">
20
</td>
</tr>
<tr>
<td style="text-align: center;">
Fevereiro
</td>
<td style="text-align: center;">
2
</td>
<td style="text-align: center;">
22
</td>
</tr>
<tr>
<td style="text-align: center;">
Março
</td>
<td style="text-align: center;">
3
</td>
<td style="text-align: center;">
23
</td>
</tr>
<tr>
<td style="text-align: center;">
Abril
</td>
<td style="text-align: center;">
4
</td>
<td style="text-align: center;">
26
</td>
</tr>
<tr>
<td style="text-align: center;">
Maio
</td>
<td style="text-align: center;">
5
</td>
<td style="text-align: center;">
28
</td>
</tr>
<tr>
<td style="text-align: center;">
Junho
</td>
<td style="text-align: center;">
6
</td>
<td style="text-align: center;">
29
</td>
</tr>
<tr>
<td style="text-align: center;">
Julho
</td>
<td style="text-align: center;">
7
</td>
<td style="text-align: center;">
32
</td>
</tr>
<tr>
<td style="text-align: center;">
Agosto
</td>
<td style="text-align: center;">
8
</td>
<td style="text-align: center;">
36
</td>
</tr>
</tbody>
</table>
</center>
<hr />
<p>Sendo <span class="math inline">\(n= 8\)</span>, <span class="math inline">\(\stackrel{-}{Y}= 27\)</span> e <span class="math inline">\(\stackrel{-}{x} = 4,5\)</span>, calculamos:</p>
<p><span class="math display">\[
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n} = 1063 - \frac{36 \cdot 216}{8} = 91\\
S_{xx} = \sum _{i=1}^{n} x_{i}^{2} - \frac{(\sum _{i=1}^{n} x_{i})^{2}}{n} = 204 - \frac{36^2}{8} = 42\\
{S}_{yy} = \sum _{i=1}^{n}y_{i}^{2} - \frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}=   6034 - \frac{216^2}{8} = 202
\]</span></p>
<hr />
<p>As estimativas dos parâmetros do modelo serão:</p>
<p><span class="math display">\[
b = \frac{S_{xy}}{S_ {xx}} = \frac{91}{42} = 2,166\\
a = \stackrel{-}{y} - b\cdot\stackrel{-}{x} = 27 - 2,166 \cdot 4,50 = 17,253\\
\]</span></p>
<p>E o modelo toma a seguinte forma:</p>
<p><span class="math display">\[
\hat{y} = 17,253 + 2,166 \cdot x
\]</span></p>
<p>O coeficiente de correlação linear de Pearson é:</p>
<p><span class="math display">\[
r = \frac{{s}_{xy}}{\sqrt{{s}_{xx}\cdot {s}_{yy}}} = \frac{91}{\sqrt{42 \cdot 202}} = 0,9880
\]</span></p>
<hr />
<center>
<div class="small-equation70">
<table>
<caption>
Quadro para análise de variância do modelo
</caption>
<thead>
<tr>
<th style="text-align: left;">
da variação
</th>
<th style="text-align: left;">
Graus de liberdade
</th>
<th style="text-align: left;">
Soma de quadrados
</th>
<th style="text-align: left;">
Quadrados médios
</th>
<th style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>c</em><em>a</em><em>l</em></sub></span>
</th>
<th style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>t</em><em>a</em><em>b</em></sub></span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">
REGRESSÃO
</td>
<td style="text-align: left;">
k = 1
</td>
<td style="text-align: left;">
<span class="math inline"><em>b</em>.<em>S</em><sub><em>x</em><em>y</em></sub> = 2, 166.91 = 197, 106</span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(QMREG =
\frac{b.S_{xy}}{1}=197,106\)</span></span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(F_{calc}=\frac{QMREG}{QMRES} = 241,84\)</span></span>
</td>
<td style="text-align: left;">
<span class="math inline"><em>F</em><sub><em>t</em><em>a</em><em>b</em>[1, (<em>n</em> − 2); <em>α</em>]</sub> = <em>F</em><sub><em>t</em><em>a</em><em>b</em>[1, 6; 5%]</sub></span>
</td>
</tr>
<tr>
<td style="text-align: left;">
RESÍDUOS
</td>
<td style="text-align: left;">
n-k-1 = n-2 = 6
</td>
<td style="text-align: left;">
<span class="math inline"><em>S</em><sub><em>y</em><em>y</em></sub> − <em>b</em>.<em>S</em><sub><em>x</em><em>y</em></sub> = 202 − 2, 166.91 = 4, 894</span>
</td>
<td style="text-align: left;">
<span class="math inline"><span class="math inline">\(QMRES =
\frac{S_{yy} -b.S{xy}}{n-2} = 0,815\)</span></span>
</td>
<td style="text-align: left;">
–
</td>
<td style="text-align: left;">
–
</td>
</tr>
<tr>
<td style="text-align: left;">
TOTAL
</td>
<td style="text-align: left;">
k+(n-k-1) = n-1 = 7
</td>
<td style="text-align: left;">
<span class="math inline"><em>S</em><sub><em>y</em><em>y</em></sub> = 202</span>
</td>
<td style="text-align: left;">
–
</td>
<td style="text-align: left;">
–
</td>
<td style="text-align: left;">
</td>
</tr>
</tbody>
</table>
</div>
<p>Conclusão: frente ao resultado da análise dos dados rejeitamos a hipótese nula sob um nível de significância de 5%. (SIMULADOR 4)</p>
</center>
<hr />
<p><br></p>
<p>Teste de hipóteses para a correlação linear <span class="math inline">\(\rho\)</span> :</p>
<p><span class="math display">\[
\begin{cases}
H_{0}: \rho = \rho_{0}  \\
H_{1}: \rho \ne 0
\end{cases}
\]</span></p>
<p>com <span class="math inline">\(\rho_{0} =0\)</span>. Estatística do teste:</p>
<p><span class="math display">\[
t_{calc}=\frac{r\cdot\sqrt{n-2}}{\sqrt{1-{r}^{2}}} =  \frac{0,9880 \cdot \sqrt{6}}{\sqrt{1-0,9880^2}} = 15,668
\]</span></p>
<hr />
<p>Rejeita-se a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se o valor da estatística for tão extremo que se verifique:</p>
<p><span class="math display">\[
t_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]}\\
\text{ou}\\
t_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}
\]</span></p>
<p><span class="math display">\[
t_{tab[\frac{\alpha }{2};\left(n-2\right)]}={t}_{tab[\frac{0.05}{2};\left(6\right)]}=-2,44 \\
t_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}={t}_{tab[1-\frac{0.05}{2};\left(6\right)]}=2,44
\]</span></p>
<p>Conclusão: frente ao resultado da análise dos dados rejeitamos a hipotese nula sob um nível de significância de 5%. (SIMULADOR 2 COM t)</p>
<hr />
<p>Teste de hipóteses para o coeficiente angular <span class="math inline">\(\beta\)</span>:</p>
<p><span class="math display">\[
\begin{cases}
H_{0}: \beta = \beta_{0} \\
H_{1}: \beta  \ne \beta_{0}
\end{cases}
\]</span></p>
<p>com <span class="math inline">\(\beta_{0} =0\)</span>. Estatística do teste:</p>
<p><span class="math display">\[
t_{calc}=\frac{b-\beta_{0}}{s_{b}}
\]</span></p>
<p>com:</p>
<p><span class="math display">\[
s_{b} = \sqrt{\frac{{\hat{\sigma}}^{2}}{{S}_{xx}}}  = \sqrt{\frac{\text{QMRES}}{S_{xx}}}
\]</span></p>
<p><span class="math display">\[
t_{calc}= 15,5491
\]</span></p>
<hr />
<p>Rejeita-se a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se:</p>
<p><span class="math display">\[
t_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]} \\
\text{ou}\\
t_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}
\]</span></p>
<p><span class="math display">\[
t_{tab[\frac{\alpha }{2};\left(n-2\right)]}={t}_{tab[\frac{0.05}{2};\left(6\right)]}=-2,44 \\
t_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}={t}_{tab[1-\frac{0.05}{2};\left(6\right)]}=2,44
\]</span></p>
<p>Conclusão: frente ao resultado da análise dos dados rejeita-se a hip´tese nula sob um nível de significância de 5%. (SIMULADOR 2 COM t)</p>
<hr />
<p>Teste de hipóteses para o coeficiente linear <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
\begin{cases}
H_{0}: \alpha  = \alpha_{0}  \\
H_{1}: \alpha  \ne \alpha_{0}
\end{cases}
\]</span></p>
<p>com <span class="math inline">\(\alpha_{0}=0\)</span>. Estatística do teste:</p>
<p><span class="math display">\[
t_{calc}=\frac{a-{\alpha }_{0}}{{s}_{a}}
\]</span></p>
<p>com</p>
<p><span class="math display">\[
s_{a} = \sqrt{\text{QMRES} \cdot
\left(\frac{1}{n}+\frac{{\stackrel{-}{x}}^{2}}{{S}_{xx}}\right)}\\
\]</span></p>
<p><span class="math display">\[
t_{calc}= 24,5268
\]</span></p>
<hr />
<p>Rejeita-se a hipótese nula (<span class="math inline">\(H_{0}\)</span>) se: </p>
<p><span class="math display">\[
t_{calc} \le {t}_{tab[\frac{\alpha }{2};\left(n-2\right)]} \\
\text{ou}\\
t_{calc} \ge {t}_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}
\]</span></p>
<p><span class="math display">\[
t_{tab[\frac{\alpha }{2};\left(n-2\right)]}={t}_{tab[\frac{0.05}{2};\left(6\right)]}=-2,44 \\
t_{tab[1-\frac{\alpha }{2};\left(n-2\right)]}={t}_{tab[1-\frac{0.05}{2};\left(6\right)]}=2,44
\]</span></p>
<p>Conclusão: frente ao resultado da análise dos dados rejeita-se a hip´tese nula sob um nível de significância de 5%. (SIMULADOR 2 COM t)</p>
<hr />
<p>O coeficiente de determinação será:</p>
<p><span class="math display">\[
R^{2} = \frac{\text{variação explicada}}{\text{variação total}}\\
R^{2}=\frac{b\cdot Sxy}{{S}_{yy}} = 0,9758
\]</span></p>
<p>O coeficiente de determinação amostral (<span class="math inline">\(R^{2}\)</span>) é uma medida estatística que informa, em termos percentuais, o quanto da variação observada na variável <span class="math inline">\(Y\)</span> está sendo explicada no modelo pela relação linear estabelecida com a variável <span class="math inline">\(X\)</span>. No exemplo em tela, 97,58%.</p>
<hr />
</div>
<div id="intervalos-de-confiança-nos-modelos-de-regressão-linear-simples" class="section level2 hasAnchor" number="12.12">
<h2><span class="header-section-number">12.12</span> Intervalos de confiança nos modelos de regressão linear simples<a href="#intervalos-de-confian%C3%A7a-nos-modelos-de-regress%C3%A3o-linear-simples" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p>Um intervalo de confiança (<span class="math inline">\(IC\)</span>) pode ser entendido como uma <strong>faixa de valores bastante específica</strong> para uma estatística calculada dentro da qual, sob alguma confiança, podemos afirmar se localizar o valor do parâmetro estimado.</p>
<p>Essa faixa pode ser fechada ou aberta (delimitada apenas por dois ou apenas um valor, respectivamente):</p>
<ul>
<li>intervalos de confiança bilaterais: intervalos delimitados por dois valores: mínimo e máximo, dentro do qual todos os valores possuem um mesmo nível de confiança de ocorrência;</li>
<li>intervalos de confiança unilaterais: intervalos delimitados apenas em um de seus lados, nos quais todos os valores possuem um mesmo nível de confiança (limitados à direita por um valor máximo ou limitados à esquerda por um valor mínimo).</li>
</ul>
<blockquote>
<p>A amplitude de um intervalo de confiança é uma função diretamente proporcional a um <em>nível de confiança</em> e à <em>variabilidade</em> da população amostrada (quanto maior a variabilidade e/ou o nível de confiança, maior sua amplitude) e inversamente proporcional ao <em>tamanho amostral</em> (quanto maior o tamanho da amostra, menor sua amplitude.</p>
</blockquote>
<p><span class="math display">\[
amplitude=\text{estimativa amostral} \pm f(confiança, variabilidade, \frac{1}{n})
\]</span></p>
<hr />
<p>Como raramente se dispõe de informação a respeito da variabilidade da carcaterística estudada na população, esse valor é considerado na expressão acima de modo estimado por uma amostra.</p>
<p>Um <strong>intervalo de confiança</strong> reflete uma estimativa objetiva da (im)precisão acarretada pelo tamanho da amostra e, assim, podemos considerá-lo como uma medida da qualidade da pesquisa.</p>
<p>O <strong>nível de confiança</strong> associado ao intervalo é designado pela quantidade <span class="math inline">\((1-\alpha)\)</span>, sendo <span class="math inline">\(\alpha\)</span> denominado de <strong>nível de significância</strong>: uma medida da probabilidade de erro.</p>
<p>Dependendo do <strong>nível de confiança</strong> que escolhemos, os limites do intervalo mudam para uma <strong>mesma</strong> estimativa amostral. Os <strong>níveis de confiança</strong> mais utilizados na literatura são os de 90%, 95% e 99%.</p>
<p>Assim, <span class="math inline">\((1-\alpha)\)</span> traduz o grau de confiança que se tem em que uma <em>particular amostra</em> de tamanho <span class="math inline">\(n\)</span> da variável aleatória <span class="math inline">\(X\)</span> dê origem a um intervalo de valores (o intervalo de confiança) que compreenda o verdadeiro valor do parâmetro sobre o qual se estima ou sobre o qual se infere.</p>
<p>Vejam a simulação onde contruímos um grande número de intervalos de confiança calculados sob as mesmas condições (mesma população amostrada, mesmo tamanho amostral (n) e nível de significância <span class="math inline">\(\alpha\)</span>).(SIMULADOR 5)</p>
<p>Nela podemos observar que uma determinada proporção desses intervalos (aproximadamente igual ao nível de confiança <span class="math inline">\(1-\alpha\)</span>), conterá o <em>parâmetro</em> sobre o qual se estima e se deseja inferir.</p>
<blockquote>
<p>Intervalo de confiança para a resposta média do modelo (equivale a dizer a resposta fornecida pelo modelo ajustado para <strong>valores observados</strong>)</p>
</blockquote>
<hr />
<blockquote>
<p>Intervalo de predição para novas observações (equivale a dizer a resposta fornecida pelo modelo ajustado para <strong>valores não observados</strong>)</p>
</blockquote>
<hr />
<blockquote>
<p>Intervalo de confiança para as estimativas dos parâmetros do modelo (o modelo ajustado apresenta meras <strong>estimativas</strong>: <strong>a</strong> e <strong>b</strong>, dos parâmetros desconhecidos: <strong><span class="math inline">\(\alpha\)</span></strong> e <strong><span class="math inline">\(\beta\)</span></strong>).</p>
</blockquote>
<hr />
<div id="intervalo-de-confiança-para-a-resposta-média-do-modelo-sob-um-nível-de-significância-alpha" class="section level3 hasAnchor" number="12.12.1">
<h3><span class="header-section-number">12.12.1</span> Intervalo de confiança para a resposta média do modelo sob um nível de significância <span class="math inline">\(\alpha\)</span><a href="#intervalo-de-confian%C3%A7a-para-a-resposta-m%C3%A9dia-do-modelo-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p><span class="math display">\[
IC=\hat{y_0} \pm {t}_{tab\left[\frac{\alpha }{2};\left(n-2\right)\right]}\cdot \hat{\sigma}\cdot \sqrt{\frac{1}{n}+ \frac{{\left({x}_{0}-\stackrel{-}{x}\right)}^{2}}{S_{xx}}}
\]</span>
em que:</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}}
\]</span></p>
<p>e <span class="math inline">\(\hat{y}_{0}\)</span> é o valor médio estimado para um <span class="math inline">\(x_{0}\)</span> pertencente à amostra e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se individualizadas por nível de significância e graus de liberdade. (SIMULADOR 2 COM t)</p>
<hr />
</div>
<div id="intervalo-de-predição-para-novas-observações-sob-um-nível-de-significância-alpha" class="section level3 hasAnchor" number="12.12.2">
<h3><span class="header-section-number">12.12.2</span> Intervalo de predição para novas observações sob um nível de significância <span class="math inline">\(\alpha\)</span><a href="#intervalo-de-predi%C3%A7%C3%A3o-para-novas-observa%C3%A7%C3%B5es-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p><strong>Importante:</strong> O intervalo de predição é sempre mais amplo que o intervalo de confiança para a resposta média, pois incorpora tanto a incerteza na estimação de <span class="math inline">\(E(Y|X)\)</span> quanto a variabilidade de observações individuais ao redor dessa média.</p>
<p><br></p>
<p><span class="math display">\[
IC=\hat{y_0} \pm  {t}_{tab\left[\frac{\alpha }{2};\left(n-2\right)\right]}\cdot \hat{\sigma }\cdot \sqrt{1+\frac{1}{n}+\frac{{\left({x}_{0}-\stackrel{-}{x}\right)}^{2}}{S_{xx}}}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}}
\]</span></p>
<p>e <span class="math inline">\(\hat{y}_{0}\)</span> é o valor predito para um <span class="math inline">\(x_{0}\)</span> não pertencente à amostra e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se individualizadas por nível de significância e graus de liberdade. (SIMULADOR 2 COM t)</p>
<hr />
</div>
<div id="intervalo-confiança-para-a-estimativa-a-do-parâmetro-alpha-sob-um-nível-de-significância-alpha" class="section level3 hasAnchor" number="12.12.3">
<h3><span class="header-section-number">12.12.3</span> Intervalo confiança para a estimativa <span class="math inline">\(a\)</span> do parâmetro <span class="math inline">\(\alpha\)</span> sob um nível de significância <span class="math inline">\(\alpha\)</span><a href="#intervalo-confian%C3%A7a-para-a-estimativa-a-do-par%C3%A2metro-alpha-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p><span class="math display">\[
a \pm  {t}_{tab\left[\frac{\alpha }{2};\left(n-2\right)\right]}\cdot \hat{\sigma } \cdot \sqrt{ \left(\frac{1}{n}+\frac{\stackrel{-}{x}^{2}}{Sxx}\right)}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}}
\]</span></p>
<p>e <span class="math inline">\(a\)</span> é a estimativa do parâmetro <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se individualizadas por nível de significância e graus de liberdade. (SIMULADOR 2 COM t)</p>
<hr />
</div>
<div id="intervalo-confiança-para-a-estimativa-b-do-parâmetro-beta-sob-um-nível-de-significância-alpha" class="section level3 hasAnchor" number="12.12.4">
<h3><span class="header-section-number">12.12.4</span> Intervalo confiança para a estimativa <span class="math inline">\(b\)</span> do parâmetro <span class="math inline">\(\beta\)</span> sob um nível de significância <span class="math inline">\(\alpha\)</span><a href="#intervalo-confian%C3%A7a-para-a-estimativa-b-do-par%C3%A2metro-beta-sob-um-n%C3%ADvel-de-signific%C3%A2ncia-alpha" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><br></p>
<p><span class="math display">\[
b \pm {t}_{tab\left[\frac{\alpha }{2},\left(n-2\right)\right]}\cdot \frac{\hat{\sigma}}{\sqrt{  {S_{xx}}}}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}}
\]</span></p>
<p>e <span class="math inline">\(b\)</span> é a estimativa do parâmetro <span class="math inline">\(\beta\)</span> e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição “t” de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido com <span class="math inline">\((n-2)\)</span> graus de liberdade. O número de graus de liberdade irá determinar qual curva da família dessa distribuição será utilizada, por essa razão, as tabelas apresentam-se individualizadas por nível de significância e graus de liberdade. (SIMULADOR 2)</p>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 6: Um jornal deseja verificar a eficácia de seus anúncios na venda de carros usados e para isso realizou um levantamento de todos os seus anúncios e informações dos resultados obtidos pelas empresas que o contrataram e dele extraiu uma pequena amostra. A tabela abaixo mostra o número de anúncios e o correspondente número de veículos vendidos por 6 companhias que usaram apenas este jornal como veículo de propaganda. Obtenha a equação de regressão linear simples. Qual a estimativa de vendas do modelo para um volume de 36 anúncios? Qual a previsão do número de carros vendidos para um volume de 70 anúncios? Quais os intervalos (estimativa, predição e para os regressores do modelo) sob um nível de significância de 5<br />
</p>
</blockquote>
<center>
<div class="small-equation80">
<table>
<caption>
Quadro de dados da quantidade de carros vendidos por 6 empresas
distintas pela quantidade de anúncios feitos
</caption>
<thead>
<tr>
<th style="text-align: center;">
Companhia
</th>
<th style="text-align: center;">
Anúncios feitos (<span class="math inline"><em>X</em></span>)
</th>
<th style="text-align: center;">
Carros vendidos (<span class="math inline"><em>Y</em></span>)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
A
</td>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
</tr>
<tr>
<td style="text-align: center;">
B
</td>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
</tr>
<tr>
<td style="text-align: center;">
C
</td>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
</tr>
<tr>
<td style="text-align: center;">
D
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
</tr>
<tr>
<td style="text-align: center;">
E
</td>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
</tr>
<tr>
<td style="text-align: center;">
F
</td>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
</tr>
</tbody>
</table>
</div>
</center>
<hr />
<p>Trazendo os resultados já calculados em exemplos anteriores:</p>
<p>com <span class="math inline">\(n= 6\)</span>, <span class="math inline">\(\stackrel{-}{y}= 90\)</span> e <span class="math inline">\(\stackrel{-}{x} = 41\)</span> calcula-se</p>
<p><span class="math display">\[
S_{xy} = \sum _{i=1}^{n} x_{i}y_{i} - \frac{\sum _{i=1}^{n}x_{i}\cdot\sum _{i=1}^{n}y_{i}}{n} = 25172 - \frac{246 \cdot 540}{6} = 3032 \\
S_{xx} = \sum _{i=1}^{n} x_{i}^{2} -\frac{(\sum _{i=1}^{n} x_{i})^{2}}{n} = 12086 - \frac{246^2}{6} = 2000 \\
{S}_{yy} = \sum _{i=1}^{n}y_{i}^{2} - \frac{(\sum _{i=1}^{n} y_{i})^{2}}{n}=   53458 - \frac{540^2}{6} = 4858
\]</span></p>
<hr />
<p>As estimativas dos parâmetros do modelo serão:</p>
<p><span class="math display">\[
b = \frac{S_{xy}}{S_ {xx}} = \frac{3032}{2000} = 1,5160 \\
a = \stackrel{-}{y} - b\cdot\stackrel{-}{x} = 90 - 1,5160 \cdot 41 = 27,844
\]</span>
E o modelo toma a seguinte forma:</p>
<p><span class="math display">\[
\hat{y} = 27,844 + 1,5160 \cdot x
\]</span></p>
<hr />
<p>O <em>valor médio</em> estimado para um volume de anúncios de 36 veiculações é de 82 carros vendidos. O intervalo de confiança para a <em>resposta média</em> do modelo: <span class="math inline">\(IC[\mu(x_{0}=36)]\)</span> sob um nível de significância <span class="math inline">\(\alpha\)</span> será</p>
<p><span class="math display">\[
\hat{y_0} \pm {t}_{tab\left[\frac{\alpha }{2};\left(n-2\right)\right]}\cdot \hat{\sigma}\cdot \sqrt{\frac{1}{n}+ \frac{{\left({x}_{0}-\stackrel{-}{x}\right)}^{2}}{S_{xx}}}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}} = 8,0853
\]</span></p>
<p><span class="math inline">\(\hat{y_0}=82\)</span> é o valor médio estimado para o valor observado <span class="math inline">\(x_{0} = 36\)</span> (um dado pertencente à amostra) e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição ``t’’ de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido (<span class="math inline">\(\alpha=5\%\)</span>) com <span class="math inline">\((n-2)=4\)</span> graus de liberdade (<span class="math inline">\(t_{tab} = 2,77\)</span>).</p>
<p>Assim, <span class="math inline">\(IC[\mu(x=36)]_{(\alpha=5\%)} = (72,5201 ; 91,4799 )\)</span>. (SIMULADOR 2 COM t)</p>
<hr />
<p>O <em>valor predito</em> para um volume de anúncios de 70 veiculações é de 134 carros vendidos. O intervalo de predição para novas observações <span class="math inline">\(IP[Y({x_{0})}]\)</span> com nível de significância <span class="math inline">\(\alpha\)</span> será:</p>
<p><span class="math display">\[
\hat{y_0} \pm {t}_{tab\left[\frac{\alpha }{2};\left(n-2\right)\right]}\cdot \hat{\sigma }\cdot \sqrt{1+\frac{1}{n}+\frac{{\left({x}_{0}-\stackrel{-}{x}\right)}^{2}}{S_{xx}}}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}} = 8,0853
\]</span></p>
<p><span class="math inline">\(\hat{y}_{0}=134\)</span> é o valor predito para um valor não observado <span class="math inline">\(x_{0} = 70\)</span> e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição ``t’’ de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido (<span class="math inline">\(\alpha=5\%\)</span>) com <span class="math inline">\((n-2)=4\)</span> graus de liberdade (<span class="math inline">\(t_{tab} = 2,77\)</span>).</p>
<blockquote>
<p>Assim, <span class="math inline">\(IP[Y({x_{0})}]_{(\alpha=5\%)} = (105,7845 ; 162,2155)\)</span></p>
</blockquote>
<p>Intervalo de confiança para a estimativa <span class="math inline">\(a\)</span> do parâmetro <span class="math inline">\(\alpha\)</span> do modelo sob um nível de significância <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
a \pm {t}_{tab\left[\frac{\alpha }{2};\left(n-2\right)\right]}\cdot \hat{\sigma } \cdot \sqrt{ \left(\frac{1}{n}+\frac{\stackrel{-}{x}^{2}}{Sxx}\right)}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}} = 8,0853
\]</span></p>
<p><span class="math inline">\(a = 27,844\)</span> é a estimativa do parâmetro <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição ``t’’ de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido (<span class="math inline">\(\alpha=5\%\)</span>) com <span class="math inline">\((n-2)=4\)</span> graus de liberdade (<span class="math inline">\(t_{tab} = 2,77\)</span>).</p>
<p>Assim, <span class="math inline">\(IC(a)_{(\alpha=5\%)} = (5,3676 ; 50,3204)\)</span>. (SIMULADOR 2 COM t)</p>
<hr />
<p>Intervalo de confiança para a estimativa <span class="math inline">\(b\)</span> do parâmetro <span class="math inline">\(\beta\)</span> do modelo sob um nível de significância <span class="math inline">\(\alpha\)</span>:</p>
<p><span class="math display">\[
b \pm  {t}_{tab\left[\frac{\alpha }{2},\left(n-2\right)\right]}\cdot \frac{\hat{\sigma}}{\sqrt{  {S_{xx}}}}
\]</span></p>
<p>em que</p>
<p><span class="math display">\[
\hat{\sigma}=\sqrt{QMRES} = \sqrt{\frac{SQRES}{(n-2)}} = \sqrt{\frac{S_{yy}- b \cdot S_{xy}}{(n-2)}} = 8,0853
\]</span></p>
<p>e <span class="math inline">\(b=1,5160\)</span> é a estimativa do parâmetro <span class="math inline">\(\beta\)</span> e e <span class="math inline">\(t_{tab}\)</span> é o quantil associado na distribuição ``t’’ de Student (William Sealy Gosset, 1876-1937) ao nível de significância pretendido (<span class="math inline">\(\alpha=5\%\)</span>) com <span class="math inline">\((n-2)=4\)</span> graus de liberdade (<span class="math inline">\(t_{tab} = 2,77\)</span>).</p>
<p>Assim, <span class="math inline">\(IC(b)_{(\alpha=5\%)} = (1,0152 ; 2,0168 )\)</span>. (SIMULADOR 2 COM t)</p>
<hr />
</div>
</div>
<div id="verificações-gráficas-visuais-das-premissas-do-mmqo" class="section level2 hasAnchor" number="12.13">
<h2><span class="header-section-number">12.13</span> Verificações gráficas (visuais) das premissas do MMQO<a href="#verifica%C3%A7%C3%B5es-gr%C3%A1ficas-visuais-das-premissas-do-mmqo" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<p>A análise dos resíduos de um modelo de regressão linear simples é parte fundamental para que se avalie se o modelo produzido representa de forma acurada a realidade estudada.</p>
<ul>
<li><p>Linearidade no parâmetro: deve-se esperar que a relação entre a variável dependente (<em>Y</em>) e a variável independente (<em>X</em>) possa ser representada por uma função linear}:</p>
<ul>
<li>pela análise dos gráficos dos resíduos padronizados no eixo <span class="math inline">\(y\)</span> pelos valores
estimados e pela variável independente no eixo <span class="math inline">\(x\)</span>. Em geral, valores próximos à
linha horizontal representam observações bem estimadas pelo modelo. Os pontos acima e abaixo são observações superestimadas ou subestimadas pelo modelo. A premissa
delinearidade é apoiada pelo padrão de distribuição dos pontos, que deve indicar
uma razoável igualdade acima e abaixo da linha. Padronizam-se os resíduos brutos
pela Divisão de cada um deles pelo desvio padrão; ou seja: <span class="math inline">\(d_{i} = \frac{e_{i}}{
  \hat{\sigma}} = \frac{e_{i}}{ \sqrt{QMRES}}\)</span></li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>independência dos resíduos: os erros não devem ser correlacionados entre si, isto é, <span class="math inline">\(Cov(\varepsilon_i, \varepsilon_j) = 0\)</span> para <span class="math inline">\(i \neq j\)</span>. Resíduos com valor médio zero e normalmente distribuídos: (<span class="math inline">\(\varepsilon \sim N(0,\sigma^{2})\)</span>):</p>
<ul>
<li>pela análise do histograma dos resíduos padronizados, com o propósito de se verificar se sua distribuição guarda semelhança com a da curva normal</li>
<li>pela comparação das frequências relativas acumuladas dos resíduos padronizados para os intervalos de (-1; +1), (-1,64; +1,64), (-1,96; +1,96) com as probabilidades da distribuição normal nesses mesmos intervalos (68%, 95% e 99%)</li>
<li>pela análise do gráfico dos resíduos padronizados ordenados pelos quantis da distribuição normal padronizada, que deve se aproximar da bissetriz do primeiro quadrante</li>
<li>pela análise temporal dos resíduos (quando há ordem de coleta) ou uso de testes como Durbin-Watson para detectar autocorrelação</li>
</ul></li>
</ul>
<hr />
<ul>
<li><p>a variância residual seja sempre constante (homocedástica) para todas as observações, isto é, <span class="math inline">\(VAR(\varepsilon)=E(\varepsilon)=\sigma^2\)</span></p></li>
<li><p>ausência de autocorrelação entre os termos de erros:</p>
<ul>
<li>pela análise do gráfico dos resíduos padronizados pelos valores estimados <span class="math inline">\(\hat{y}\)</span>, que deve apresentar pontos dispostos aleatoriamente sem padrão aparente;</li>
</ul></li>
<li><p>mensuração das variáveis: assume-se que as variáveis foram medidas sem erro;</p></li>
<li><p>correta especificação do modelo: todas as variáveis independentes teoricamente relevantes foram incluídas no modelo e nenhuma irrelevante foi mantida;</p></li>
<li><p>ausência de multicolinearidade.</p></li>
</ul>
<hr />
</div>
<div id="verificações-adicionais" class="section level2 hasAnchor" number="12.14">
<h2><span class="header-section-number">12.14</span> Verificações adicionais<a href="#verifica%C3%A7%C3%B5es-adicionais" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><br></p>
<ul>
<li>Análise de pontos com elevada capacidade de alavancar o modelo. A alavancagem mede o quanto uma observação <span class="math inline">\(x_{i}\)</span> contribui para a predição de <span class="math inline">\(\hat{y}_{i}\)</span> pelo modelo. Um ponto é considerado alavanca (<em>leverage</em>) quando este exerce uma forte influência no seu valor ajustado, sem com isso afetar a estimativa dos parâmetros do modelo. De modo análogo à distância de Cook, há diversos critérios para estabelecer um valor crítico para os <em>hat values</em>: <span class="math inline">\(h_{ii}\)</span>:
<ul>
<li><span class="math inline">\(h_{ii}\)</span> &gt; 2p/n (Hoaglin e Welsch, 1978),</li>
<li><span class="math inline">\(h_{ii}\)</span> &gt; 3p/n.</li>
</ul></li>
</ul>
<hr />
<ul>
<li>Pontos discrepantes (<span class="math inline">\(outliers\)</span>): A discrepância pode ser medida pela distância residual. Entretanto, os resíduos não são uma medida completa da discrepância. Para tanto basta-se imaginar casos onde onde uma observação possua elevada alavancagem que arraste o modelo inteiro em sua direção, resultando em pequenos resíduos. Uma forma de isolar esses pontos é dividindo seu resíduo por 1-<span class="math inline">\(h_{ii}\)</span>, obtendo-se a partir dessa expressão os resíduos <span class="math inline">\(studentizados\)</span>.</li>
</ul>
<hr />
<ul>
<li><p>influentes: A estatística distância de Cook mede a influência de um determinado dado da amostra no que tange a quanto ele está afetando a linha de regressão, sendo medida pelo quanto a linha de regressão se alteraria caso esse dado fosse removido da da análise: ele exerce um destacado impacto da estimativa dos parâmetros do modelo. A influência na locação (afastamento de alguma observação da vizinhança do resto dos dados) pode ser investigada pelo
gráfico feito das distâncias de Cook contra os valores ajustados. Há vários critérios para se estabelecer um valor limite para a estatística de Cook:\</p></li>
<li><p><span class="math inline">\(D_{i}\)</span> &gt; 1 (Cook e Weisberg, 1982);
<br></p></li>
<li><p>duas vezes a média das distâncias de Cook;
<br></p></li>
<li><p>4/n &lt; <span class="math inline">\(D_{i}\)</span> &lt; 1 (Bollen et al, 1990); ou,
<br></p></li>
<li><p>o valor crítico do quantil da distribuição F para uma significância igual a 0.5 com df1=p e f2=n-p.</p></li>
</ul>
<hr />
<p><br></p>
<blockquote>
<p>Exemplo 7: Um jornal deseja verificar a eficácia de seus anúncios na venda de carros usados e para isso realizou um levantamento de todos os seus anúncios e informações dos resultados obtidos pelas empresas que o contrataram e dele extraiu uma pequena amostra. A tabela abaixo mostra o número de anúncios e o correspondente número de veículos vendidos por 6 companhias que usaram apenas este jornal como veículo de propaganda. Estime os parâmetros de um modelo de regressão linear simples de <span class="math inline">\(X\)</span> por <span class="math inline">\(Y\)</span> verifique os pressupostos subjacentes ao método utilizado. Faça a análise dos resíduos e identifique possíveis <span class="math inline">\(outliers\)</span> .</p>
</blockquote>
<center>
<div class="small-equation70">
<table>
<caption>
Quadro de dados da quantidade de carros vendidos por 6 empresas
distintas pela quantidade de anúncios feitos
</caption>
<thead>
<tr>
<th style="text-align: center;">
Companhia
</th>
<th style="text-align: center;">
Anúncios feitos (<span class="math inline"><em>X</em></span>)
</th>
<th style="text-align: center;">
Carros vendidos (<span class="math inline"><em>Y</em></span>)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
A
</td>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
</tr>
<tr>
<td style="text-align: center;">
B
</td>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
</tr>
<tr>
<td style="text-align: center;">
C
</td>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
</tr>
<tr>
<td style="text-align: center;">
D
</td>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
</tr>
<tr>
<td style="text-align: center;">
E
</td>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
</tr>
<tr>
<td style="text-align: center;">
F
</td>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
</tr>
</tbody>
</table>
</div>
</center>
<blockquote>
<p>Trazendo o modelo estimado anteriormente: <span class="math inline">\(\hat{y} = 27,844 + 1,5160 \cdot x\)</span></p>
</blockquote>
<hr />
<p><br></p>
<center>
<table>
<caption>
Quadro de valores observados, estimados, resíduos brutos e
padronizados
</caption>
<thead>
<tr>
<th style="text-align: center;">
Anúncios (X)
</th>
<th style="text-align: center;">
Carros vendidos (Y)
</th>
<th style="text-align: center;">
Valores estimados
</th>
<th style="text-align: center;">
Resíduos brutos
</th>
<th style="text-align: center;">
Resíduos padronizados
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">
74
</td>
<td style="text-align: center;">
139
</td>
<td style="text-align: center;">
140,028
</td>
<td style="text-align: center;">
-1,028
</td>
<td style="text-align: center;">
-0,1271
</td>
</tr>
<tr>
<td style="text-align: center;">
45
</td>
<td style="text-align: center;">
108
</td>
<td style="text-align: center;">
96,064
</td>
<td style="text-align: center;">
11,936
</td>
<td style="text-align: center;">
1,4762
</td>
</tr>
<tr>
<td style="text-align: center;">
48
</td>
<td style="text-align: center;">
98
</td>
<td style="text-align: center;">
100,612
</td>
<td style="text-align: center;">
-2,612
</td>
<td style="text-align: center;">
0,3230
</td>
</tr>
<tr>
<td style="text-align: center;">
36
</td>
<td style="text-align: center;">
76
</td>
<td style="text-align: center;">
82,420
</td>
<td style="text-align: center;">
-6,420
</td>
<td style="text-align: center;">
0,7940
</td>
</tr>
<tr>
<td style="text-align: center;">
27
</td>
<td style="text-align: center;">
62
</td>
<td style="text-align: center;">
68,776
</td>
<td style="text-align: center;">
-6,776
</td>
<td style="text-align: center;">
-0,8380
</td>
</tr>
<tr>
<td style="text-align: center;">
16
</td>
<td style="text-align: center;">
57
</td>
<td style="text-align: center;">
52,100
</td>
<td style="text-align: center;">
4,900
</td>
<td style="text-align: center;">
0,6060
</td>
</tr>
</tbody>
</table>
</center>
<hr />
<figure class="image">
<img src="images12/linearidade.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<figure class="image">
<img src="images12/histo.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<figure class="image">
<img src="images12/qqplot.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<figure class="image">
<img src="images12/homoced.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<p><br></p>
<div id="roteiro-básico-para-uma-análise-de-regressão-linear-simples" class="section level4 hasAnchor" number="12.14.0.1">
<h4><span class="header-section-number">12.14.0.1</span> Roteiro básico para uma análise de regressão linear simples<a href="#roteiro-b%C3%A1sico-para-uma-an%C3%A1lise-de-regress%C3%A3o-linear-simples" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<ul>
<li>Definir o problema de pesquisa, selecionar a variável dependente e
identificar a variável independente; ou seja, proceder a especificação do modelo. Aqui o pesquisador deve definir qual é a relação esperada entre a variável dependente e a independente;</li>
<li>Maximizar o número de observações no sentido de aumentar o poder
estatístico, a capacidade de generalização e reduzir toda sorte de problemas associados a estimação de parâmetros populacionais a partir de dados amostrais com <span class="math inline">\(n\)</span> reduzido;</li>
<li>Estimar um modelo;</li>
<li>Verificar em que medida os dados disponíveis satisfazem os pressupostos
da análise de regressão de mínimos quadrados ordinários. Como procedimento padrão, o pesquisador deve reportar as técnicas utilizadas para corrigir eventuais violações (transformações, re-codificações, aumento de <span class="math inline">\(n\)</span>, etc.);</li>
<li>Interpretar os resultados, caso o modelo seja validado.</li>
</ul>
<hr />
<p><br></p>
</div>
<div id="homocedasticidade-transformações-para-estabilização-da-variância" class="section level4 hasAnchor" number="12.14.0.2">
<h4><span class="header-section-number">12.14.0.2</span> Homocedasticidade: transformações para estabilização da variância<a href="#homocedasticidade-transforma%C3%A7%C3%B5es-para-estabiliza%C3%A7%C3%A3o-da-vari%C3%A2ncia" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>Quando se observa que a distribuição gráfica dos resíduos não se mostra homocedástica, muitas vezes é útil aplicar uma transformação de Box-Cox para estabilizarmos a variância (torná-la constante independentemente do valor do resíduo).</p>
<p><strong>Importante:</strong> A transformação de Box-Cox é aplicada <strong>apenas à variável dependente</strong> <span class="math inline">\(Y\)</span>, não à variável independente <span class="math inline">\(X\)</span>.</p>
<p>Considerando <span class="math inline">\(Y_{1}, ..., Y_{n}\)</span> os dados originais da variável dependente, a transformação de Box-Cox consiste em encontrar um <span class="math inline">\(\lambda\)</span> tal que os dados transformados <span class="math inline">\(Y^{(\lambda)}_{1}, ..., Y^{(\lambda)}_{n}\)</span> se aproximem de uma distribuição normal e apresentem variância constante.</p>
<p>O modelo passa a assumir a forma: <span class="math inline">\(Y^{(\lambda)} = X \cdot \beta + \varepsilon\)</span> com <span class="math inline">\(Y^{(\lambda)}\)</span> sendo:</p>
<p><span class="math display">\[
\frac{Y^{\lambda} - 1}{\lambda} \text{  se } \lambda \ne 0 \\
ln (Y_{i}) \text{  se } \lambda = 0
\]</span></p>
<hr />
<p><br></p>
</div>
<div id="transformações-para-linearização-das-relações" class="section level4 hasAnchor" number="12.14.0.3">
<h4><span class="header-section-number">12.14.0.3</span> Transformações para linearização das relações<a href="#transforma%C3%A7%C3%B5es-para-lineariza%C3%A7%C3%A3o-das-rela%C3%A7%C3%B5es" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<p>Algumas vezes as relações observadas entre a variável dependente e a independente não se mostram diretamente lineares.</p>
<p>Relações não-lineares podem ser linearizadas pela aplicação de transformações aos dados:</p>
<ul>
<li>Função hiperbólica: <span class="math inline">\(Y = \frac{X}{a \cdot X - b}\)</span>, pela forma transformada: <span class="math inline">\(\frac{1}{Y} = a - \frac{b}{X}\)</span></li>
<li>Função exponencial: <span class="math inline">\(Y = a \cdot e^{b \cdot X}\)</span>, pela forma transformada: $Ln (Y) = Ln (a) + b X $</li>
<li>Função potência: <span class="math inline">\(Y = a \cdot X ^{b}\)</span>, pela forma transformada: <span class="math inline">\(Ln (Y) = Ln (a) + b \cdot Ln (X)\)</span></li>
</ul>
<hr />
<p><br></p>
</div>
<div id="tabelas-2" class="section level4 hasAnchor" number="12.14.0.4">
<h4><span class="header-section-number">12.14.0.4</span> Tabelas<a href="introducao-a-correlacao-linear-de-pearson-e-regressao-linear-simples.html#tabelas-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><br></p>
<figure class="image">
<img src="images12/tabela_t.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<figure class="image">
<img src="images12/tabela_F_5.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<figure class="image">
<img src="images12/tab_correlacao.png" alt="Figure" width="80%" height="auto" style="display: block; margin: auto;">
</figure>
<hr />
<p><br></p>
</div>
<div id="resolução-do-sistema-de-equações-matriciais" class="section level4 hasAnchor" number="12.14.0.5">
<h4><span class="header-section-number">12.14.0.5</span> Resolução do sistema de equações matriciais<a href="#resolu%C3%A7%C3%A3o-do-sistema-de-equa%C3%A7%C3%B5es-matriciais" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Seja a matriz <span class="math inline">\(Y\)</span> das observações realizadas na variável dependente <span class="math inline">\(Y_{i}\)</span> (dimensão <span class="math inline">\(n \times 1\)</span>):</p>
<p><br></p>
<p><span class="math display">\[
Y = \begin{pmatrix}
y_{1} \\
y_{2} \\
\vdots \\
y_{n}
\end{pmatrix}
\]</span></p>
<p>Seja a matriz <span class="math inline">\(X\)</span> das observações realizadas na variável independente <span class="math inline">\(X_{i}\)</span> (dimensão <span class="math inline">\(n \times 2\)</span>):</p>
<p><span class="math display">\[
X = \begin{pmatrix}
1 &amp; x_{1} \\
1 &amp; x_{2} \\
\vdots &amp; \vdots \\
1 &amp; x_{n}
\end{pmatrix}
\]</span></p>
<hr />
<p>Seja a matriz <span class="math inline">\(\beta\)</span> dos parâmetros a serem estimados (dimensão: <span class="math inline">\(2 \times 1\)</span>):</p>
<p><span class="math display">\[
\beta = \begin{pmatrix}
\hat{\beta}_{0} \\
\hat{\beta}_{1}
\end{pmatrix}
\]</span></p>
<p>Seja a matriz <span class="math inline">\(e\)</span> dos termos aleatórios (dimensão: <span class="math inline">\(n \times 1\)</span>), não correlacionados, com média zero e variância constante:</p>
<p><span class="math display">\[
e = \begin{pmatrix}
e_{1} \\
e_{2} \\
\vdots \\
e_{n}
\end{pmatrix}
\]</span></p>
<hr />
<p>Então podemos escrever o seguinte sistema matricial:</p>
<p><span class="math display">\[
Y = X \cdot \hat{\beta} + e
\]</span></p>
<p>A minimização da soma dos quadrados dos resíduos pode ser realizada fazendo-se:</p>
<p><span class="math display">\[
\Sigma (e_{i})^{2} = e^T \cdot e
\]</span></p>
<p>O sistema acima tomará a forma:</p>
<p><span class="math display">\[
e = Y - X \cdot \hat{\beta}
\]</span></p>
<p><span class="math display">\[
e^T \cdot e = (Y - X \cdot \hat{\beta})^T \cdot (Y - X \cdot \hat{\beta})
\]</span></p>
<hr />
<p>Expandindo:</p>
<p><span class="math display">\[
Y^T \cdot Y - 2 \cdot \hat{\beta}^T \cdot X^T \cdot Y + \hat{\beta}^T \cdot X^T \cdot X \cdot \hat{\beta}
\]</span></p>
<p>Minimizando os resíduos, obtemos a equação normal:</p>
<p><span class="math display">\[
(X^T \cdot X) \cdot \hat{\beta} = X^T \cdot Y
\]</span></p>
<p>Multiplicando ambos os lados por <span class="math inline">\((X^T \cdot X)^{-1}\)</span>:</p>
<p><span class="math display">\[
(X^T \cdot X)^{-1} \cdot (X^T \cdot X) \cdot \hat{\beta} = (X^T \cdot X)^{-1} \cdot X^T \cdot Y
\]</span></p>
<hr />
<p>Por fim, considerando-se que <span class="math inline">\((X^T \cdot X)^{-1} \cdot (X^T \cdot X) = I\)</span>, obtemos a solução para <span class="math inline">\(\hat{\beta}\)</span>:</p>
<p><span class="math display">\[
\hat{\beta} = (X^T \cdot X)^{-1} \cdot X^T \cdot Y
\]</span></p>

</div>
</div>
</div>
<script>
$(document).ready(function() {
  var $summary = $('.book-summary');
  var $body = $('.book-body');
  var $header = $('.book-header');
  var isResizing = false;
  var startX, startWidth;

  // Adicionar handle de redimensionamento
  $summary.append('<div class="resize-handle"></div>');
  
  var $handle = $('.resize-handle');

  $handle.on('mousedown', function(e) {
    isResizing = true;
    startX = e.clientX;
    startWidth = $summary.width();
    
    $('body').css('cursor', 'ew-resize');
    e.preventDefault();
  });

  $(document).on('mousemove', function(e) {
    if (!isResizing) return;
    
    var width = startWidth + (e.clientX - startX);
    
    // Limites de largura
    if (width < 200) width = 200;
    if (width > 600) width = 600;
    
    $summary.css('width', width + 'px');
    
    // Atualizar left do body e header se o TOC estiver visível
    if ($('.book').hasClass('with-summary')) {
      $body.css('left', width + 'px');
      $header.css('left', width + 'px');
    }
  });

  $(document).on('mouseup', function() {
    if (isResizing) {
      isResizing = false;
      $('body').css('cursor', 'default');
    }
  });
  
  // Observar mudanças na classe 'with-summary'
  var observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      if (mutation.attributeName === 'class') {
        var hasSummary = $('.book').hasClass('with-summary');
        if (!hasSummary) {
          // TOC colapsado
          $body.css('left', '0');
          $header.css('left', '0');
        } else {
          // TOC expandido
          var width = $summary.width();
          $body.css('left', width + 'px');
          $header.css('left', width + 'px');
        }
      }
    });
  });
  
  observer.observe($('.book')[0], {
    attributes: true
  });
});
</script>
            </section>

          </div>
        </div>
      </div>
<a href="introducao-a-testes-de-hipoteses.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introducao-a-regressao-linear-multipla.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/USERNAME/REPO/edit/BRANCH/12-correlacao_e_regressao_linear_simples.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["apostila.pdf", "apostila.epub"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "none",
    "depth": 8
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
